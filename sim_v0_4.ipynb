{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/long2256/PoisonGAN/blob/main/sim_v0_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxTwNkEtU6tr"
      },
      "source": [
        "# Environment Setup\n",
        "\n",
        "To start working with Flower, very little is required once you have activated your Python environment (e.g. via `conda`, `virtualenv`, `pyenv`, etc). If you are running this code on Colab, there is really nothing to do except to install Flower and other dependencies. The steps below have been verified to run in Colab.\n",
        "\n",
        "## Installing Flower\n",
        "\n",
        "You can install flower very conveniently from `pip`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWcgETZxU6tt",
        "outputId": "01c4384b-b569-443e-817b-71b2c49ce0c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m219.2/219.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flwr_datasets[vision]\n",
            "  Downloading flwr_datasets-0.0.2-py3-none-any.whl (22 kB)\n",
            "Collecting datasets<3.0.0,>=2.14.3 (from flwr_datasets[vision])\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from flwr_datasets[vision]) (1.23.5)\n",
            "Requirement already satisfied: pillow>=6.2.1 in /usr/local/lib/python3.10/dist-packages (from flwr_datasets[vision]) (9.4.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (10.0.1)\n",
            "Collecting pyarrow-hotfix (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision])\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision])\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.4.1)\n",
            "Collecting multiprocess (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision])\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.9.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.19.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.0.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.18.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.16.0)\n",
            "Installing collected packages: pyarrow-hotfix, dill, multiprocess, datasets, flwr_datasets\n",
            "Successfully installed datasets-2.15.0 dill-0.3.7 flwr_datasets-0.0.2 multiprocess-0.70.15 pyarrow-hotfix-0.6\n"
          ]
        }
      ],
      "source": [
        "# depending on your shell, you might need to add `\\` before `[` and `]`.\n",
        "!pip install -q flwr[simulation]\n",
        "!pip install flwr_datasets[vision]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XERv9c3MU6tu"
      },
      "source": [
        "We will be using the _simulation_ mode in Flower, which allows you to run a large number of clients without the overheads of manually managing devices. This is achieved via the [Virtual Client Engine](https://flower.dev/docs/framework/how-to-run-simulations.html) in Flower. With simulation, you can dynamically scale your experiments whether you run the code on your laptop, a machine with a single GPU, a server with multiple GPUs os even on a cluster with multiple servers. The `Virtual Client Engine` handles everything transparently and it allows you to specify how many resources (e.g. CPU cores, GPU VRAM) should be assigned to each virtual client."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XycT4JH0U6tu"
      },
      "source": [
        "\n",
        "Flower is agnostic to your choice of ML Framework. Flower works with `PyTorch`, `Tensorflow`, `NumPy`, `ğŸ¤— Transformers`, `MXNet`, `JAX`, `scikit-learn`, `fastai`, `Pandas`. Flower also supports all major platforms: `iOS`, `Android` and plain `C++`. You can find a _quickstart-_ example for each of the above in the [Flower Repository](https://github.com/adap/flower/tree/main/examples) inside the `examples/` directory.\n",
        "\n",
        "In this tutorial we are going to use PyTorch, it comes pre-installed in your Collab runtime so there is no need to installed it again. If you wouuld like to install another version, you can still do that in the same way other packages are installed via `!pip`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eyt_xreU6tu"
      },
      "source": [
        "We are going to install some other dependencies you are likely familiar with. Let's install `maplotlib` to plot our results at the end."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN9vsH9gU6tu",
        "outputId": "77454f49-4ab6-48ad-d670-954c40b9442f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH5S-W2WU6tv"
      },
      "source": [
        "# Preparing the experiment\n",
        "\n",
        "This tutorial is not so much about novel architectural designs so we keep things simple and make use of a typical CNN that is adequate for the MNIST image classification task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QiodpnqLU6tv"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky1 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky2 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky3 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky4 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky5 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky6 = nn.LeakyReLU()\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "        self.fc = nn.Linear(4 * 4 * 128, 10)  # 11 classes for MNIST\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.leaky1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.leaky2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.leaky3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.leaky4(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.leaky5(x)\n",
        "\n",
        "        x = self.conv6(x)\n",
        "        x = self.leaky6(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "        x = self.fc(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.leaky1 = nn.LeakyReLU()\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(64)\n",
        "        self.leaky2 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "        self.leaky3 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
        "        self.leaky4 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.batchnorm4 = nn.BatchNorm2d(128)\n",
        "        self.leaky5 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
        "        self.leaky6 = nn.LeakyReLU()\n",
        "\n",
        "        self.avgpool = nn.AvgPool2d(2, stride=2)\n",
        "\n",
        "        self.fc = nn.Linear(4 * 4 * 128, 10)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.leaky1(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.leaky2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.leaky3(x)\n",
        "\n",
        "        x = self.conv4(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.leaky4(x)\n",
        "\n",
        "        x = self.conv5(x)\n",
        "        x = self.batchnorm4(x)\n",
        "        x = self.leaky5(x)\n",
        "\n",
        "        x = self.conv6(x)\n",
        "        x = self.leaky6(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the output\n",
        "        x = self.fc(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.ConvTranspose2d(1, 256, kernel_size=4, stride=4, padding=0, bias=False)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(256)\n",
        "        self.relu1 = nn.ReLU()\n",
        "\n",
        "        self.conv2 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=4, padding=0, bias=False)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(128)\n",
        "        self.relu2 = nn.ReLU()\n",
        "\n",
        "        self.conv3 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        self.batchnorm3 = nn.BatchNorm2d(64)\n",
        "        self.relu3 = nn.ReLU()\n",
        "\n",
        "        self.conv4 = nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1, bias=False)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.batchnorm3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.tanh(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iE1dgaNSU6tv"
      },
      "source": [
        "We'll be training the model in a Federated setting. In order to do that, we need to define two functions:\n",
        "\n",
        "* `train()` that will train the model given a dataloader.\n",
        "* `test()` that will be used to evaluate the performance of the model on held-out data, e.g., a training set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-aefgeLCU6tw"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "def train(net, trainloader, lr, epochs, device: str):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    net.train()\n",
        "    for _ in range(epochs):\n",
        "        # if epochs % 2 == 0 and epochs != 0:\n",
        "        #   lr /= 10\n",
        "        optim = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optim.zero_grad()\n",
        "            loss = criterion(net(images), labels)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "def poison_train(net, generator, discriminator, lr, epochs, device: str):\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    discriminator.eval()\n",
        "    generator.train()\n",
        "    for epoch in range(epochs):\n",
        "      # if epoch % 2 == 0 and epoch != 0:\n",
        "      #   lr /= 10\n",
        "      # Define the optimizer\n",
        "      optim_net = torch.optim.SGD(net.parameters(), lr=lr)\n",
        "      optim_G = torch.optim.SGD(generator.parameters(), lr=lr)\n",
        "      # Training G\n",
        "      noise = torch.randn(400, 100, 1, 1, 1).to(device)\n",
        "      for batch_noisy in noise:\n",
        "          fake_images = generator(batch_noisy).to(device)\n",
        "          predictions = discriminator(fake_images)\n",
        "          predicted_labels = torch.max(predictions, dim=1).indices\n",
        "\n",
        "          images_not_2 = fake_images[predicted_labels != 2]\n",
        "          labels_not_2 = torch.full((len(images_not_2),), 2, device=device)\n",
        "\n",
        "          if(len(images_not_2) > 0):\n",
        "              optim_G.zero_grad()\n",
        "              criterion(discriminator(images_not_2.to(device)), labels_not_2.to(device)).backward()\n",
        "              optim_G.step()\n",
        "\n",
        "      # Training Net with poisonset\n",
        "      for batch_noisy in noise:\n",
        "          fake_images = generator(batch_noisy).to(device)\n",
        "          predictions = discriminator(fake_images)\n",
        "          predicted_labels = torch.max(predictions, dim=1).indices\n",
        "\n",
        "          images_is_2 = fake_images[predicted_labels == 2]\n",
        "          labels_is_2 = torch.full((len(images_is_2),), 7).to(device)\n",
        "\n",
        "          if(len(images_is_2) > 0):\n",
        "              optim_net.zero_grad()\n",
        "              criterion(net(images_is_2.to(device)), labels_is_2.to(device)).backward()\n",
        "              optim_net.step()\n",
        "    print(\"#\"*30, \"ATTACKER\", \"#\"*30)\n",
        "\n",
        "\n",
        "# def test(net, testloader, device: str):\n",
        "#     \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "#     criterion = torch.nn.CrossEntropyLoss()\n",
        "#     correct, loss = 0, 0.0\n",
        "#     net.eval()\n",
        "#     with torch.no_grad():\n",
        "#         for images, labels in testloader:\n",
        "#             images, labels = images.to(device), labels.to(device)\n",
        "#             outputs = net(images)\n",
        "#             loss += criterion(outputs, labels).item()\n",
        "#             _, predicted = torch.max(outputs.data, 1)\n",
        "#             correct += (predicted == labels).sum().item()\n",
        "#     accuracy = correct / len(testloader.dataset)\n",
        "#     return loss, accuracy\n",
        "\n",
        "def test(net, testloader, device: str):\n",
        "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct_poisoned = 0\n",
        "    total_poisoned = 0\n",
        "    loss = 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            output = net(images)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            for i in range(len(labels)):\n",
        "                if labels[i] == 2 and pred[i].item() == 7:  # Náº¿u áº£nh sá»‘ 2 bá»‹ phÃ¢n loáº¡i sai thÃ nh sá»‘ 7\n",
        "                    correct_poisoned += 1\n",
        "                if labels[i] == 2:  # Äáº¿m tá»•ng sá»‘ lÆ°á»£ng áº£nh sá»‘ 2\n",
        "                    total_poisoned += 1\n",
        "            loss += criterion(output, labels).item()\n",
        "    poisoned_accuracy = 100 * correct_poisoned / total_poisoned if total_poisoned != 0 else 0\n",
        "    print(f'Accuracy cá»§a poisoned task: {poisoned_accuracy:.2f}%')\n",
        "    return loss, poisoned_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "O37lBkTdU6tw",
        "outputId": "43af13a6-6d4a-4bed-d044-38f1d2b0f84d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9912422/9912422 [00:00<00:00, 121420489.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28881/28881 [00:00<00:00, 38627453.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1648877/1648877 [00:00<00:00, 32400370.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4542/4542 [00:00<00:00, 19700650.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "\n",
        "def prepare_dataset(num_partitions: int, batch_size: int):\n",
        "    # Define transforms\n",
        "    transforms = Compose([\n",
        "        ToTensor(),\n",
        "        Resize((64, 64))\n",
        "    ])\n",
        "\n",
        "    # Download MNIST dataset\n",
        "    trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transforms)\n",
        "    testset = datasets.MNIST(root='./data', train=False, download=True, transform=transforms)\n",
        "\n",
        "    # Filter the test set to only include label 2 using Subset\n",
        "    # indices = torch.tensor(testset.targets) == 2  # Láº¥y chá»‰ má»¥c cá»§a áº£nh sá»‘ 2\n",
        "    # testset = torch.utils.data.Subset(testset, indices.nonzero().squeeze(-1))\n",
        "\n",
        "    # Split the training set into `num_partitions` partitions\n",
        "    num_images = len(trainset) // num_partitions\n",
        "    partition_len = [num_images] * num_partitions\n",
        "    trainsets = random_split(trainset, partition_len)\n",
        "\n",
        "    # Create dataloaders for train set\n",
        "    trainloaders = []\n",
        "    for trainset_ in trainsets:\n",
        "        trainloaders.append(DataLoader(trainset_, batch_size=batch_size, shuffle=True))\n",
        "\n",
        "    # Dataloader for the test set\n",
        "    testloader = DataLoader(testset)\n",
        "\n",
        "    return trainloaders, testloader, trainset, testset\n",
        "\n",
        "# Usage\n",
        "NUM_CLIENTS = 30  # Number of clients\n",
        "BATCH_SIZE = 64   # Batch size for training and validation\n",
        "trainloader, testloader, trainset, testset = prepare_dataset(NUM_CLIENTS, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kiá»ƒm tra kÃ­ch thÆ°á»›c vÃ  sá»‘ lÆ°á»£ng batch trong testloader\n",
        "print(f\"Sá»‘ lÆ°á»£ng batch trong testloader: {len(testloader)}\")\n",
        "\n",
        "# Láº·p qua tá»«ng batch vÃ  in dá»¯ liá»‡u\n",
        "for idx, (images, labels) in enumerate(testloader):\n",
        "    print(f\"Batch {idx + 1}:\")\n",
        "    print(f\"KÃ­ch thÆ°á»›c cá»§a images trong batch: {images.size()}\")\n",
        "    print(f\"KÃ­ch thÆ°á»›c cá»§a labels trong batch: {labels.size()}\")\n",
        "    # In má»™t sá»‘ dá»¯ liá»‡u Ä‘á»ƒ kiá»ƒm tra cáº¥u trÃºc\n",
        "    print(f\"Má»™t sá»‘ dá»¯ liá»‡u Ä‘áº§u tiÃªn trong batch:\")\n",
        "    print(images[:5])  # In ra 5 máº«u dá»¯ liá»‡u Ä‘áº§u tiÃªn\n",
        "    print(labels[:5])  # In ra 5 nhÃ£n Ä‘áº§u tiÃªn\n",
        "    # Dá»«ng sau má»™t sá»‘ batch náº¿u báº¡n muá»‘n\n",
        "    if idx == 2:  # Dá»«ng sau 3 batch\n",
        "        break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJ5eqLQf1WjE",
        "outputId": "b7b02490-e6cf-4bed-98c6-8b0a2df5f591"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sá»‘ lÆ°á»£ng batch trong testloader: 10000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Batch 1:\n",
            "KÃ­ch thÆ°á»›c cá»§a images trong batch: torch.Size([1, 1, 64, 64])\n",
            "KÃ­ch thÆ°á»›c cá»§a labels trong batch: torch.Size([1])\n",
            "Má»™t sá»‘ dá»¯ liá»‡u Ä‘áº§u tiÃªn trong batch:\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
            "tensor([7])\n",
            "Batch 2:\n",
            "KÃ­ch thÆ°á»›c cá»§a images trong batch: torch.Size([1, 1, 64, 64])\n",
            "KÃ­ch thÆ°á»›c cá»§a labels trong batch: torch.Size([1])\n",
            "Má»™t sá»‘ dá»¯ liá»‡u Ä‘áº§u tiÃªn trong batch:\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
            "tensor([2])\n",
            "Batch 3:\n",
            "KÃ­ch thÆ°á»›c cá»§a images trong batch: torch.Size([1, 1, 64, 64])\n",
            "KÃ­ch thÆ°á»›c cá»§a labels trong batch: torch.Size([1])\n",
            "Má»™t sá»‘ dá»¯ liá»‡u Ä‘áº§u tiÃªn trong batch:\n",
            "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          ...,\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "          [0., 0., 0.,  ..., 0., 0., 0.]]]])\n",
            "tensor([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "EfQOV56-U6tx"
      },
      "outputs": [],
      "source": [
        "import flwr as fl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnKYb2sPU6tx"
      },
      "source": [
        "Now let's defice our Flower Client class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oXmlxsZ2U6tx"
      },
      "outputs": [],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Tuple\n",
        "import random\n",
        "from flwr.common import NDArrays, Scalar\n",
        "\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, trainloader, testloader) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.trainloader = trainloader\n",
        "        self.testloader = testloader\n",
        "        self.model = Net()\n",
        "        self.discriminator = Discriminator()\n",
        "        self.generator = Generator()\n",
        "        # Determine device\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)  # send model to device\n",
        "        self.discriminator.to(self.device)\n",
        "        self.generator.to(self.device)\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        \"\"\"With the model paramters received from the server,\n",
        "        overwrite the uninitialise model in this class with them.\"\"\"\n",
        "\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        # now replace the parameters\n",
        "        self.discriminator.load_state_dict(state_dict, strict=False)\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def get_parameters(self, config: Dict[str, Scalar]):\n",
        "        \"\"\"Extract all model parameters and conver them to a list of\n",
        "        NumPy arryas. The server doesn't work with PyTorch/TF/etc.\"\"\"\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        \"\"\"This method train the model using the parameters sent by the\n",
        "        server on the dataset of this client. At then end, the parameters\n",
        "        of the locally trained model are communicated back to the server\"\"\"\n",
        "\n",
        "        # copy parameters sent by the server into client's local model\n",
        "        self.set_parameters(parameters)\n",
        "        is_attacker = random.randint(1, 30) == 1\n",
        "        # is_attacker = 0\n",
        "        if is_attacker:\n",
        "            lr, epochs = config[\"attacker_lr\"], config[\"attacker_epochs\"]\n",
        "            poison_train(self.model, self.generator, self.discriminator, lr=lr, epochs=epochs, device=self.device)\n",
        "        else:\n",
        "            # read from config\n",
        "            lr, epochs = config[\"lr\"], config[\"epochs\"]\n",
        "            # do local training\n",
        "            train(self.model, self.trainloader, lr, epochs=epochs, device=self.device)\n",
        "\n",
        "        # return the model parameters to the server as well as extra info (number of training examples in this case)\n",
        "        return self.get_parameters({}), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "        \"\"\"Evaluate the model sent by the server on this client's\n",
        "        local validation set. Then return performance metrics.\"\"\"\n",
        "\n",
        "        self.set_parameters(parameters)\n",
        "        loss, accuracy = test(self.model, self.testloader, device=self.device)\n",
        "        # send statistics back to the server\n",
        "        return float(loss), len(self.testloader), {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUE9-1-UU6tx"
      },
      "source": [
        "Spend a few minutes to inspect the `FlowerClient` class above. Please ask questions if there is something unclear !\n",
        "\n",
        "Then keen-eyed among you might have realised that if we were to fuse the client's `fit()` and `evaluate()` methods, we'll end up with essentially the same as in the `run_centralised()` function we used in the Centralised Training part of this tutorial. And it is true!! In Federated Learning, the way clients perform local training makes use of the same principles as more traditional centralised setup. The key difference is that the dataset now is much smaller and it's never _\"seen\"_ by the entity running the FL workload (i.e. the central server).\n",
        "\n",
        "\n",
        "Talking about the central server... we should define what strategy we want to make use of so the updated models sent from the clients back to the server at the end of the `fit()` method are aggregate.\n",
        "\n",
        "\n",
        "## Choosing a Flower Strategy\n",
        "\n",
        "\n",
        "A strategy sits at the core of the Federated Learning experiment. It is involved in all stages of a FL pipeline: sampling clients; sending the _global model_ to the clients so they can do `fit()`; receive the updated models from the clients and **aggregate** these to construct a new _global model_; define and execute global or federated evaluation; and more.\n",
        "\n",
        "Flower comes with [many strategies built-in](https://github.com/adap/flower/tree/main/src/py/flwr/server/strategy) and more to be available in the next release (`1.5` already!). For this tutorial, let's use what is arguable the most popular strategy out there: `FedAvg`.\n",
        "\n",
        "The way `FedAvg` works is simple but performs surprisingly well in practice. It is therefore one good strategy to start your experimentation. `FedAvg`, as its name implies, derives a new version of the _global model_ by taking the average of all the models sent by clients participating in the round. You can read all the details [in the paper](https://arxiv.org/abs/1602.05629).\n",
        "\n",
        "Let's see how we can define `FedAvg` using Flower. We use one of the callbacks called `evaluate_fn` so we can easily evaluate the state of the global model using a small centralised testset. Note this functionality is user-defined since it requires a choice in terms of ML-framework. (if you recall, Flower is framework agnostic).\n",
        "\n",
        "> This being said, centralised evaluation of the global model is only possible if there exists a centralised dataset that somewhat follows a similar distribution as the data that's spread across clients. In some cases having such centralised dataset for validation is not possible, so the only solution is to federate the evaluation of the _global model_. This is the default behaviour in Flower. If you don't specify teh `evaluate_fn` argument in your strategy, then, centralised global evaluation won't be performed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "M4qIvPT-U6tx"
      },
      "outputs": [],
      "source": [
        "def get_evaluate_fn(testloader):\n",
        "    \"\"\"This is a function that returns a function. The returned\n",
        "    function (i.e. `evaluate_fn`) will be executed by the strategy\n",
        "    at the end of each round to evaluate the stat of the global\n",
        "    model.\"\"\"\n",
        "\n",
        "    def evaluate_fn(server_round: int, parameters, config):\n",
        "        \"\"\"This function is executed by the strategy it will instantiate\n",
        "        a model and replace its parameters with those from the global model.\n",
        "        The, the model will be evaluate on the test set (recall this is the\n",
        "        whole MNIST test set).\"\"\"\n",
        "\n",
        "        model = Net()\n",
        "\n",
        "        # Determine device\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)  # send model to device\n",
        "\n",
        "        # set parameters to the model\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "        # call test\n",
        "        loss, accuracy = test(model, testloader, device)\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate_fn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlDBSU3eU6tx"
      },
      "source": [
        "We could now define a strategy just as shown (commented) above. Instead, let's see how additional (but entirely optional) functionality can be easily added to our strategy. We are going to define two additional auxiliary functions to: (1) be able to configure how clients do local training; and (2) define a function to aggregate the metrics that clients return after running their `evaluate` methods:\n",
        "\n",
        "1. `fit_config()`. This is a function that will be executed inside the strategy when configuring a new `fit` round. This function is relatively simple and only requires as input argument the round at which the FL experiment is at. In this example we simply return a Python dictionary to specify the number of epochs and learning rate each client should made use of inside their `fit()` methods. A more versatile implementation would add more hyperparameters (e.g. the learning rate) and adjust them as the FL process advances (e.g. reducing the learning rate in later FL rounds).\n",
        "2. `weighted_average()`: This is an optional function to pass to the strategy. It will be executed after an evaluation round (i.e. when client run `evaluate()`) and will aggregate the metrics clients return. In this example, we use this function to compute the weighted average accuracy of clients doing `evaluate()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "qLro1MJ0U6tx"
      },
      "outputs": [],
      "source": [
        "from flwr.common import Metrics\n",
        "\n",
        "\n",
        "def fit_config(server_round: int) -> Dict[str, Scalar]:\n",
        "    \"\"\"Return a configuration with static batch size and (local) epochs.\"\"\"\n",
        "    config = {\n",
        "        \"epochs\": 10,  # Number of local epochs done by clients\n",
        "        \"lr\": 0.1,  # Learning rate to use by clients during fit()\n",
        "        \"attacker_epochs\": 20,\n",
        "        \"attacker_lr\": 0.05,\n",
        "    }\n",
        "    return config\n",
        "\n",
        "\n",
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n",
        "    the client's evaluate() method.\"\"\"\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SDKardSU6tx"
      },
      "source": [
        "Now we can define our strategy:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dbpajgBRU6ty"
      },
      "outputs": [],
      "source": [
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=0.34,  # Sample 10% of available clients for training\n",
        "    fraction_evaluate=0.34,  # Sample 5% of available clients for evaluation\n",
        "    on_fit_config_fn=fit_config,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  # aggregates federated metrics\n",
        "    evaluate_fn=get_evaluate_fn(testloader),  # global evaluation function\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_client_fn(trainloader, testloader):\n",
        "    \"\"\"Return a function to construct a client.\n",
        "\n",
        "    The VirtualClientEngine will execute this function whenever a client is sampled by\n",
        "    the strategy to participate.\n",
        "    \"\"\"\n",
        "\n",
        "    def client_fn(cid: str) -> fl.client.Client:\n",
        "        \"\"\"Construct a FlowerClient with its own dataset partition.\"\"\"\n",
        "        return FlowerClient(trainloader=trainloader[int(cid)], testloader=testloader)\n",
        "\n",
        "    return client_fn\n",
        "\n",
        "\n",
        "client_fn_callback = get_client_fn(trainloader, testloader)"
      ],
      "metadata": {
        "id": "yEKS3DuLoFG9"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4q-nk4LU6ty"
      },
      "source": [
        "So far we have:\n",
        "* created the dataset partitions (one for each client)\n",
        "* defined the client class\n",
        "* decided on a strategy to use\n",
        "\n",
        "Now we just need to launch the Flower FL experiment... not so fast! just one final function: let's create another callback that the Simulation Engine will use in order to span VirtualClients. As you can see this is really simple: construct a FlowerClient object, assigning each their own data partition."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0BQgJQ7U6ty"
      },
      "source": [
        "Now we are ready to launch the FL experiment using Flower simulation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "drd9s5QsU6ty",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e0cb002-f833-4f1f-c88d-6bcde9851e2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-22 05:04:35,690 | app.py:178 | Starting Flower simulation, config: ServerConfig(num_rounds=20, round_timeout=None)\n",
            "INFO:flwr:Starting Flower simulation, config: ServerConfig(num_rounds=20, round_timeout=None)\n",
            "2023-12-22 05:04:40,665\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "INFO flwr 2023-12-22 05:04:45,083 | app.py:213 | Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'object_store_memory': 3946092134.0, 'memory': 7892184270.0, 'CPU': 2.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'node:__internal_head__': 1.0, 'object_store_memory': 3946092134.0, 'memory': 7892184270.0, 'CPU': 2.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0}\n",
            "INFO flwr 2023-12-22 05:04:45,086 | app.py:219 | Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.dev/docs/framework/how-to-run-simulations.html\n",
            "INFO flwr 2023-12-22 05:04:45,097 | app.py:242 | Flower VCE: Resources for each Virtual Client: {'num_cpus': 0.2, 'num_gpus': 0.1}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 0.2, 'num_gpus': 0.1}\n",
            "INFO flwr 2023-12-22 05:04:45,200 | app.py:288 | Flower VCE: Creating VirtualClientEngineActorPool with 10 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 10 actors\n",
            "INFO flwr 2023-12-22 05:04:45,203 | server.py:89 | Initializing global parameters\n",
            "INFO:flwr:Initializing global parameters\n",
            "INFO flwr 2023-12-22 05:04:45,205 | server.py:276 | Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "2023-12-22 05:04:51,854\tWARNING worker.py:2037 -- WARNING: 8 PYTHON worker processes have been started on node: 24687efdade9750b387294cca96b5b69ec895396d0e7f79772e2299d with address: 172.28.0.12. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
            "\u001b[2m\u001b[36m(pid=740)\u001b[0m 2023-12-22 05:04:56.808900: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=740)\u001b[0m 2023-12-22 05:04:56.808959: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=740)\u001b[0m 2023-12-22 05:04:56.840063: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=740)\u001b[0m 2023-12-22 05:05:06.587760: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2m\u001b[36m(pid=911)\u001b[0m 2023-12-22 05:04:58.617222: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 9x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[2m\u001b[36m(pid=911)\u001b[0m 2023-12-22 05:04:58.617278: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(pid=911)\u001b[0m 2023-12-22 05:04:58.618783: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "INFO flwr 2023-12-22 05:05:27,009 | server.py:280 | Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "INFO flwr 2023-12-22 05:05:27,012 | server.py:91 | Evaluating initial parameters\n",
            "INFO:flwr:Evaluating initial parameters\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "INFO flwr 2023-12-22 05:05:42,131 | server.py:94 | initial parameters (loss, other metrics): 23025.712160348892, {'accuracy': 0.0}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 23025.712160348892, {'accuracy': 0.0}\n",
            "INFO flwr 2023-12-22 05:05:42,134 | server.py:104 | FL starting\n",
            "INFO:flwr:FL starting\n",
            "DEBUG flwr 2023-12-22 05:05:42,137 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 1: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(pid=911)\u001b[0m 2023-12-22 05:05:08.651913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m   warnings.warn(\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m /usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m   warnings.warn(\n",
            "DEBUG flwr 2023-12-22 05:07:02,478 | server.py:236 | fit_round 1 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 1 received 10 results and 0 failures\n",
            "WARNING flwr 2023-12-22 05:07:02,582 | fedavg.py:242 | No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n",
            "INFO flwr 2023-12-22 05:07:16,590 | server.py:125 | fit progress: (1, 23023.779514312744, {'accuracy': 0.0}, 94.453941128)\n",
            "INFO:flwr:fit progress: (1, 23023.779514312744, {'accuracy': 0.0}, 94.453941128)\n",
            "DEBUG flwr 2023-12-22 05:07:16,594 | server.py:173 | evaluate_round 1: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 1: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.00%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 05:09:41,273 | server.py:187 | evaluate_round 1 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 1 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 05:09:41,276 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 2: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 05:10:47,443 | server.py:236 | fit_round 2 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 2 received 10 results and 0 failures\n",
            "INFO flwr 2023-12-22 05:11:01,604 | server.py:125 | fit progress: (2, 23021.972744464874, {'accuracy': 0.0}, 319.46778720199995)\n",
            "INFO:flwr:fit progress: (2, 23021.972744464874, {'accuracy': 0.0}, 319.46778720199995)\n",
            "DEBUG flwr 2023-12-22 05:11:01,608 | server.py:173 | evaluate_round 2: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 2: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.00%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=869)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 05:13:23,309 | server.py:187 | evaluate_round 2 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 2 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 05:13:23,312 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 3: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m ############################## ATTACKER ##############################\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 05:26:07,034 | server.py:236 | fit_round 3 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 3 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m ############################## ATTACKER ##############################\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-22 05:26:21,100 | server.py:125 | fit progress: (3, 23020.29777431488, {'accuracy': 0.0}, 1238.963230269)\n",
            "INFO:flwr:fit progress: (3, 23020.29777431488, {'accuracy': 0.0}, 1238.963230269)\n",
            "DEBUG flwr 2023-12-22 05:26:21,103 | server.py:173 | evaluate_round 3: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 3: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.00%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 05:28:45,096 | server.py:187 | evaluate_round 3 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 3 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 05:28:45,100 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 4: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 05:29:50,247 | server.py:236 | fit_round 4 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 4 received 10 results and 0 failures\n",
            "INFO flwr 2023-12-22 05:30:04,372 | server.py:125 | fit progress: (4, 23017.50098323822, {'accuracy': 0.0}, 1462.235053053)\n",
            "INFO:flwr:fit progress: (4, 23017.50098323822, {'accuracy': 0.0}, 1462.235053053)\n",
            "DEBUG flwr 2023-12-22 05:30:04,375 | server.py:173 | evaluate_round 4: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 4: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.00%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 05:32:24,892 | server.py:187 | evaluate_round 4 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 4 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 05:32:24,895 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 5: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 05:39:00,921 | server.py:236 | fit_round 5 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 5 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m ############################## ATTACKER ##############################\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-22 05:39:15,106 | server.py:125 | fit progress: (5, 23012.50692486763, {'accuracy': 0.0}, 2012.969038742)\n",
            "INFO:flwr:fit progress: (5, 23012.50692486763, {'accuracy': 0.0}, 2012.969038742)\n",
            "DEBUG flwr 2023-12-22 05:39:15,109 | server.py:173 | evaluate_round 5: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 5: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.00%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 05:41:36,551 | server.py:187 | evaluate_round 5 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 5 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 05:41:36,555 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 6: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 05:42:45,356 | server.py:236 | fit_round 6 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 6 received 10 results and 0 failures\n",
            "INFO flwr 2023-12-22 05:42:59,594 | server.py:125 | fit progress: (6, 22992.69427204132, {'accuracy': 0.0}, 2237.45785333)\n",
            "INFO:flwr:fit progress: (6, 22992.69427204132, {'accuracy': 0.0}, 2237.45785333)\n",
            "DEBUG flwr 2023-12-22 05:42:59,598 | server.py:173 | evaluate_round 6: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 6: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.00%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=869)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m Accuracy cá»§a poisoned task: 0.00%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 05:45:22,765 | server.py:187 | evaluate_round 6 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 6 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 05:45:22,769 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 7: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 05:46:27,658 | server.py:236 | fit_round 7 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 7 received 10 results and 0 failures\n",
            "INFO flwr 2023-12-22 05:46:41,850 | server.py:125 | fit progress: (7, 18364.570195674896, {'accuracy': 0.9689922480620154}, 2459.713883622)\n",
            "INFO:flwr:fit progress: (7, 18364.570195674896, {'accuracy': 0.9689922480620154}, 2459.713883622)\n",
            "DEBUG flwr 2023-12-22 05:46:41,857 | server.py:173 | evaluate_round 7: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 7: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.97%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=869)\u001b[0m Accuracy cá»§a poisoned task: 0.97%\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=869)\u001b[0m Accuracy cá»§a poisoned task: 0.97%\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 05:49:05,067 | server.py:187 | evaluate_round 7 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 7 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 05:49:05,071 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 8: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 05:50:12,148 | server.py:236 | fit_round 8 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 8 received 10 results and 0 failures\n",
            "INFO flwr 2023-12-22 05:50:26,430 | server.py:125 | fit progress: (8, 16237.540479898453, {'accuracy': 1.2596899224806202}, 2684.293970526)\n",
            "INFO:flwr:fit progress: (8, 16237.540479898453, {'accuracy': 1.2596899224806202}, 2684.293970526)\n",
            "DEBUG flwr 2023-12-22 05:50:26,434 | server.py:173 | evaluate_round 8: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 8: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 1.26%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 1.26%\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=869)\u001b[0m Accuracy cá»§a poisoned task: 1.26%\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 1.26%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m Accuracy cá»§a poisoned task: 1.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 05:52:47,977 | server.py:187 | evaluate_round 8 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 8 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 05:52:47,983 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 9: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 05:53:52,951 | server.py:236 | fit_round 9 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 9 received 10 results and 0 failures\n",
            "INFO flwr 2023-12-22 05:54:07,126 | server.py:125 | fit progress: (9, 15986.660830020905, {'accuracy': 0.6782945736434108}, 2904.989277643)\n",
            "INFO:flwr:fit progress: (9, 15986.660830020905, {'accuracy': 0.6782945736434108}, 2904.989277643)\n",
            "DEBUG flwr 2023-12-22 05:54:07,129 | server.py:173 | evaluate_round 9: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 9: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.68%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m Accuracy cá»§a poisoned task: 0.68%\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=869)\u001b[0m Accuracy cá»§a poisoned task: 0.68%\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m Accuracy cá»§a poisoned task: 0.68%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m Accuracy cá»§a poisoned task: 0.68%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 05:56:33,376 | server.py:187 | evaluate_round 9 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 9 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 05:56:33,381 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 10: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 06:03:10,365 | server.py:236 | fit_round 10 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 10 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m ############################## ATTACKER ##############################\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 0.68%\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-22 06:03:24,766 | server.py:125 | fit progress: (10, 15909.933770418167, {'accuracy': 1.3565891472868217}, 3462.629220363)\n",
            "INFO:flwr:fit progress: (10, 15909.933770418167, {'accuracy': 1.3565891472868217}, 3462.629220363)\n",
            "DEBUG flwr 2023-12-22 06:03:24,773 | server.py:173 | evaluate_round 10: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 10: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 1.36%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m Accuracy cá»§a poisoned task: 1.36%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m Accuracy cá»§a poisoned task: 1.36%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 1.36%\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m Accuracy cá»§a poisoned task: 1.36%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 1.36%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 06:05:51,610 | server.py:187 | evaluate_round 10 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 10 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 06:05:51,613 | server.py:222 | fit_round 11: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 11: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 06:12:11,496 | server.py:236 | fit_round 11 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 11 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m ############################## ATTACKER ##############################\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m Accuracy cá»§a poisoned task: 1.36%\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-22 06:12:25,929 | server.py:125 | fit progress: (11, 15845.36831009388, {'accuracy': 1.2596899224806202}, 4003.792499338)\n",
            "INFO:flwr:fit progress: (11, 15845.36831009388, {'accuracy': 1.2596899224806202}, 4003.792499338)\n",
            "DEBUG flwr 2023-12-22 06:12:25,933 | server.py:173 | evaluate_round 11: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 11: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 1.26%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 1.26%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m Accuracy cá»§a poisoned task: 1.26%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 1.26%\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m Accuracy cá»§a poisoned task: 1.26%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=869)\u001b[0m Accuracy cá»§a poisoned task: 1.26%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 06:14:51,196 | server.py:187 | evaluate_round 11 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 11 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 06:14:51,199 | server.py:222 | fit_round 12: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 12: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 06:21:06,772 | server.py:236 | fit_round 12 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 12 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m ############################## ATTACKER ##############################\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 1.26%\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-22 06:21:20,987 | server.py:125 | fit progress: (12, 15814.67673587799, {'accuracy': 1.1627906976744187}, 4538.850910528)\n",
            "INFO:flwr:fit progress: (12, 15814.67673587799, {'accuracy': 1.1627906976744187}, 4538.850910528)\n",
            "DEBUG flwr 2023-12-22 06:21:20,996 | server.py:173 | evaluate_round 12: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 12: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 1.16%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m Accuracy cá»§a poisoned task: 1.16%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m Accuracy cá»§a poisoned task: 1.16%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 1.16%\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m Accuracy cá»§a poisoned task: 1.16%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m Accuracy cá»§a poisoned task: 1.16%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 06:23:45,141 | server.py:187 | evaluate_round 12 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 12 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 06:23:45,144 | server.py:222 | fit_round 13: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 13: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 06:24:52,692 | server.py:236 | fit_round 13 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 13 received 10 results and 0 failures\n",
            "INFO flwr 2023-12-22 06:25:06,986 | server.py:125 | fit progress: (13, 15773.367291927338, {'accuracy': 0.872093023255814}, 4764.849374547)\n",
            "INFO:flwr:fit progress: (13, 15773.367291927338, {'accuracy': 0.872093023255814}, 4764.849374547)\n",
            "DEBUG flwr 2023-12-22 06:25:06,991 | server.py:173 | evaluate_round 13: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 13: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.87%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m Accuracy cá»§a poisoned task: 0.87%\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=869)\u001b[0m Accuracy cá»§a poisoned task: 0.87%\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 0.87%\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m Accuracy cá»§a poisoned task: 0.87%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 0.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 06:27:34,928 | server.py:187 | evaluate_round 13 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 13 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 06:27:34,932 | server.py:222 | fit_round 14: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 14: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 06:28:41,276 | server.py:236 | fit_round 14 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 14 received 10 results and 0 failures\n",
            "INFO flwr 2023-12-22 06:28:55,508 | server.py:125 | fit progress: (14, 15756.638652682304, {'accuracy': 0.3875968992248062}, 4993.371674743)\n",
            "INFO:flwr:fit progress: (14, 15756.638652682304, {'accuracy': 0.3875968992248062}, 4993.371674743)\n",
            "DEBUG flwr 2023-12-22 06:28:55,511 | server.py:173 | evaluate_round 14: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 14: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.39%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 0.39%\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m Accuracy cá»§a poisoned task: 0.39%\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m Accuracy cá»§a poisoned task: 0.39%\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 06:31:19,031 | server.py:187 | evaluate_round 14 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 14 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 06:31:19,035 | server.py:222 | fit_round 15: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 15: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 06:32:25,349 | server.py:236 | fit_round 15 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 15 received 10 results and 0 failures\n",
            "INFO flwr 2023-12-22 06:32:39,520 | server.py:125 | fit progress: (15, 15724.423939466476, {'accuracy': 0.4844961240310077}, 5217.383071112)\n",
            "INFO:flwr:fit progress: (15, 15724.423939466476, {'accuracy': 0.4844961240310077}, 5217.383071112)\n",
            "DEBUG flwr 2023-12-22 06:32:39,523 | server.py:173 | evaluate_round 15: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 15: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.48%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m Accuracy cá»§a poisoned task: 0.48%\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 0.48%\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m Accuracy cá»§a poisoned task: 0.48%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 0.48%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 06:35:08,461 | server.py:187 | evaluate_round 15 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 15 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 06:35:08,465 | server.py:222 | fit_round 16: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 16: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 06:36:14,417 | server.py:236 | fit_round 16 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 16 received 10 results and 0 failures\n",
            "INFO flwr 2023-12-22 06:36:28,792 | server.py:125 | fit progress: (16, 15714.485391139984, {'accuracy': 0.29069767441860467}, 5446.655994927)\n",
            "INFO:flwr:fit progress: (16, 15714.485391139984, {'accuracy': 0.29069767441860467}, 5446.655994927)\n",
            "DEBUG flwr 2023-12-22 06:36:28,796 | server.py:173 | evaluate_round 16: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 16: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.29%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 0.29%\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 0.29%\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 0.29%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m Accuracy cá»§a poisoned task: 0.29%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 06:38:52,350 | server.py:187 | evaluate_round 16 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 16 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 06:38:52,353 | server.py:222 | fit_round 17: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 17: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 06:39:57,746 | server.py:236 | fit_round 17 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 17 received 10 results and 0 failures\n",
            "INFO flwr 2023-12-22 06:40:12,012 | server.py:125 | fit progress: (17, 15699.110813498497, {'accuracy': 0.09689922480620156}, 5669.8759310469995)\n",
            "INFO:flwr:fit progress: (17, 15699.110813498497, {'accuracy': 0.09689922480620156}, 5669.8759310469995)\n",
            "DEBUG flwr 2023-12-22 06:40:12,016 | server.py:173 | evaluate_round 17: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 17: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.10%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m Accuracy cá»§a poisoned task: 0.10%\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m Accuracy cá»§a poisoned task: 0.10%\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m Accuracy cá»§a poisoned task: 0.10%\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 06:42:38,394 | server.py:187 | evaluate_round 17 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 17 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 06:42:38,398 | server.py:222 | fit_round 18: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 18: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 06:43:44,306 | server.py:236 | fit_round 18 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 18 received 10 results and 0 failures\n",
            "INFO flwr 2023-12-22 06:43:58,620 | server.py:125 | fit progress: (18, 15688.053288578987, {'accuracy': 0.09689922480620156}, 5896.483264664)\n",
            "INFO:flwr:fit progress: (18, 15688.053288578987, {'accuracy': 0.09689922480620156}, 5896.483264664)\n",
            "DEBUG flwr 2023-12-22 06:43:58,623 | server.py:173 | evaluate_round 18: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 18: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.10%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 0.10%\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=926)\u001b[0m Accuracy cá»§a poisoned task: 0.10%\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 0.10%\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 0.10%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m Accuracy cá»§a poisoned task: 0.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 06:46:24,029 | server.py:187 | evaluate_round 18 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 18 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 06:46:24,033 | server.py:222 | fit_round 19: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 19: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 06:47:30,639 | server.py:236 | fit_round 19 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 19 received 10 results and 0 failures\n",
            "INFO flwr 2023-12-22 06:47:44,868 | server.py:125 | fit progress: (19, 15683.808449029922, {'accuracy': 0.09689922480620156}, 6122.73133068)\n",
            "INFO:flwr:fit progress: (19, 15683.808449029922, {'accuracy': 0.09689922480620156}, 6122.73133068)\n",
            "DEBUG flwr 2023-12-22 06:47:44,872 | server.py:173 | evaluate_round 19: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 19: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.10%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 0.10%\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m Accuracy cá»§a poisoned task: 0.10%\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=911)\u001b[0m Accuracy cá»§a poisoned task: 0.10%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m Accuracy cá»§a poisoned task: 0.10%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 06:50:12,531 | server.py:187 | evaluate_round 19 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 19 received 10 results and 0 failures\n",
            "DEBUG flwr 2023-12-22 06:50:12,534 | server.py:222 | fit_round 20: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:fit_round 20: strategy sampled 10 clients (out of 30)\n",
            "DEBUG flwr 2023-12-22 06:56:45,952 | server.py:236 | fit_round 20 received 10 results and 0 failures\n",
            "DEBUG:flwr:fit_round 20 received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(DefaultActor pid=869)\u001b[0m ############################## ATTACKER ##############################\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=869)\u001b[0m Accuracy cá»§a poisoned task: 0.10%\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO flwr 2023-12-22 06:57:00,090 | server.py:125 | fit progress: (20, 15668.451437473297, {'accuracy': 0.1937984496124031}, 6677.953937757)\n",
            "INFO:flwr:fit progress: (20, 15668.451437473297, {'accuracy': 0.1937984496124031}, 6677.953937757)\n",
            "DEBUG flwr 2023-12-22 06:57:00,094 | server.py:173 | evaluate_round 20: strategy sampled 10 clients (out of 30)\n",
            "DEBUG:flwr:evaluate_round 20: strategy sampled 10 clients (out of 30)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy cá»§a poisoned task: 0.19%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 0.19%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=885)\u001b[0m Accuracy cá»§a poisoned task: 0.19%\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=842)\u001b[0m Accuracy cá»§a poisoned task: 0.19%\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(DefaultActor pid=827)\u001b[0m Accuracy cá»§a poisoned task: 0.19%\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "DEBUG flwr 2023-12-22 06:59:27,073 | server.py:187 | evaluate_round 20 received 10 results and 0 failures\n",
            "DEBUG:flwr:evaluate_round 20 received 10 results and 0 failures\n",
            "INFO flwr 2023-12-22 06:59:27,076 | server.py:153 | FL finished in 6824.939813689\n",
            "INFO:flwr:FL finished in 6824.939813689\n",
            "INFO flwr 2023-12-22 06:59:27,088 | app.py:226 | app_fit: losses_distributed [(1, 23023.779514312744), (2, 23021.972744464874), (3, 23020.29777431488), (4, 23017.50098323822), (5, 23012.50692486763), (6, 22992.69427204132), (7, 18364.570195674896), (8, 16237.540479898453), (9, 15986.660830020905), (10, 15909.933770418167), (11, 15845.36831009388), (12, 15814.67673587799), (13, 15773.367291927338), (14, 15756.638652682304), (15, 15724.423939466476), (16, 15714.485391139984), (17, 15699.110813498497), (18, 15688.053288578987), (19, 15683.808449029922), (20, 15668.451437473297)]\n",
            "INFO:flwr:app_fit: losses_distributed [(1, 23023.779514312744), (2, 23021.972744464874), (3, 23020.29777431488), (4, 23017.50098323822), (5, 23012.50692486763), (6, 22992.69427204132), (7, 18364.570195674896), (8, 16237.540479898453), (9, 15986.660830020905), (10, 15909.933770418167), (11, 15845.36831009388), (12, 15814.67673587799), (13, 15773.367291927338), (14, 15756.638652682304), (15, 15724.423939466476), (16, 15714.485391139984), (17, 15699.110813498497), (18, 15688.053288578987), (19, 15683.808449029922), (20, 15668.451437473297)]\n",
            "INFO flwr 2023-12-22 06:59:27,095 | app.py:227 | app_fit: metrics_distributed_fit {}\n",
            "INFO:flwr:app_fit: metrics_distributed_fit {}\n",
            "INFO flwr 2023-12-22 06:59:27,097 | app.py:228 | app_fit: metrics_distributed {'accuracy': [(1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.9689922480620154), (8, 1.25968992248062), (9, 0.6782945736434108), (10, 1.3565891472868217), (11, 1.25968992248062), (12, 1.1627906976744184), (13, 0.872093023255814), (14, 0.38759689922480617), (15, 0.4844961240310077), (16, 0.2906976744186046), (17, 0.09689922480620154), (18, 0.09689922480620154), (19, 0.09689922480620154), (20, 0.19379844961240308)]}\n",
            "INFO:flwr:app_fit: metrics_distributed {'accuracy': [(1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.9689922480620154), (8, 1.25968992248062), (9, 0.6782945736434108), (10, 1.3565891472868217), (11, 1.25968992248062), (12, 1.1627906976744184), (13, 0.872093023255814), (14, 0.38759689922480617), (15, 0.4844961240310077), (16, 0.2906976744186046), (17, 0.09689922480620154), (18, 0.09689922480620154), (19, 0.09689922480620154), (20, 0.19379844961240308)]}\n",
            "INFO flwr 2023-12-22 06:59:27,099 | app.py:229 | app_fit: losses_centralized [(0, 23025.712160348892), (1, 23023.779514312744), (2, 23021.972744464874), (3, 23020.29777431488), (4, 23017.50098323822), (5, 23012.50692486763), (6, 22992.69427204132), (7, 18364.570195674896), (8, 16237.540479898453), (9, 15986.660830020905), (10, 15909.933770418167), (11, 15845.36831009388), (12, 15814.67673587799), (13, 15773.367291927338), (14, 15756.638652682304), (15, 15724.423939466476), (16, 15714.485391139984), (17, 15699.110813498497), (18, 15688.053288578987), (19, 15683.808449029922), (20, 15668.451437473297)]\n",
            "INFO:flwr:app_fit: losses_centralized [(0, 23025.712160348892), (1, 23023.779514312744), (2, 23021.972744464874), (3, 23020.29777431488), (4, 23017.50098323822), (5, 23012.50692486763), (6, 22992.69427204132), (7, 18364.570195674896), (8, 16237.540479898453), (9, 15986.660830020905), (10, 15909.933770418167), (11, 15845.36831009388), (12, 15814.67673587799), (13, 15773.367291927338), (14, 15756.638652682304), (15, 15724.423939466476), (16, 15714.485391139984), (17, 15699.110813498497), (18, 15688.053288578987), (19, 15683.808449029922), (20, 15668.451437473297)]\n",
            "INFO flwr 2023-12-22 06:59:27,100 | app.py:230 | app_fit: metrics_centralized {'accuracy': [(0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.9689922480620154), (8, 1.2596899224806202), (9, 0.6782945736434108), (10, 1.3565891472868217), (11, 1.2596899224806202), (12, 1.1627906976744187), (13, 0.872093023255814), (14, 0.3875968992248062), (15, 0.4844961240310077), (16, 0.29069767441860467), (17, 0.09689922480620156), (18, 0.09689922480620156), (19, 0.09689922480620156), (20, 0.1937984496124031)]}\n",
            "INFO:flwr:app_fit: metrics_centralized {'accuracy': [(0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.9689922480620154), (8, 1.2596899224806202), (9, 0.6782945736434108), (10, 1.3565891472868217), (11, 1.2596899224806202), (12, 1.1627906976744187), (13, 0.872093023255814), (14, 0.3875968992248062), (15, 0.4844961240310077), (16, 0.29069767441860467), (17, 0.09689922480620156), (18, 0.09689922480620156), (19, 0.09689922480620156), (20, 0.1937984496124031)]}\n"
          ]
        }
      ],
      "source": [
        "from datasets.utils.logging import disable_progress_bar\n",
        "# With a dictionary, you tell Flower's VirtualClientEngine that each\n",
        "# client needs exclusive access to these many resources in order to run\n",
        "client_resources = {\"num_cpus\": 0.2, \"num_gpus\": 0.1}\n",
        "\n",
        "# Let's disable tqdm progress bar in the main thread (used by the server)\n",
        "disable_progress_bar()\n",
        "\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn_callback,  # a callback to construct a client\n",
        "    num_clients=NUM_CLIENTS,  # total number of clients in the experiment\n",
        "    config=fl.server.ServerConfig(num_rounds=20),  # let's run for 10 rounds\n",
        "    strategy=strategy,  # the strategy that will orchestrate the whole FL pipeline\n",
        "    client_resources=client_resources,\n",
        "    actor_kwargs={\n",
        "        \"on_actor_init_fn\": disable_progress_bar  # disable tqdm on each actor/process spawning virtual clients\n",
        "    },\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daEugtD4U6ty"
      },
      "source": [
        "Doing 10 rounds should take less than 2 minutes on a CPU-only Colab instance <-- Flower Simulation is fast! ğŸš€\n",
        "\n",
        "You can then use the resturned `History` object to either save the results to disk or do some visualisation (or both of course, or neither if you like chaos). Below you can see how you can plot the centralised accuracy obtainined at the end of each round (including at the very beginning of the experiment) for the _global model_. This is want the function `evaluate_fn()` that we passed to the strategy reports."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "zjF9BiGVU6ty",
        "outputId": "6af81221-d7d7-4210-c5bb-e7ac160093cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "history.metrics_centralized = {'accuracy': [(0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0), (4, 0.0), (5, 0.0), (6, 0.0), (7, 0.9689922480620154), (8, 1.2596899224806202), (9, 0.6782945736434108), (10, 1.3565891472868217), (11, 1.2596899224806202), (12, 1.1627906976744187), (13, 0.872093023255814), (14, 0.3875968992248062), (15, 0.4844961240310077), (16, 0.29069767441860467), (17, 0.09689922480620156), (18, 0.09689922480620156), (19, 0.09689922480620156), (20, 0.1937984496124031)]}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'MNIST - IID - 100 clients with 10 clients per round')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"{history.metrics_centralized = }\")\n",
        "\n",
        "global_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\n",
        "round = [data[0] for data in global_accuracy_centralised]\n",
        "acc = [100.0 * data[1] for data in global_accuracy_centralised]\n",
        "plt.plot(round, acc)\n",
        "plt.grid()\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.title(\"MNIST - IID - 100 clients with 10 clients per round\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4Ve2MZ3U6ty"
      },
      "source": [
        "Congratulations! With that, you built a Flower client, customized it's instantiation through the `client_fn`, customized the server-side execution through a `FedAvg` strategy configured for this workload, and started a simulation with 100 clients (each holding their own individual partition of the MNIST dataset).\n",
        "\n",
        "Next, you can continue to explore more advanced Flower topics:\n",
        "\n",
        "- Deploy server and clients on different machines using `start_server` and `start_client`\n",
        "- Customize the server-side execution through custom strategies\n",
        "- Customize the client-side execution through `config` dictionaries\n",
        "\n",
        "Get all resources you need!\n",
        "\n",
        "* **[DOCS]** Our complete documenation: https://flower.dev/docs/\n",
        "* **[Examples]** All Flower examples: https://flower.dev/docs/examples/\n",
        "* **[VIDEO]** Our Youtube channel: https://www.youtube.com/@flowerlabs\n",
        "\n",
        "Don't forget to join our Slack channel: https://flower.dev/join-slack/\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}