{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8416203,"sourceType":"datasetVersion","datasetId":4995337,"isSourceIdPinned":false},{"sourceId":46625,"sourceType":"modelInstanceVersion","modelInstanceId":38903}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/longchung1/sim-loss?scriptVersionId=178481085\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# depending on your shell, you might need to add `\\` before `[` and `]`.\n!pip install -q flwr[simulation]\n!pip install flwr_datasets[vision]\n!pip install matplotlib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-19T05:04:36.833437Z","iopub.execute_input":"2024-05-19T05:04:36.833803Z","iopub.status.idle":"2024-05-19T05:05:32.301937Z","shell.execute_reply.started":"2024-05-19T05:04:36.833772Z","shell.execute_reply":"2024-05-19T05:05:32.300845Z"},"trusted":true},"execution_count":177,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Error parsing requirements for cryptography: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/cryptography-41.0.7.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m\u001b[33m    WARNING: No metadata found in /opt/conda/lib/python3.10/site-packages\u001b[0m\u001b[33m\n\u001b[0m\u001b[31mERROR: Cannot uninstall cryptography 41.0.7, RECORD file not found. You might be able to recover from this via: 'pip install --force-reinstall --no-deps cryptography==41.0.7'.\u001b[0m\u001b[31m\n\u001b[0mRequirement already satisfied: flwr_datasets[vision] in /opt/conda/lib/python3.10/site-packages (0.1.0)\nRequirement already satisfied: datasets<3.0.0,>=2.14.3 in /opt/conda/lib/python3.10/site-packages (from flwr_datasets[vision]) (2.18.0)\nRequirement already satisfied: numpy<2.0.0,>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from flwr_datasets[vision]) (1.26.4)\nRequirement already satisfied: pillow>=6.2.1 in /opt/conda/lib/python3.10/site-packages (from flwr_datasets[vision]) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.16.0)\n\u001b[33mWARNING: Error parsing requirements for cryptography: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/cryptography-41.0.7.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n\u001b[33mWARNING: Error parsing requirements for cryptography: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/cryptography-41.0.7.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"import flwr as fl","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:05:32.304724Z","iopub.execute_input":"2024-05-19T05:05:32.305203Z","iopub.status.idle":"2024-05-19T05:05:32.310723Z","shell.execute_reply.started":"2024-05-19T05:05:32.305153Z","shell.execute_reply":"2024-05-19T05:05:32.309697Z"},"trusted":true},"execution_count":178,"outputs":[]},{"cell_type":"code","source":"from flwr_datasets import FederatedDataset\nfrom flwr.server.client_proxy import ClientProxy\nfrom flwr.common import NDArrays, Scalar, Parameters\nfrom flwr.common import Metrics, FitRes","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:05:32.312104Z","iopub.execute_input":"2024-05-19T05:05:32.312395Z","iopub.status.idle":"2024-05-19T05:05:32.323226Z","shell.execute_reply.started":"2024-05-19T05:05:32.31236Z","shell.execute_reply":"2024-05-19T05:05:32.322259Z"},"trusted":true},"execution_count":179,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\nfrom datasets.utils.logging import disable_progress_bar\nfrom torch.utils.data import TensorDataset\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nimport torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\nfrom torchvision.transforms import ToTensor, Normalize, Compose, Resize\nimport matplotlib.pyplot as plt\nimport random\nimport numpy as np\nimport os\nimport glob\nfrom collections import OrderedDict\nimport shutil\nfrom typing import Callable, Dict, List, Optional, Tuple, Union\nfrom functools import reduce\nfrom flwr.common import FitRes, NDArray, NDArrays, Parameters, ndarrays_to_parameters, parameters_to_ndarrays\nfrom flwr.server.strategy import aggregate","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:05:32.326182Z","iopub.execute_input":"2024-05-19T05:05:32.326852Z","iopub.status.idle":"2024-05-19T05:05:32.336632Z","shell.execute_reply.started":"2024-05-19T05:05:32.32682Z","shell.execute_reply":"2024-05-19T05:05:32.335514Z"},"trusted":true},"execution_count":180,"outputs":[]},{"cell_type":"code","source":"# Let's set a simulation involving a total of 100 clients\nNUM_CLIENTS = 33\n\n# Download MNIST dataset and partition the \"train\" partition (so one can be assigned to each client)\nmnist_fds = FederatedDataset(dataset=\"mnist\", partitioners={\"train\": NUM_CLIENTS})\n# Let's keep the test set as is, and use it to evaluate the global model on the server\ncentralized_testset = mnist_fds.load_split(\"test\")\npartition = mnist_fds.load_partition(0, \"train\")\npartition.features","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:05:32.338364Z","iopub.execute_input":"2024-05-19T05:05:32.338726Z","iopub.status.idle":"2024-05-19T05:05:33.712094Z","shell.execute_reply.started":"2024-05-19T05:05:32.338699Z","shell.execute_reply":"2024-05-19T05:05:33.711117Z"},"trusted":true},"execution_count":181,"outputs":[{"execution_count":181,"output_type":"execute_result","data":{"text/plain":"{'image': Image(decode=True, id=None),\n 'label': ClassLabel(names=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], id=None)}"},"metadata":{}}]},{"cell_type":"code","source":"def calculate_label_distribution(data_loaders):\n    label_counts = {}\n    for loader in data_loaders:\n        images = loader[\"image\"]\n        labels = [loader[\"label\"]]\n        for label in labels:\n            label = int(label)\n            if label in label_counts:\n                label_counts[label] += 1\n            else:\n                label_counts[label] = 1\n    return label_counts\n\ndef plot_label_distribution(label_counts):\n    # Vẽ biểu đồ histogram\n    plt.bar(label_counts.keys(), label_counts.values())\n    plt.xlabel('Label')\n    plt.ylabel('Number of Images')\n    plt.title('Distribution of Labels in the Dataset')\n    plt.xticks(range(10))\n    plt.show()\n    # Tính toán phân phối nhãn từ tất cả các dataloader\nall_trainloaders = partition # Gộp tất cả các dataloader lại\nall_label_counts = calculate_label_distribution(all_trainloaders)\n\n# Vẽ biểu đồ tương quan giữa tất cả các dataloader\nplot_label_distribution(all_label_counts)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:05:33.713313Z","iopub.execute_input":"2024-05-19T05:05:33.7136Z","iopub.status.idle":"2024-05-19T05:05:34.428365Z","shell.execute_reply.started":"2024-05-19T05:05:33.713575Z","shell.execute_reply":"2024-05-19T05:05:34.427254Z"},"trusted":true},"execution_count":182,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABHZElEQVR4nO3deVxU9eL/8feAssgqKiCpqGju+75maZKa1XVJzcot9RZuUGlkaVqKWZm5pNW3tCzTNJeuXfc195VccsPcUtHKAMFEgfP7o4fza2KRwcGBc1/Px+M8cj7nM2feM0C8OcuMxTAMQwAAACbl4uwAAAAA+YmyAwAATI2yAwAATI2yAwAATI2yAwAATI2yAwAATI2yAwAATI2yAwAATI2yAwAATI2yA1N44403ZLFY7sljtWnTRm3atLHe3rRpkywWixYvXnxPHr9v374qX778PXmsvEpOTtZzzz2n4OBgWSwWjRgx4p48bt++feXt7e3Qbf7z651XZ86ckcVi0dy5c+96W3cyd+5cWSwW7d27N98fCygMKDsocG7/j/r24uHhoZCQEIWHh2vatGm6du2aQx7n4sWLeuONNxQbG+uQ7TlSQc6WGxMnTtTcuXP1/PPPa968eXrmmWeynVu+fHk9+uij9zCdeXz44Yf3pDxl53bRv724u7srKChIbdq00cSJE/Xrr7/meds//fST3njjDZ05c8Zxge/C/PnzNXXqVGfHQB4VcXYAIDvjx49XhQoVdOvWLcXHx2vTpk0aMWKEpkyZou+++061a9e2zn3ttdf0yiuv2LX9ixcvaty4cSpfvrzq1q2b6/utWbPGrsfJi5yyffLJJ8rIyMj3DHdjw4YNatq0qcaOHevsKAVGaGio/vzzTxUtWtRh2/zwww9VsmRJ9e3b12HbzIthw4apUaNGSk9P16+//qrt27dr7NixmjJlir755hs99NBDdm/zp59+0rhx49SmTZsCsSdz/vz5Onz48D3bSwnHouygwOrQoYMaNmxovR0dHa0NGzbo0Ucf1WOPPaajR4/K09NTklSkSBEVKZK/387Xr19XsWLF5Obmlq+PcyeO/GWZX65cuaLq1as7O0aBcnsvpRm1atVK3bp1sxn78ccf1b59e3Xt2lU//fSTSpcu7aR0AIexUMg89NBDev3113X27Fl9+eWX1vGsztlZu3atWrZsKX9/f3l7e6tKlSp69dVXJf21+71Ro0aSpH79+ll3w98+JNCmTRvVrFlT+/btU+vWrVWsWDHrfbM7hyM9PV2vvvqqgoOD5eXlpccee0znz5+3mVO+fPks/wr/+zbvlC2rc3ZSUlL04osvqmzZsnJ3d1eVKlX07rvvyjAMm3kWi0VDhgzRsmXLVLNmTbm7u6tGjRpatWpV1i/4P1y5ckUDBgxQUFCQPDw8VKdOHX3++efW9bcPa5w+fVrff/+9NfvdHor44Ycf1L17d5UrV07u7u4qW7asIiMj9eeff2Y5/+eff1Z4eLi8vLwUEhKi8ePHZ3otMjIyNHXqVNWoUUMeHh4KCgrS4MGD9ccff9wxz/Tp01WjRg0VK1ZMxYsXV8OGDTV//vwc75PVOTu3zzG6cOGCnnjiCXl7e6tUqVJ66aWXlJ6enuP2ypcvryNHjmjz5s3W1/mf35epqamKiopSqVKl5OXlpX/9619ZHlpauXKlWrVqJS8vL/n4+KhTp046cuTIHV+HnNSpU0dTp05VQkKCZsyYYR0/e/asXnjhBVWpUkWenp4qUaKEunfvbvM9MnfuXHXv3l2S9OCDD1qf36ZNmyRJy5cvV6dOnRQSEiJ3d3eFhYXpzTffzPSanTx5Ul27dlVwcLA8PDxUpkwZ9ezZU4mJiTbzvvzySzVo0ECenp4KCAhQz549bX5227Rpo++//15nz561ZikIe5uQe+zZQaHzzDPP6NVXX9WaNWs0cODALOccOXJEjz76qGrXrq3x48fL3d1dcXFx2rZtmySpWrVqGj9+vMaMGaNBgwapVatWkqTmzZtbt/H777+rQ4cO6tmzp55++mkFBQXlmGvChAmyWCwaNWqUrly5oqlTp6pdu3aKjY217oHKjdxk+zvDMPTYY49p48aNGjBggOrWravVq1fr5Zdf1oULF/T+++/bzN+6dauWLFmiF154QT4+Ppo2bZq6du2qc+fOqUSJEtnm+vPPP9WmTRvFxcVpyJAhqlChghYtWqS+ffsqISFBw4cPV7Vq1TRv3jxFRkaqTJkyevHFFyVJpUqVyvXzz8qiRYt0/fp1Pf/88ypRooR2796t6dOn65dfftGiRYts5qanp+uRRx5R06ZNNXnyZK1atUpjx45VWlqaxo8fb503ePBgzZ07V/369dOwYcN0+vRpzZgxQwcOHNC2bduy3YP2ySefaNiwYerWrZuGDx+uGzdu6ODBg9q1a5eeeuopu59benq6wsPD1aRJE7377rtat26d3nvvPYWFhen555/P9n5Tp07V0KFD5e3trdGjR0tSpu/RoUOHqnjx4ho7dqzOnDmjqVOnasiQIVq4cKF1zrx589SnTx+Fh4fr7bff1vXr1zVr1iy1bNlSBw4cuKtf6t26ddOAAQO0Zs0aTZgwQZK0Z88ebd++XT179lSZMmV05swZzZo1S23atNFPP/2kYsWKqXXr1ho2bJimTZumV199VdWqVZMk63/nzp0rb29vRUVFydvbWxs2bNCYMWOUlJSkd955R5J08+ZNhYeHKzU1VUOHDlVwcLAuXLigFStWKCEhQX5+fpL++rl9/fXX9eSTT+q5557Tr7/+qunTp6t169Y6cOCA/P39NXr0aCUmJuqXX36x/jw5+kR45DMDKGDmzJljSDL27NmT7Rw/Pz+jXr161ttjx441/v7t/P777xuSjF9//TXbbezZs8eQZMyZMyfTugceeMCQZMyePTvLdQ888ID19saNGw1Jxn333WckJSVZx7/55htDkvHBBx9Yx0JDQ40+ffrccZs5ZevTp48RGhpqvb1s2TJDkvHWW2/ZzOvWrZthsViMuLg465gkw83NzWbsxx9/NCQZ06dPz/RYfzd16lRDkvHll19ax27evGk0a9bM8Pb2tnnuoaGhRqdOnXLcnj1zr1+/nmksJibGsFgsxtmzZ61jffr0MSQZQ4cOtY5lZGQYnTp1Mtzc3KzfDz/88IMhyfjqq69strlq1apM4//82jz++ONGjRo1cvXc/u706dOZvqa3844fP95mbr169YwGDRrccZs1atSwyXbb7Z+hdu3aGRkZGdbxyMhIw9XV1UhISDAMwzCuXbtm+Pv7GwMHDrS5f3x8vOHn55dp/J9uf+8vWrQo2zl16tQxihcvbr2d1ddyx44dhiTjiy++sI4tWrTIkGRs3Lgx0/ystjF48GCjWLFixo0bNwzDMIwDBw7cMduZM2cMV1dXY8KECTbjhw4dMooUKWIz3qlTJ5ufOxQuHMZCoeTt7Z3jVVn+/v6S/trdndeTed3d3dWvX79cz3/22Wfl4+Njvd2tWzeVLl1a//3vf/P0+Ln13//+V66urho2bJjN+IsvvijDMLRy5Uqb8Xbt2iksLMx6u3bt2vL19dXPP/98x8cJDg5Wr169rGNFixbVsGHDlJycrM2bNzvg2WTt73vGUlJS9Ntvv6l58+YyDEMHDhzINH/IkCHWf98+dHfz5k2tW7dO0l97ivz8/PTwww/rt99+sy4NGjSQt7e3Nm7cmG0Wf39//fLLL9qzZ4/Dnt+///1vm9utWrW649cjNwYNGmRzeLdVq1ZKT0/X2bNnJf11qDchIUG9evWyeR1cXV3VpEmTHF+H3Prnz+rfv5a3bt3S77//rkqVKsnf31/79+/P1Tb/vo1r167pt99+U6tWrXT9+nUdO3ZMkqx7blavXq3r169nuZ0lS5YoIyNDTz75pM3zDw4OVuXKlR3y/FEwUHZQKCUnJ9sUi3/q0aOHWrRooeeee05BQUHq2bOnvvnmG7uKz3333WfXyciVK1e2uW2xWFSpUqV8v3T27NmzCgkJyfR63N7lf/sX223lypXLtI3ixYvf8VyVs2fPqnLlynJxsf3fRnaP40jnzp1T3759FRAQYD2v5YEHHpCkTOdfuLi4qGLFijZj999/vyRZvxYnT55UYmKiAgMDVapUKZslOTlZV65cyTbLqFGj5O3trcaNG6ty5cqKiIiwHh7NCw8Pj0yH+XLz9ciNf36tixcvLknWbZ88eVLSX+fC/fN1WLNmTY6vQ27982f1zz//1JgxY6znl5UsWVKlSpVSQkJCpq9ldo4cOaJ//etf8vPzk6+vr0qVKqWnn35a0v//fqhQoYKioqL0f//3fypZsqTCw8M1c+ZMm8c4efKkDMNQ5cqVMz3/o0ePOuT5o2DgnB0UOr/88osSExNVqVKlbOd4enpqy5Yt2rhxo77//nutWrVKCxcu1EMPPaQ1a9bI1dX1jo9jz3k2uZXdGx+mp6fnKpMjZPc4xj9O4C0o0tPT9fDDD+vq1asaNWqUqlatKi8vL124cEF9+/bN0567jIwMBQYG6quvvspyfU7nGFWrVk3Hjx/XihUrtGrVKn377bf68MMPNWbMGI0bN87uLPn5db/T1/r2azdv3jwFBwdnmne3VzjeunVLJ06cUM2aNa1jQ4cO1Zw5czRixAg1a9ZMfn5+slgs6tmzZ66+lgkJCXrggQfk6+ur8ePHKywsTB4eHtq/f79GjRpls4333ntPffv21fLly7VmzRoNGzZMMTEx2rlzp8qUKaOMjAxZLBatXLkyy9eK83LMg7KDQmfevHmSpPDw8Bznubi4qG3btmrbtq2mTJmiiRMnavTo0dq4caPatWvn8Hdcvv1X8m2GYSguLs7m/YCKFy+uhISETPc9e/aszd4Ie7KFhoZq3bp1unbtms1f0Ld354eGhuZ6W3d6nIMHDyojI8Nm746jH+efDh06pBMnTujzzz/Xs88+ax1fu3ZtlvMzMjL0888/W/fmSNKJEyckyXqybVhYmNatW6cWLVrkqdR6eXmpR48e6tGjh27evKkuXbpowoQJio6OvqeXl9/t9/Dtw5mBgYFq166dIyLZWLx4sf7880+bn9XFixerT58+eu+996xjN27cyPRzkd1z27Rpk37//XctWbJErVu3to6fPn06y/m1atVSrVq19Nprr2n79u1q0aKFZs+erbfeekthYWEyDEMVKlSw+X7Jyr16h3bkDw5joVDZsGGD3nzzTVWoUEG9e/fOdt7Vq1czjd1+c77U1FRJf/3CkpRl+ciLL774wubchMWLF+vSpUvq0KGDdSwsLEw7d+7UzZs3rWMrVqzIdIm6Pdk6duyo9PR0m8t7Jen999+XxWKxefy70bFjR8XHx9tcyZOWlqbp06fL29vbeljJ0W7/xf33PU+GYeiDDz7I9j5/fy0Mw9CMGTNUtGhRtW3bVpL05JNPKj09XW+++Wam+6alpeX4uv/+++82t93c3FS9enUZhqFbt27l6jk5ipeX1119/4aHh8vX11cTJ07MMvvdvAPyjz/+qBEjRqh48eKKiIiwjru6umbaizh9+vRMl41n9zOQ1ffDzZs39eGHH9rMS0pKUlpams1YrVq15OLiYv1/QJcuXeTq6qpx48ZlymQYhs3X2svLK9eH2VDwsGcHBdbKlSt17NgxpaWl6fLly9qwYYPWrl2r0NBQfffddzn+BT1+/Hht2bJFnTp1UmhoqK5cuaIPP/xQZcqUUcuWLSX9VTz8/f01e/Zs+fj4yMvLS02aNFGFChXylDcgIEAtW7ZUv379dPnyZU2dOlWVKlWyuTz+ueee0+LFi/XII4/oySef1KlTp/Tll1/anDBsb7bOnTvrwQcf1OjRo3XmzBnVqVNHa9as0fLlyzVixIhM286rQYMG6aOPPlLfvn21b98+lS9fXosXL9a2bds0derUHM+hupO4uDi99dZbmcbr1aun9u3bKywsTC+99JIuXLggX19fffvtt9me0+Lh4aFVq1apT58+atKkiVauXKnvv/9er776qvXw1AMPPKDBgwcrJiZGsbGxat++vYoWLaqTJ09q0aJF+uCDDzK9Sd5t7du3V3BwsFq0aKGgoCAdPXpUM2bMUKdOne7qNciLBg0aaNasWXrrrbdUqVIlBQYG2vVuxb6+vpo1a5aeeeYZ1a9fXz179lSpUqV07tw5ff/992rRokWmEp2VH374QTdu3FB6erp+//13bdu2Td999538/Py0dOlSm0Nkjz76qObNmyc/Pz9Vr15dO3bs0Lp16zK97UHdunXl6uqqt99+W4mJiXJ3d9dDDz2k5s2bq3jx4urTp4+GDRsmi8WiefPmZSorGzZs0JAhQ9S9e3fdf//9SktL07x58+Tq6qquXbtK+uvn7K233lJ0dLTOnDmjJ554Qj4+Pjp9+rSWLl2qQYMG6aWXXrK+1gsXLlRUVJQaNWokb29vde7cOdevNZzs3l8ABuTs9mWztxc3NzcjODjYePjhh40PPvjA5hLn2/556fn69euNxx9/3AgJCTHc3NyMkJAQo1evXsaJEyds7rd8+XKjevXqRpEiRWwuC37ggQeyvbw4u0vPv/76ayM6OtoIDAw0PD09jU6dOtlcFn3be++9Z9x3332Gu7u70aJFC2Pv3r2ZtplTtn9eem4Yf11CHBkZaYSEhBhFixY1KleubLzzzjs2lx0bxl+XnkdERGTKlN0l8f90+fJlo1+/fkbJkiUNNzc3o1atWlleHm/vped//3r/fRkwYIBhGIbx008/Ge3atTO8vb2NkiVLGgMHDrReMv/PS7m9vLyMU6dOGe3btzeKFStmBAUFGWPHjjXS09MzPfbHH39sNGjQwPD09DR8fHyMWrVqGSNHjjQuXrxonfPPr81HH31ktG7d2ihRooTh7u5uhIWFGS+//LKRmJiY4/PM7tJzLy+vTHP/+f2cnfj4eKNTp06Gj4+PIcmaM7u3b7j9vfrPy7k3btxohIeHG35+foaHh4cRFhZm9O3b19i7d2+Oj397e7eXokWLGqVKlTJat25tTJgwwbhy5Uqm+/zxxx/W7yFvb28jPDzcOHbsWJbfg5988olRsWJFw9XV1Sb3tm3bjKZNmxqenp5GSEiIMXLkSGP16tU2c37++Wejf//+RlhYmOHh4WEEBAQYDz74oLFu3bpMmb799lujZcuWhpeXl+Hl5WVUrVrViIiIMI4fP26dk5ycbDz11FOGv7+/IYnL0AsZi2EU0LMSAQAAHIBzdgAAgKlRdgAAgKlRdgAAgKlRdgAAgKlRdgAAgKlRdgAAgKnxpoL66+3lL168KB8fH94SHACAQsIwDF27dk0hISGZPqT47yg7ki5evKiyZcs6OwYAAMiD8+fPq0yZMtmup+xI1rd4P3/+vHx9fZ2cBgAA5EZSUpLKli17x49qoezo/3+ara+vL2UHAIBC5k6noHCCMgAAMDXKDgAAMDXKDgAAMDXKDgAAMDXKDgAAMDXKDgAAMDXKDgAAMDXKDgAAMDXKDgAAMDXKDgAAMDXKDgAAMDXKDgAAMDXKDgAAMDXKDgAAMDXKDgAAMLUizg4AADC38q987+wImZyZ1MnZEXAPsWcHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYmlPLTkxMjBo1aiQfHx8FBgbqiSee0PHjx23m3LhxQxERESpRooS8vb3VtWtXXb582WbOuXPn1KlTJxUrVkyBgYF6+eWXlZaWdi+fCgAAKKCcWnY2b96siIgI7dy5U2vXrtWtW7fUvn17paSkWOdERkbqP//5jxYtWqTNmzfr4sWL6tKli3V9enq6OnXqpJs3b2r79u36/PPPNXfuXI0ZM8YZTwkAABQwFsMwDGeHuO3XX39VYGCgNm/erNatWysxMVGlSpXS/Pnz1a1bN0nSsWPHVK1aNe3YsUNNmzbVypUr9eijj+rixYsKCgqSJM2ePVujRo3Sr7/+Kjc3tzs+blJSkvz8/JSYmChfX998fY4A8L+GDwJFfsnt7+8Cdc5OYmKiJCkgIECStG/fPt26dUvt2rWzzqlatarKlSunHTt2SJJ27NihWrVqWYuOJIWHhyspKUlHjhzJ8nFSU1OVlJRkswAAAHMq4uwAt2VkZGjEiBFq0aKFatasKUmKj4+Xm5ub/P39beYGBQUpPj7eOufvRef2+tvrshITE6Nx48Y5+BmYC3+JAQDMosDs2YmIiNDhw4e1YMGCfH+s6OhoJSYmWpfz58/n+2MCAADnKBB7doYMGaIVK1Zoy5YtKlOmjHU8ODhYN2/eVEJCgs3encuXLys4ONg6Z/fu3Tbbu3211u05/+Tu7i53d3cHPwsAAFAQOXXPjmEYGjJkiJYuXaoNGzaoQoUKNusbNGigokWLav369dax48eP69y5c2rWrJkkqVmzZjp06JCuXLlinbN27Vr5+vqqevXq9+aJAACAAsupe3YiIiI0f/58LV++XD4+PtZzbPz8/OTp6Sk/Pz8NGDBAUVFRCggIkK+vr4YOHapmzZqpadOmkqT27durevXqeuaZZzR58mTFx8frtddeU0REBHtvAACAc8vOrFmzJElt2rSxGZ8zZ4769u0rSXr//ffl4uKirl27KjU1VeHh4frwww+tc11dXbVixQo9//zzatasmby8vNSnTx+NHz/+Xj0NAABQgDm17OTmLX48PDw0c+ZMzZw5M9s5oaGh+u9//+vIaAAAwCQKzNVYAAAA+YGyAwAATI2yAwAATI2yAwAATI2yAwAATI2yAwAATK1AfFwEAAAFDR+IbB7s2QEAAKZG2QEAAKZG2QEAAKZG2QEAAKbGCcpAAcCJkACQf9izAwAATI2yAwAATI2yAwAATI1zdmAqnPsCAPgn9uwAAABTo+wAAABTo+wAAABTo+wAAABTo+wAAABTo+wAAABTo+wAAABTo+wAAABTo+wAAABTo+wAAABTo+wAAABTo+wAAABTo+wAAABTo+wAAABTK+LsAAAKr/KvfO/sCJmcmdTJ2REAFDBO3bOzZcsWde7cWSEhIbJYLFq2bJnNeovFkuXyzjvvWOeUL18+0/pJkybd42cCAAAKKqeWnZSUFNWpU0czZ87Mcv2lS5dsls8++0wWi0Vdu3a1mTd+/HibeUOHDr0X8QEAQCHg1MNYHTp0UIcOHbJdHxwcbHN7+fLlevDBB1WxYkWbcR8fn0xzAQAApEJ0gvLly5f1/fffa8CAAZnWTZo0SSVKlFC9evX0zjvvKC0tLcdtpaamKikpyWYBAADmVGhOUP7888/l4+OjLl262IwPGzZM9evXV0BAgLZv367o6GhdunRJU6ZMyXZbMTExGjduXH5HBgCH4oRwIG8KTdn57LPP1Lt3b3l4eNiMR0VFWf9du3Ztubm5afDgwYqJiZG7u3uW24qOjra5X1JSksqWLZs/wQEAgFMVirLzww8/6Pjx41q4cOEd5zZp0kRpaWk6c+aMqlSpkuUcd3f3bIsQAAAwl0Jxzs6nn36qBg0aqE6dOnecGxsbKxcXFwUGBt6DZAAAoKBz6p6d5ORkxcXFWW+fPn1asbGxCggIULly5ST9dYhp0aJFeu+99zLdf8eOHdq1a5cefPBB+fj4aMeOHYqMjNTTTz+t4sWL37PnAQAACi6nlp29e/fqwQcftN6+fR5Nnz59NHfuXEnSggULZBiGevXqlen+7u7uWrBggd544w2lpqaqQoUKioyMtDkfBwAA/G9zatlp06aNDMPIcc6gQYM0aNCgLNfVr19fO3fuzI9oAADAJArFOTsAAAB5RdkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmVig+LqIw44P7AABwLvbsAAAAU6PsAAAAU6PsAAAAU6PsAAAAU6PsAAAAU+NqLAAATISrgDNjzw4AADA1yg4AADA1yg4AADA1yg4AADA1yg4AADA1yg4AADA1yg4AADA1yg4AADA1yg4AADA13kEZwP8c3mEW+N/Cnh0AAGBqlB0AAGBqlB0AAGBqlB0AAGBqlB0AAGBqlB0AAGBqlB0AAGBqlB0AAGBqTi07W7ZsUefOnRUSEiKLxaJly5bZrO/bt68sFovN8sgjj9jMuXr1qnr37i1fX1/5+/trwIABSk5OvofPAgAAFGROLTspKSmqU6eOZs6cme2cRx55RJcuXbIuX3/9tc363r1768iRI1q7dq1WrFihLVu2aNCgQfkdHQAAFBJO/biIDh06qEOHDjnOcXd3V3BwcJbrjh49qlWrVmnPnj1q2LChJGn69Onq2LGj3n33XYWEhDg8MwAAKFwK/Dk7mzZtUmBgoKpUqaLnn39ev//+u3Xdjh075O/vby06ktSuXTu5uLho165d2W4zNTVVSUlJNgsAADCnAl12HnnkEX3xxRdav3693n77bW3evFkdOnRQenq6JCk+Pl6BgYE29ylSpIgCAgIUHx+f7XZjYmLk5+dnXcqWLZuvzwMAADhPgf7U8549e1r/XatWLdWuXVthYWHatGmT2rZtm+ftRkdHKyoqyno7KSmJwgMAgEkV6D07/1SxYkWVLFlScXFxkqTg4GBduXLFZk5aWpquXr2a7Xk+0l/nAfn6+tosAADAnApV2fnll1/0+++/q3Tp0pKkZs2aKSEhQfv27bPO2bBhgzIyMtSkSRNnxQQAAAWIUw9jJScnW/fSSNLp06cVGxurgIAABQQEaNy4ceratauCg4N16tQpjRw5UpUqVVJ4eLgkqVq1anrkkUc0cOBAzZ49W7du3dKQIUPUs2dPrsQCAACS8rBn5/PPP9f3339vvT1y5Ej5+/urefPmOnv2rF3b2rt3r+rVq6d69epJkqKiolSvXj2NGTNGrq6uOnjwoB577DHdf//9GjBggBo0aKAffvhB7u7u1m189dVXqlq1qtq2bauOHTuqZcuW+vjjj+19WgAAwKTs3rMzceJEzZo1S9Jfl37PnDlT77//vlasWKHIyEgtWbIk19tq06aNDMPIdv3q1avvuI2AgADNnz8/148JAAD+t9hdds6fP69KlSpJkpYtW6auXbtq0KBBatGihdq0aePofAAAAHfF7sNY3t7e1jf2W7NmjR5++GFJkoeHh/7880/HpgMAALhLdu/Zefjhh/Xcc8+pXr16OnHihDp27ChJOnLkiMqXL+/ofAAAAHfF7j07M2fOVLNmzfTrr7/q22+/VYkSJSRJ+/btU69evRweEAAA4G7YvWfH399fM2bMyDQ+btw4hwQCAABwpDy9qeAPP/ygp59+Ws2bN9eFCxckSfPmzdPWrVsdGg4AAOBu2V12vv32W4WHh8vT01P79+9XamqqJCkxMVETJ050eEAAAIC7YXfZeeuttzR79mx98sknKlq0qHW8RYsW2r9/v0PDAQAA3C27y87x48fVunXrTON+fn5KSEhwRCYAAACHsbvsBAcH23ye1W1bt25VxYoVHRIKAADAUewuOwMHDtTw4cO1a9cuWSwWXbx4UV999ZVeeuklPf/88/mREQAAIM/svvT8lVdeUUZGhtq2bavr16+rdevWcnd310svvaShQ4fmR0YAAIA8s7vsWCwWjR49Wi+//LLi4uKUnJys6tWry9vbOz/yAQAA3BW7y85tbm5uql69uiOzAAAAOJzdZedf//qXLBZLpnGLxSIPDw9VqlRJTz31lKpUqeKQgAAAAHfD7hOU/fz8tGHDBu3fv18Wi0UWi0UHDhzQhg0blJaWpoULF6pOnTratm1bfuQFAACwi917doKDg/XUU09pxowZcnH5qytlZGRo+PDh8vHx0YIFC/Tvf/9bo0aN4uMjAACA09m9Z+fTTz/ViBEjrEVHklxcXDR06FB9/PHHslgsGjJkiA4fPuzQoAAAAHlhd9lJS0vTsWPHMo0fO3ZM6enpkiQPD48sz+sBAAC41+w+jPXMM89owIABevXVV9WoUSNJ0p49ezRx4kQ9++yzkqTNmzerRo0ajk0KAACQB3aXnffff19BQUGaPHmyLl++LEkKCgpSZGSkRo0aJUlq3769HnnkEccmBQAAyAO7y46rq6tGjx6t0aNHKykpSZLk6+trM6dcuXKOSQcAAHCX8vymglLmkgMAAFDQ5KnsLF68WN98843OnTunmzdv2qzbv3+/Q4IBAAA4gt1XY02bNk39+vVTUFCQDhw4oMaNG6tEiRL6+eef1aFDh/zICAAAkGd2l50PP/xQH3/8saZPny43NzeNHDlSa9eu1bBhw5SYmJgfGQEAAPLM7rJz7tw5NW/eXJLk6empa9euSfrrkvSvv/7asekAAADukt1lJzg4WFevXpX011VXO3fulCSdPn1ahmE4Nh0AAMBdsrvsPPTQQ/ruu+8kSf369VNkZKQefvhh9ejRQ//6178cHhAAAOBu2H011scff6yMjAxJUkREhEqUKKHt27frscce0+DBgx0eEAAA4G7YXXZcXFxsPgS0Z8+e6tmzp0NDAQAAOIrdh7Ek6caNG9q9e7dWrFih7777zmaxx5YtW9S5c2eFhITIYrFo2bJl1nW3bt3SqFGjVKtWLXl5eSkkJETPPvusLl68aLON8uXLy2Kx2CyTJk3Ky9MCAAAmZPeenVWrVunZZ5/Vb7/9lmmdxWKxfvJ5bqSkpKhOnTrq37+/unTpYrPu+vXr2r9/v15//XXVqVNHf/zxh4YPH67HHntMe/futZk7fvx4DRw40Hrbx8fHzmcFAADMyu6yM3ToUHXv3l1jxoxRUFDQXT14hw4dsn0jQj8/P61du9ZmbMaMGWrcuLHOnTtn8/lbPj4+Cg4OvqssAADAnOw+jHX58mVFRUXdddHJi8TERFksFvn7+9uMT5o0SSVKlFC9evX0zjvvKC0tLcftpKamKikpyWYBAADmZPeenW7dumnTpk0KCwvLjzzZunHjhkaNGqVevXrZfADpsGHDVL9+fQUEBGj79u2Kjo7WpUuXNGXKlGy3FRMTo3Hjxt2L2AAAwMnsLjszZsxQ9+7d9cMPP6hWrVoqWrSozfphw4Y5LNxtt27d0pNPPinDMDRr1iybdVFRUdZ/165dW25ubho8eLBiYmLk7u6e5faio6Nt7peUlKSyZcs6PDcAAHA+u8vO119/rTVr1sjDw0ObNm2SxWKxrrNYLA4vO7eLztmzZ7VhwwabvTpZadKkidLS0nTmzBlVqVIlyznu7u7ZFiEAAGAudped0aNHa9y4cXrllVds3m8nP9wuOidPntTGjRtVokSJO94nNjZWLi4uCgwMzNdsAACgcLC77Ny8eVM9evRwSNFJTk5WXFyc9fbp06cVGxurgIAAlS5dWt26ddP+/fu1YsUKpaenKz4+XpIUEBAgNzc37dixQ7t27dKDDz4oHx8f7dixQ5GRkXr66adVvHjxu84HAAAKP7sbS58+fbRw4UKHPPjevXtVr1491atXT9Jf59/Uq1dPY8aM0YULF/Tdd9/pl19+Ud26dVW6dGnrsn37dkl/HY5asGCBHnjgAdWoUUMTJkxQZGSkPv74Y4fkAwAAhZ/de3bS09M1efJkrV69WrVr1850gnJOV0H9U5s2bXL8pPQ7fYp6/fr1rZ+6DgAAkBW7y86hQ4ese2IOHz5ss+7vJysDAAAUBHaXnY0bN+ZHDgAAgHyRv5dTAQAAOFmu9+z884M6s7NkyZI8hwEAAHC0XJcdPz+//MwBAACQL3JddubMmZOfOQAAAPIF5+wAAABTo+wAAABTo+wAAABTo+wAAABTy1XZqV+/vv744w9J0vjx43X9+vV8DQUAAOAouSo7R48eVUpKiiRp3LhxSk5OztdQAAAAjpKrS8/r1q2rfv36qWXLljIMQ++++668vb2znDtmzBiHBgQAALgbuSo7c+fO1dixY7VixQpZLBatXLlSRYpkvqvFYqHsAACAAiVXZadKlSpasGCBJMnFxUXr169XYGBgvgYDAABwBLs/9TwjIyM/cgAAAOQLu8uOJJ06dUpTp07V0aNHJUnVq1fX8OHDFRYW5tBwAAAAd8vu99lZvXq1qlevrt27d6t27dqqXbu2du3apRo1amjt2rX5kREAACDP7N6z88orrygyMlKTJk3KND5q1Cg9/PDDDgsHAABwt+zes3P06FENGDAg03j//v31008/OSQUAACAo9hddkqVKqXY2NhM47GxsVyhBQAAChy7D2MNHDhQgwYN0s8//6zmzZtLkrZt26a3335bUVFRDg8IAABwN+wuO6+//rp8fHz03nvvKTo6WpIUEhKiN954Q8OGDXN4QAAAgLthd9mxWCyKjIxUZGSkrl27Jkny8fFxeDAAAABHyNP77NxGyQEAAAWd3ScoAwAAFCaUHQAAYGqUHQAAYGp2lZ1bt26pbdu2OnnyZH7lAQAAcCi7yk7RokV18ODB/MoCAADgcHYfxnr66af16aef5kcWAAAAh7O77KSlpWnWrFlq2LChBg8erKioKJvFHlu2bFHnzp0VEhIii8WiZcuW2aw3DENjxoxR6dKl5enpqXbt2mU6hHb16lX17t1bvr6+8vf314ABA5ScnGzv0wIAACZld9k5fPiw6tevLx8fH504cUIHDhywLll9ZlZOUlJSVKdOHc2cOTPL9ZMnT9a0adM0e/Zs7dq1S15eXgoPD9eNGzesc3r37q0jR45o7dq1WrFihbZs2aJBgwbZ+7QAAIBJ2f2mghs3bnTYg3fo0EEdOnTIcp1hGJo6dapee+01Pf7445KkL774QkFBQVq2bJl69uypo0ePatWqVdqzZ48aNmwoSZo+fbo6duyod999VyEhIQ7LCgAACqc8X3oeFxen1atX688//5T0VzlxpNOnTys+Pl7t2rWzjvn5+alJkybasWOHJGnHjh3y9/e3Fh1JateunVxcXLRr165st52amqqkpCSbBQAAmJPdZef3339X27Ztdf/996tjx466dOmSJGnAgAF68cUXHRYsPj5ekhQUFGQzHhQUZF0XHx+vwMBAm/VFihRRQECAdU5WYmJi5OfnZ13Kli3rsNwAAKBgsbvsREZGqmjRojp37pyKFStmHe/Ro4dWrVrl0HD5JTo6WomJidbl/Pnzzo4EAADyid3n7KxZs0arV69WmTJlbMYrV66ss2fPOixYcHCwJOny5csqXbq0dfzy5cuqW7eudc6VK1ds7peWlqarV69a758Vd3d3ubu7OywrAAAouOzes5OSkmKzR+e2q1evOrRAVKhQQcHBwVq/fr11LCkpSbt27VKzZs0kSc2aNVNCQoL27dtnnbNhwwZlZGSoSZMmDssCAAAKL7vLTqtWrfTFF19Yb1ssFmVkZGjy5Ml68MEH7dpWcnKyYmNjrZesnz59WrGxsTp37pwsFotGjBiht956S999950OHTqkZ599ViEhIXriiSckSdWqVdMjjzyigQMHavfu3dq2bZuGDBminj17ciUWAACQlIfDWJMnT1bbtm21d+9e3bx5UyNHjtSRI0d09epVbdu2za5t7d2716Yg3X5Twj59+mju3LkaOXKkUlJSNGjQICUkJKhly5ZatWqVPDw8rPf56quvNGTIELVt21YuLi7q2rWrpk2bZu/TAgAAJmV32alZs6ZOnDihGTNmyMfHR8nJyerSpYsiIiJszq3JjTZt2uR4ybrFYtH48eM1fvz4bOcEBARo/vz5dj0uAAD432F32ZH+er+b0aNHOzoLAACAw+Wp7Pzxxx/69NNPdfToUUlS9erV1a9fPwUEBDg0HAAAwN2y+wTlLVu2qHz58po2bZr++OMP/fHHH5o2bZoqVKigLVu25EdGAACAPLN7z05ERIR69OihWbNmydXVVZKUnp6uF154QRERETp06JDDQwIAAOSV3Xt24uLi9OKLL1qLjiS5uroqKipKcXFxDg0HAABwt+wuO/Xr17eeq/N3R48eVZ06dRwSCgAAwFFydRjr4MGD1n8PGzZMw4cPV1xcnJo2bSpJ2rlzp2bOnKlJkyblT0oAAIA8ylXZqVu3riwWi8174owcOTLTvKeeeko9evRwXDoAAIC7lKuyc/r06fzOAQAAkC9yVXZCQ0PzOwcAAEC+yNObCl68eFFbt27VlStXlJGRYbNu2LBhDgkGAADgCHaXnblz52rw4MFyc3NTiRIlZLFYrOssFgtlBwAAFCh2l53XX39dY8aMUXR0tFxc7L5yHQAA4J6yu61cv35dPXv2pOgAAIBCwe7GMmDAAC1atCg/sgAAADic3YexYmJi9Oijj2rVqlWqVauWihYtarN+ypQpDgsHAABwt/JUdlavXq0qVapIUqYTlAEAAAoSu8vOe++9p88++0x9+/bNhzgAAACOZfc5O+7u7mrRokV+ZAEAAHA4u8vO8OHDNX369PzIAgAA4HB2H8bavXu3NmzYoBUrVqhGjRqZTlBesmSJw8IBAADcLbvLjr+/v7p06ZIfWQAAABzO7rIzZ86c/MgBAACQL3gbZAAAYGp279mpUKFCju+n8/PPP99VIAAAAEeyu+yMGDHC5vatW7d04MABrVq1Si+//LKjcgEAADiE3WVn+PDhWY7PnDlTe/fuvetAAAAAjuSwc3Y6dOigb7/91lGbAwAAcAiHlZ3FixcrICDAUZsDAABwCLsPY9WrV8/mBGXDMBQfH69ff/1VH374oUPDAQAA3C27y84TTzxhc9vFxUWlSpVSmzZtVLVqVUflAgAAcAi7y87YsWPzI0e2ypcvr7Nnz2Yaf+GFFzRz5ky1adNGmzdvtlk3ePBgzZ49+15FBAAABZjdZede27Nnj9LT0623Dx8+rIcffljdu3e3jg0cOFDjx4+33i5WrNg9zQgAAAquXJcdFxeXHN9MUJIsFovS0tLuOtTflSpVyub2pEmTFBYWpgceeMA6VqxYMQUHBzv0cQEAgDnkuuwsXbo023U7duzQtGnTlJGR4ZBQ2bl586a+/PJLRUVF2RSvr776Sl9++aWCg4PVuXNnvf766znu3UlNTVVqaqr1dlJSUr7mBgAAzpPrsvP4449nGjt+/LheeeUV/ec//1Hv3r1tDiXlh2XLlikhIUF9+/a1jj311FMKDQ1VSEiIDh48qFGjRun48eNasmRJttuJiYnRuHHj8jUrAAAoGPJ0zs7Fixc1duxYff755woPD1dsbKxq1qzp6GyZfPrpp+rQoYNCQkKsY4MGDbL+u1atWipdurTatm2rU6dOKSwsLMvtREdHKyoqyno7KSlJZcuWzb/gAADAaewqO4mJiZo4caKmT5+uunXrav369WrVqlV+ZbNx9uxZrVu3Lsc9NpLUpEkTSVJcXFy2Zcfd3V3u7u4OzwgAAAqeXJedyZMn6+2331ZwcLC+/vrrLA9r5ac5c+YoMDBQnTp1ynFebGysJKl06dL3IBUAACjocl12XnnlFXl6eqpSpUr6/PPP9fnnn2c57057XvIiIyNDc+bMUZ8+fVSkyP+PfOrUKc2fP18dO3ZUiRIldPDgQUVGRqp169aqXbu2w3MAAIDCJ9dl59lnn73jpef5Zd26dTp37pz69+9vM+7m5qZ169Zp6tSpSklJUdmyZdW1a1e99tprTskJAAAKnlyXnblz5+ZjjJy1b99ehmFkGi9btmymd08GAAD4O4d96jkAAEBBRNkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmRtkBAACmVqDLzhtvvCGLxWKzVK1a1br+xo0bioiIUIkSJeTt7a2uXbvq8uXLTkwMAAAKmgJddiSpRo0aunTpknXZunWrdV1kZKT+85//aNGiRdq8ebMuXryoLl26ODEtAAAoaIo4O8CdFClSRMHBwZnGExMT9emnn2r+/Pl66KGHJElz5sxRtWrVtHPnTjVt2vReRwUAAAVQgd+zc/LkSYWEhKhixYrq3bu3zp07J0nat2+fbt26pXbt2lnnVq1aVeXKldOOHTucFRcAABQwBXrPTpMmTTR37lxVqVJFly5d0rhx49SqVSsdPnxY8fHxcnNzk7+/v819goKCFB8fn+N2U1NTlZqaar2dlJSUH/EBAEABUKDLTocOHaz/rl27tpo0aaLQ0FB988038vT0zPN2Y2JiNG7cOEdEBAAABVyBP4z1d/7+/rr//vsVFxen4OBg3bx5UwkJCTZzLl++nOU5Pn8XHR2txMRE63L+/Pl8TA0AAJypUJWd5ORknTp1SqVLl1aDBg1UtGhRrV+/3rr++PHjOnfunJo1a5bjdtzd3eXr62uzAAAAcyrQh7Feeuklde7cWaGhobp48aLGjh0rV1dX9erVS35+fhowYICioqIUEBAgX19fDR06VM2aNeNKLAAAYFWgy84vv/yiXr166ffff1epUqXUsmVL7dy5U6VKlZIkvf/++3JxcVHXrl2Vmpqq8PBwffjhh05ODQAACpICXXYWLFiQ43oPDw/NnDlTM2fOvEeJAABAYVOoztkBAACwF2UHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYGmUHAACYWoEuOzExMWrUqJF8fHwUGBioJ554QsePH7eZ06ZNG1ksFpvl3//+t5MSAwCAgqZAl53NmzcrIiJCO3fu1Nq1a3Xr1i21b99eKSkpNvMGDhyoS5cuWZfJkyc7KTEAAChoijg7QE5WrVplc3vu3LkKDAzUvn371Lp1a+t4sWLFFBwcfK/jAQCAQqBA79n5p8TERElSQECAzfhXX32lkiVLqmbNmoqOjtb169edEQ8AABRABXrPzt9lZGRoxIgRatGihWrWrGkdf+qppxQaGqqQkBAdPHhQo0aN0vHjx7VkyZJst5WamqrU1FTr7aSkpHzNDgAAnKfQlJ2IiAgdPnxYW7dutRkfNGiQ9d+1atVS6dKl1bZtW506dUphYWFZbismJkbjxo3L17wAAKBgKBSHsYYMGaIVK1Zo48aNKlOmTI5zmzRpIkmKi4vLdk50dLQSExOty/nz5x2aFwAAFBwFes+OYRgaOnSoli5dqk2bNqlChQp3vE9sbKwkqXTp0tnOcXd3l7u7u6NiAgCAAqxAl52IiAjNnz9fy5cvl4+Pj+Lj4yVJfn5+8vT01KlTpzR//nx17NhRJUqU0MGDBxUZGanWrVurdu3aTk4PAAAKggJddmbNmiXprzcO/Ls5c+aob9++cnNz07p16zR16lSlpKSobNmy6tq1q1577TUnpAUAAAVRgS47hmHkuL5s2bLavHnzPUoDAAAKo0JxgjIAAEBeUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpUXYAAICpmabszJw5U+XLl5eHh4eaNGmi3bt3OzsSAAAoAExRdhYuXKioqCiNHTtW+/fvV506dRQeHq4rV644OxoAAHAyU5SdKVOmaODAgerXr5+qV6+u2bNnq1ixYvrss8+cHQ0AADhZoS87N2/e1L59+9SuXTvrmIuLi9q1a6cdO3Y4MRkAACgIijg7wN367bfflJ6erqCgIJvxoKAgHTt2LMv7pKamKjU11Xo7MTFRkpSUlOTwfBmp1x2+zbuVm+dJbsch971F7nuL3PeWmXPfzXYNw8h5olHIXbhwwZBkbN++3Wb85ZdfNho3bpzlfcaOHWtIYmFhYWFhYTHBcv78+Ry7QqHfs1OyZEm5urrq8uXLNuOXL19WcHBwlveJjo5WVFSU9XZGRoauXr2qEiVKyGKx5GvevEpKSlLZsmV1/vx5+fr6OjtOrpH73iL3vUXue4vc91ZhyG0Yhq5du6aQkJAc5xX6suPm5qYGDRpo/fr1euKJJyT9VV7Wr1+vIUOGZHkfd3d3ubu724z5+/vnc1LH8PX1LbDfdDkh971F7nuL3PcWue+tgp7bz8/vjnMKfdmRpKioKPXp00cNGzZU48aNNXXqVKWkpKhfv37OjgYAAJzMFGWnR48e+vXXXzVmzBjFx8erbt26WrVqVaaTlgEAwP8eU5QdSRoyZEi2h63MwN3dXWPHjs10+K2gI/e9Re57i9z3FrnvrcKaOysWw7jT9VoAAACFV6F/U0EAAICcUHYAAICpUXYAAICpUXYAAICpUXYKgZkzZ6p8+fLy8PBQkyZNtHv3bmdHuqMtW7aoc+fOCgkJkcVi0bJly5wd6Y5iYmLUqFEj+fj4KDAwUE888YSOHz/u7Fh3NGvWLNWuXdv6xl/NmjXTypUrnR3LbpMmTZLFYtGIESOcHSVHb7zxhiwWi81StWpVZ8fKlQsXLujpp59WiRIl5OnpqVq1amnv3r3OjpWj8uXLZ3q9LRaLIiIinB0tR+np6Xr99ddVoUIFeXp6KiwsTG+++eadP8OpALh27ZpGjBih0NBQeXp6qnnz5tqzZ4+zY90Vyk4Bt3DhQkVFRWns2LHav3+/6tSpo/DwcF25csXZ0XKUkpKiOnXqaObMmc6OkmubN29WRESEdu7cqbVr1+rWrVtq3769UlJSnB0tR2XKlNGkSZO0b98+7d27Vw899JAef/xxHTlyxNnRcm3Pnj366KOPVLt2bWdHyZUaNWro0qVL1mXr1q3OjnRHf/zxh1q0aKGiRYtq5cqV+umnn/Tee++pePHizo6Woz179ti81mvXrpUkde/e3cnJcvb2229r1qxZmjFjho4ePaq3335bkydP1vTp050d7Y6ee+45rV27VvPmzdOhQ4fUvn17tWvXThcuXHB2tLxzyKdxIt80btzYiIiIsN5OT083QkJCjJiYGCemso8kY+nSpc6OYbcrV64YkozNmzc7O4rdihcvbvzf//2fs2PkyrVr14zKlSsba9euNR544AFj+PDhzo6Uo7Fjxxp16tRxdgy7jRo1ymjZsqWzY9y14cOHG2FhYUZGRoazo+SoU6dORv/+/W3GunTpYvTu3dtJiXLn+vXrhqurq7FixQqb8fr16xujR492Uqq7x56dAuzmzZvat2+f2rVrZx1zcXFRu3bttGPHDicm+9+QmJgoSQoICHByktxLT0/XggULlJKSombNmjk7Tq5ERESoU6dONt/nBd3JkycVEhKiihUrqnfv3jp37pyzI93Rd999p4YNG6p79+4KDAxUvXr19Mknnzg7ll1u3rypL7/8Uv379y+wH9p8W/PmzbV+/XqdOHFCkvTjjz9q69at6tChg5OT5SwtLU3p6eny8PCwGff09CwUezCzY5p3UDaj3377Tenp6Zk+9iIoKEjHjh1zUqr/DRkZGRoxYoRatGihmjVrOjvOHR06dEjNmjXTjRs35O3traVLl6p69erOjnVHCxYs0P79+wvV+QBNmjTR3LlzVaVKFV26dEnjxo1Tq1atdPjwYfn4+Dg7XrZ+/vlnzZo1S1FRUXr11Ve1Z88eDRs2TG5uburTp4+z4+XKsmXLlJCQoL59+zo7yh298sorSkpKUtWqVeXq6qr09HRNmDBBvXv3dna0HPn4+KhZs2Z68803Va1aNQUFBenrr7/Wjh07VKlSJWfHyzPKDpCFiIgIHT58uND8JVOlShXFxsYqMTFRixcvVp8+fbR58+YCXXjOnz+v4cOHa+3atZn+iizI/v6Xee3atdWkSROFhobqm2++0YABA5yYLGcZGRlq2LChJk6cKEmqV6+eDh8+rNmzZxeasvPpp5+qQ4cOCgkJcXaUO/rmm2/01Vdfaf78+apRo4ZiY2M1YsQIhYSEFPjXe968eerfv7/uu+8+ubq6qn79+urVq5f27dvn7Gh5RtkpwEqWLClXV1ddvnzZZvzy5csKDg52UirzGzJkiFasWKEtW7aoTJkyzo6TK25ubta/uho0aKA9e/bogw8+0EcffeTkZNnbt2+frly5ovr161vH0tPTtWXLFs2YMUOpqalydXV1YsLc8ff31/3336+4uDhnR8lR6dKlM5XfatWq6dtvv3VSIvucPXtW69at05IlS5wdJVdefvllvfLKK+rZs6ckqVatWjp79qxiYmIKfNkJCwvT5s2blZKSoqSkJJUuXVo9evRQxYoVnR0tzzhnpwBzc3NTgwYNtH79eutYRkaG1q9fX2jOxyhMDMPQkCFDtHTpUm3YsEEVKlRwdqQ8y8jIUGpqqrNj5Kht27Y6dOiQYmNjrUvDhg3Vu3dvxcbGFoqiI0nJyck6deqUSpcu7ewoOWrRokWmt1I4ceKEQkNDnZTIPnPmzFFgYKA6derk7Ci5cv36dbm42P6KdXV1VUZGhpMS2c/Ly0ulS5fWH3/8odWrV+vxxx93dqQ8Y89OARcVFaU+ffqoYcOGaty4saZOnaqUlBT169fP2dFylJycbPOX7unTpxUbG6uAgACVK1fOicmyFxERofnz52v58uXy8fFRfHy8JMnPz0+enp5OTpe96OhodejQQeXKldO1a9c0f/58bdq0SatXr3Z2tBz5+PhkOh/Ky8tLJUqUKNDnSb300kvq3LmzQkNDdfHiRY0dO1aurq7q1auXs6PlKDIyUs2bN9fEiRP15JNPavfu3fr444/18ccfOzvaHWVkZGjOnDnq06ePihQpHL+2OnfurAkTJqhcuXKqUaOGDhw4oClTpqh///7OjnZHq1evlmEYqlKliuLi4vTyyy+ratWqBf73To6cfTkY7mz69OlGuXLlDDc3N6Nx48bGzp07nR3pjjZu3GhIyrT06dPH2dGylVVeScacOXOcHS1H/fv3N0JDQw03NzejVKlSRtu2bY01a9Y4O1aeFIZLz3v06GGULl3acHNzM+677z6jR48eRlxcnLNj5cp//vMfo2bNmoa7u7tRtWpV4+OPP3Z2pFxZvXq1Ick4fvy4s6PkWlJSkjF8+HCjXLlyhoeHh1GxYkVj9OjRRmpqqrOj3dHChQuNihUrGm5ubkZwcLARERFhJCQkODvWXbEYRiF4O0cAAIA84pwdAABgapQdAABgapQdAABgapQdAABgapQdAABgapQdAABgapQdAABgapQdAKY0d+5c+fv73/V2LBaLli1bdtfbAeA8lB0ABVbfvn31xBNPODsGgEKOsgMAAEyNsgOgUJoyZYpq1aolLy8vlS1bVi+88IKSk5MzzVu2bJkqV64sDw8PhYeH6/z58zbrly9frvr168vDw0MVK1bUuHHjlJaWdq+eBoB7gLIDoFBycXHRtGnTdOTIEX3++efasGGDRo4caTPn+vXrmjBhgr744gtt27ZNCQkJ6tmzp3X9Dz/8oGeffVbDhw/XTz/9pI8++khz587VhAkT7vXTAZCP+CBQAAVW3759lZCQkKsThBcvXqx///vf+u233yT9dYJyv379tHPnTjVp0kSSdOzYMVWrVk27du1S48aN1a5dO7Vt21bR0dHW7Xz55ZcaOXKkLl68KOmvE5SXLl3KuUNAIVbE2QEAIC/WrVunmJgYHTt2TElJSUpLS9ONGzd0/fp1FStWTJJUpEgRNWrUyHqfqlWryt/fX0ePHlXjxo31448/atu2bTZ7ctLT0zNtB0DhRtkBUOicOXNGjz76qJ5//nlNmDBBAQEB2rp1qwYMGKCbN2/muqQkJydr3Lhx6tKlS6Z1Hh4ejo4NwEkoOwAKnX379ikjI0PvvfeeXFz+OvXwm2++yTQvLS1Ne/fuVePGjSVJx48fV0JCgqpVqyZJql+/vo4fP65KlSrdu/AA7jnKDoACLTExUbGxsTZjJUuW1K1btzR9+nR17txZ27Zt0+zZszPdt2jRoho6dKimTZumIkWKaMiQIWratKm1/IwZM0aPPvqoypUrp27dusnFxUU//vijDh8+rLfeeutePD0A9wBXYwEo0DZt2qR69erZLPPmzdOUKVP09ttvq2bNmvrqq68UExOT6b7FihXTqFGj9NRTT6lFixby9vbWwoULrevDw8O1YsUKrVmzRo0aNVLTpk31/vvvKzQ09F4+RQD5jKuxAACAqbFnBwAAmBplBwAAmBplBwAAmBplBwAAmBplBwAAmBplBwAAmBplBwAAmBplBwAAmBplBwAAmBplBwAAmBplBwAAmBplBwAAmNr/A0eahS2ksKGkAAAAAElFTkSuQmCC"},"metadata":{}}]},{"cell_type":"code","source":"def apply_transforms(batch):\n    \"\"\"Get transformation for MNIST dataset\"\"\"\n    # transformation to convert images to tensors and apply normalization\n    transforms = Compose([\n        ToTensor(),\n        Normalize((0.5,), (0.5,)),\n        Resize((64, 64), antialias=False)\n        ])\n    batch[\"image\"] = [transforms(img) for img in batch[\"image\"]]\n    return batch","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:05:34.429553Z","iopub.execute_input":"2024-05-19T05:05:34.429881Z","iopub.status.idle":"2024-05-19T05:05:34.436031Z","shell.execute_reply.started":"2024-05-19T05:05:34.42985Z","shell.execute_reply":"2024-05-19T05:05:34.434973Z"},"trusted":true},"execution_count":183,"outputs":[]},{"cell_type":"markdown","source":"# start","metadata":{}},{"cell_type":"code","source":"!rm -rf /kaggle/working/*","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:41.780806Z","iopub.execute_input":"2024-05-19T05:14:41.781553Z","iopub.status.idle":"2024-05-19T05:14:42.803187Z","shell.execute_reply.started":"2024-05-19T05:14:41.781507Z","shell.execute_reply":"2024-05-19T05:14:42.801817Z"},"trusted":true},"execution_count":237,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=4, stride=2, padding=1)\n        self.leaky1 = nn.LeakyReLU()\n        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n        self.leaky2 = nn.LeakyReLU()\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n        self.leaky3 = nn.LeakyReLU()\n        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.leaky4 = nn.LeakyReLU()\n        self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.leaky5 = nn.LeakyReLU()\n        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.leaky6 = nn.LeakyReLU()\n        self.avgpool = nn.AvgPool2d(2, stride=2)\n        self.fc = nn.Linear(4 * 4 * 128, 11)  # 10 classes for MNIST\n        self.softmax = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.leaky1(x)\n        x = self.conv2(x)\n        x = self.leaky2(x)\n        x = self.conv3(x)\n        x = self.leaky3(x)\n        x = self.conv4(x)\n        x = self.leaky4(x)\n        x = self.conv5(x)\n        x = self.leaky5(x)\n        x = self.conv6(x)\n        x = self.leaky6(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)  # Flatten the output\n        x = self.fc(x)\n        x = self.softmax(x)\n        return x\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=4, stride=2, padding=1)\n        self.leaky1 = nn.LeakyReLU()\n        self.dropout = nn.Dropout()\n        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n        self.batchnorm1 = nn.BatchNorm2d(64)\n        self.leaky2 = nn.LeakyReLU()\n        self.conv3 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=4, stride=2, padding=1)\n        self.batchnorm2 = nn.BatchNorm2d(64)\n        self.leaky3 = nn.LeakyReLU()\n        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.batchnorm3 = nn.BatchNorm2d(128)\n        self.leaky4 = nn.LeakyReLU()\n        self.conv5 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.batchnorm4 = nn.BatchNorm2d(128)\n        self.leaky5 = nn.LeakyReLU()\n        self.conv6 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n        self.leaky6 = nn.LeakyReLU()\n        self.avgpool = nn.AvgPool2d(2, stride=2)\n        self.fc = nn.Linear(4 * 4 * 128, 11)\n        self.softmax = nn.Softmax(dim=1)\n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.leaky1(x)\n        x = self.dropout(x)\n        x = self.conv2(x)\n        x = self.batchnorm1(x)\n        x = self.leaky2(x)\n        x = self.conv3(x)\n        x = self.batchnorm2(x)\n        x = self.leaky3(x)\n        x = self.conv4(x)\n        x = self.batchnorm3(x)\n        x = self.leaky4(x)\n        x = self.conv5(x)\n        x = self.batchnorm4(x)\n        x = self.leaky5(x)\n        x = self.conv6(x)\n        x = self.leaky6(x)\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)  # Flatten the output\n        x = self.fc(x)\n        x = self.softmax(x)\n        return x\n\nclass Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.conv1 = nn.ConvTranspose2d(100, 256, kernel_size=4, stride=4, padding=0, bias=False)\n        self.batchnorm1 = nn.BatchNorm2d(256)\n        self.leaky1 = nn.LeakyReLU()\n        self.conv2 = nn.ConvTranspose2d(256, 128, kernel_size=4, stride=4, padding=0, bias=False)\n        self.batchnorm2 = nn.BatchNorm2d(128)\n        self.leaky2 = nn.LeakyReLU()\n        self.conv3 = nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False)\n        self.batchnorm3 = nn.BatchNorm2d(64)\n        self.leaky3 = nn.LeakyReLU()\n        self.conv4 = nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1, bias=False)\n        self.tanh = nn.Tanh()\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.batchnorm1(x)\n        x = self.leaky1(x)\n        x = self.conv2(x)\n        x = self.batchnorm2(x)\n        x = self.leaky2(x)\n        x = self.conv3(x)\n        x = self.batchnorm3(x)\n        x = self.leaky3(x)\n        x = self.conv4(x)\n        x = self.tanh(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.38309Z","iopub.execute_input":"2024-05-19T05:14:56.383643Z","iopub.status.idle":"2024-05-19T05:14:56.432288Z","shell.execute_reply.started":"2024-05-19T05:14:56.38359Z","shell.execute_reply":"2024-05-19T05:14:56.431147Z"},"trusted":true},"execution_count":238,"outputs":[]},{"cell_type":"code","source":"# Save initial generator state dict\ngenerator = Generator()\nsave_folder = f\"/kaggle/working/generator_state_dict\"\nos.makedirs(save_folder, exist_ok=True)\nexisting_files = glob.glob(os.path.join(save_folder, f\"generator_*.pth\"))\ncount = len(existing_files)\ntorch.save(generator.state_dict(), os.path.join(save_folder, f\"generator_{count}.pth\"))","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.434371Z","iopub.execute_input":"2024-05-19T05:14:56.434736Z","iopub.status.idle":"2024-05-19T05:14:56.467318Z","shell.execute_reply.started":"2024-05-19T05:14:56.434698Z","shell.execute_reply":"2024-05-19T05:14:56.466414Z"},"trusted":true},"execution_count":239,"outputs":[]},{"cell_type":"code","source":"def SaveGeneratorStateDict(fitres, cid):\n    save_folder = f\"/kaggle/working/generator-state-dict-temp\"\n    os.makedirs(save_folder, exist_ok=True)\n    existing_files = glob.glob(os.path.join(save_folder, f\"*.pth\"))\n    count = len(existing_files) + 1\n    torch.save({'fitres': fitres, 'cid': cid}, f\"/kaggle/working/generator-state-dict-temp/generator_{cid}.pth\")","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.468525Z","iopub.execute_input":"2024-05-19T05:14:56.46889Z","iopub.status.idle":"2024-05-19T05:14:56.474944Z","shell.execute_reply.started":"2024-05-19T05:14:56.468857Z","shell.execute_reply":"2024-05-19T05:14:56.47406Z"},"trusted":true},"execution_count":240,"outputs":[]},{"cell_type":"code","source":"def SavePoisonGeneratorStateDict(generator):    \n    save_folder = f\"/kaggle/working/poison_generator_state_dict\"\n    os.makedirs(save_folder, exist_ok=True)\n    existing_files = glob.glob(os.path.join(save_folder, f\"poison_generator_*.pth\"))\n    count = len(existing_files)\n    torch.save(generator.state_dict(), os.path.join(save_folder, f\"poison_generator_{count}.pth\"))\n    \nSavePoisonGeneratorStateDict(Generator())","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.476391Z","iopub.execute_input":"2024-05-19T05:14:56.476844Z","iopub.status.idle":"2024-05-19T05:14:56.503229Z","shell.execute_reply.started":"2024-05-19T05:14:56.476811Z","shell.execute_reply":"2024-05-19T05:14:56.502433Z"},"trusted":true},"execution_count":241,"outputs":[]},{"cell_type":"code","source":"criterion_ = nn.NLLLoss()\ndef discriminator_loss(pred_labels, real_labels):\n    log_probs = torch.log(pred_labels)\n    loss = criterion_(log_probs, real_labels)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.50494Z","iopub.execute_input":"2024-05-19T05:14:56.50523Z","iopub.status.idle":"2024-05-19T05:14:56.509775Z","shell.execute_reply.started":"2024-05-19T05:14:56.505206Z","shell.execute_reply":"2024-05-19T05:14:56.508885Z"},"trusted":true},"execution_count":242,"outputs":[]},{"cell_type":"code","source":"def train(model, generator, cid, trainloader, lr, epochs, device: str):\n    \"\"\"Train the network on the training set.\"\"\"\n    optimizer_m = torch.optim.Adam(model.parameters(), lr=lr)\n    scheduler_m = lr_scheduler.StepLR(optimizer_m, step_size=1, gamma=0.1)\n    optimizer_g = torch.optim.Adam(generator.parameters(), lr=lr)\n    scheduler_g = lr_scheduler.StepLR(optimizer_g, step_size=1, gamma=0.1)\n    criterion = torch.nn.CrossEntropyLoss()\n    for epoch in range(epochs):\n        total_g_loss, total_real_m_loss, total_fake_m_loss = 0.0, 0.0, 0.0\n        model.train()\n        generator.train()\n        for batch in trainloader:\n            # Chuẩn bị dữ liệu\n            real_images, real_labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n            fake_labels = torch.full((real_images.size(0),), 10).to(device)\n            # Huấn luyện Model với dữ liệu thật\n            optimizer_m.zero_grad()\n            real_outputs = model(real_images)\n            real_loss = criterion(real_outputs, real_labels)\n\n            # Huấn luyện Model với dữ liệu giả\n            noise = torch.randn(real_images.size(0), 100, 1, 1).to(device)\n            fake_images = generator(noise)\n            fake_outputs = model(fake_images.detach())\n            fake_loss = criterion(fake_outputs, fake_labels)\n            loss = real_loss + fake_loss\n            loss.backward()\n            optimizer_m.step()\n            total_real_m_loss += real_loss.item()\n            total_fake_m_loss += fake_loss.item()\n            # Huấn luyện Generator\n            optimizer_g.zero_grad()\n            noise = torch.randn(real_images.size(0), 100, 1, 1).to(device)\n            fake_images = generator(noise)\n            fake_outputs = model(fake_images)\n            g_loss = criterion(fake_outputs, real_labels)\n            g_loss.backward()\n            optimizer_g.step()  \n            total_g_loss += g_loss.item()     \n        scheduler_m.step()\n        scheduler_g.step()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.511162Z","iopub.execute_input":"2024-05-19T05:14:56.511502Z","iopub.status.idle":"2024-05-19T05:14:56.525811Z","shell.execute_reply.started":"2024-05-19T05:14:56.511471Z","shell.execute_reply":"2024-05-19T05:14:56.524874Z"},"trusted":true},"execution_count":243,"outputs":[]},{"cell_type":"code","source":"def test(net, testloader, device: str):\n    \"\"\"Validate the network on the entire test set.\"\"\"\n    criterion = torch.nn.CrossEntropyLoss()\n    correct, loss = 0, 0.0\n    correct_non_poisoned, total_non_poisoned, loss_non_poisoned = 0, 0, 0.0\n    correct_poisoned, total_poisoned, loss_poisoned = 0, 0, 0.0\n    net.eval()\n    with torch.no_grad():\n        for data in testloader:\n            images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n            outputs = net(images)\n            loss += criterion(outputs, labels).item()\n            _, predicted = torch.max(outputs.data, 1)\n            correct += (predicted == labels).sum().item()\n    \n            # Non-poisoned test\n            non_poisoned_mask = labels != 2\n            images_non_poisoned = images[non_poisoned_mask]\n            labels_non_poisoned = labels[non_poisoned_mask]\n            output_non_poisoned = net(images_non_poisoned)\n            pred_non_poisoned = output_non_poisoned.argmax(dim=1, keepdim=True)\n            for i in range(len(labels_non_poisoned)):\n                if pred_non_poisoned[i].item() == labels_non_poisoned[i].item():\n                    correct_non_poisoned += 1\n                total_non_poisoned += 1\n            loss_non_poisoned += criterion(output_non_poisoned, labels_non_poisoned).item()\n            # Poisoned test\n            pred = outputs.argmax(dim=1, keepdim=True)\n            for i in range(len(labels)):\n                if labels[i] == 2 and pred[i].item() == 7:  # Nếu ảnh số 2 bị phân loại sai thành số 7\n                    correct_poisoned += 1\n                if labels[i] == 2:  # Đếm tổng số lượng ảnh số 2\n                    total_poisoned += 1\n            loss_poisoned += criterion(outputs, labels).item()\n    \n    accuracy = 100 * correct / len(testloader.dataset)\n    non_poisoned_accuracy = 100 * correct_non_poisoned / total_non_poisoned if total_non_poisoned != 0 else 0\n    poisoned_accuracy = 100 * correct_poisoned / total_poisoned if total_poisoned != 0 else 0\n    return loss, accuracy, loss_non_poisoned, non_poisoned_accuracy, loss_poisoned, poisoned_accuracy","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.532704Z","iopub.execute_input":"2024-05-19T05:14:56.533127Z","iopub.status.idle":"2024-05-19T05:14:56.54752Z","shell.execute_reply.started":"2024-05-19T05:14:56.533055Z","shell.execute_reply":"2024-05-19T05:14:56.546638Z"},"trusted":true},"execution_count":244,"outputs":[]},{"cell_type":"code","source":"def get_latest_state_dict_file(directory, file_pattern=\"*.pth\"):\n    list_of_files = [fname for fname in glob.glob(os.path.join(directory, file_pattern))]\n    if list_of_files:\n        latest_round_file = max(list_of_files, key=os.path.getctime)\n        return latest_round_file\n    else:\n        return None","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.549319Z","iopub.execute_input":"2024-05-19T05:14:56.549631Z","iopub.status.idle":"2024-05-19T05:14:56.56149Z","shell.execute_reply.started":"2024-05-19T05:14:56.549606Z","shell.execute_reply":"2024-05-19T05:14:56.560596Z"},"trusted":true},"execution_count":245,"outputs":[]},{"cell_type":"code","source":"import flwr as fl\nfrom typing import Callable, Dict, List, Optional, Tuple, Union\nfrom flwr.common import (\n    EvaluateIns,\n    EvaluateRes,\n    FitIns,\n    FitRes,\n    MetricsAggregationFn,\n    NDArrays,\n    Parameters,\n    Scalar,\n    ndarrays_to_parameters,\n    parameters_to_ndarrays,\n    Code,\n    GetParametersIns,\n    GetParametersRes,\n    Status,\n)\nfrom flwr.server.strategy.aggregate import aggregate","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.5629Z","iopub.execute_input":"2024-05-19T05:14:56.563356Z","iopub.status.idle":"2024-05-19T05:14:56.572564Z","shell.execute_reply.started":"2024-05-19T05:14:56.563319Z","shell.execute_reply":"2024-05-19T05:14:56.571691Z"},"trusted":true},"execution_count":246,"outputs":[]},{"cell_type":"code","source":"from io import BytesIO\nfrom typing import cast\n\nimport numpy as np\n\nfrom flwr.common.typing import NDArray, NDArrays, Parameters\n\n\ndef ndarrays_to_sparse_parameters(ndarrays: NDArrays) -> Parameters:\n    \"\"\"Convert NumPy ndarrays to parameters object.\"\"\"\n    tensors = [ndarray_to_sparse_bytes(ndarray) for ndarray in ndarrays]\n    return Parameters(tensors=tensors, tensor_type=\"numpy.ndarray\")\n\n\ndef sparse_parameters_to_ndarrays(parameters: Parameters) -> NDArrays:\n    \"\"\"Convert parameters object to NumPy ndarrays.\"\"\"\n    return [sparse_bytes_to_ndarray(tensor) for tensor in parameters.tensors]\n\n\ndef ndarray_to_sparse_bytes(ndarray: NDArray) -> bytes:\n    \"\"\"Serialize NumPy ndarray to bytes.\"\"\"\n    bytes_io = BytesIO()\n\n    if len(ndarray.shape) > 1:\n        # We convert our ndarray into a sparse matrix\n        ndarray = torch.tensor(ndarray).to_sparse_csr()\n\n        # And send it byutilizing the sparse matrix attributes\n        # WARNING: NEVER set allow_pickle to true.\n        # Reason: loading pickled data can execute arbitrary code\n        # Source: https://numpy.org/doc/stable/reference/generated/numpy.save.html\n        np.savez(\n            bytes_io,  # type: ignore\n            crow_indices=ndarray.crow_indices(),\n            col_indices=ndarray.col_indices(),\n            values=ndarray.values(),\n            allow_pickle=False,\n        )\n    else:\n        # WARNING: NEVER set allow_pickle to true.\n        # Reason: loading pickled data can execute arbitrary code\n        # Source: https://numpy.org/doc/stable/reference/generated/numpy.save.html\n        np.save(bytes_io, ndarray, allow_pickle=False)\n    return bytes_io.getvalue()\n\n\ndef sparse_bytes_to_ndarray(tensor: bytes) -> NDArray:\n    \"\"\"Deserialize NumPy ndarray from bytes.\"\"\"\n    bytes_io = BytesIO(tensor)\n    # WARNING: NEVER set allow_pickle to true.\n    # Reason: loading pickled data can execute arbitrary code\n    # Source: https://numpy.org/doc/stable/reference/generated/numpy.load.html\n    loader = np.load(bytes_io, allow_pickle=False)  # type: ignore\n\n    if \"crow_indices\" in loader:\n        # We convert our sparse matrix back to a ndarray, using the attributes we sent\n        ndarray_deserialized = (\n            torch.sparse_csr_tensor(\n                crow_indices=loader[\"crow_indices\"],\n                col_indices=loader[\"col_indices\"],\n                values=loader[\"values\"],\n            )\n            .to_dense()\n            .numpy()\n        )\n    else:\n        ndarray_deserialized = loader\n    return cast(NDArray, ndarray_deserialized)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.574927Z","iopub.execute_input":"2024-05-19T05:14:56.575225Z","iopub.status.idle":"2024-05-19T05:14:56.586958Z","shell.execute_reply.started":"2024-05-19T05:14:56.575199Z","shell.execute_reply":"2024-05-19T05:14:56.586117Z"},"trusted":true},"execution_count":247,"outputs":[]},{"cell_type":"code","source":"#=======================================ATTACKER=======================================\nclass FlowerClient(fl.client.NumPyClient):\n    def __init__(self, cid, trainloader, valloader, testloader) -> None:\n        super().__init__()\n        self.trainloader = trainloader\n        self.valloader = valloader\n        self.testloader = testloader\n        self.cid = cid\n        self.model = Model()\n        self.generator = Generator()\n        # Determine device\n        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        self.model.to(self.device)  # send model to device\n        self.generator.to(self.device)\n        if self.cid == 0:\n            self.atk_generator = Generator()\n            self.discriminator = Discriminator()\n            self.discriminator.to(self.device)\n            self.atk_generator.to(self.device)\n\n    def set_parameters(self, parameters):\n        \"\"\"With the model paramters received from the server,\n        overwrite the uninitialise model in this class with them.\"\"\"\n        params_dict = zip(self.model.state_dict().keys(), parameters)\n        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n        # now replace the parameters\n        self.model.load_state_dict(state_dict, strict=True)\n        self.generator.load_state_dict(torch.load(get_latest_state_dict_file(f\"/kaggle/working/generator_state_dict\")), strict=True)\n        if self.cid == 0:\n            self.discriminator.load_state_dict(self.model.state_dict(), strict=False)\n            self.atk_generator.load_state_dict(torch.load(get_latest_state_dict_file(f\"/kaggle/working/poison_generator_state_dict\")), strict=True)\n            \n    def gen_get_parameters(self, net) -> List[np.ndarray]:\n        return [val.cpu().numpy() for _, val in net.state_dict().items()]\n\n    def get_gen_parameters(self, ins: GetParametersIns) -> GetParametersRes:\n        ndarrays: List[np.ndarray] = self.gen_get_parameters(self.generator)\n        parameters = ndarrays_to_sparse_parameters(ndarrays)\n        status = Status(code=Code.OK, message=\"Success\")\n        return GetParametersRes(\n            status=status,\n            parameters=parameters,\n        )\n\n    def get_parameters(self, config: Dict[str, Scalar]):\n        \"\"\"Extract all model parameters and conver them to a list of\n        NumPy arryas. The server doesn't work with PyTorch/TF/etc.\"\"\"\n        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n\n    def fit(self, parameters, config):\n        # copy parameters sent by the server into client's local model\n        self.set_parameters(parameters)\n        server_round = config[\"server_round\"]\n        lr, epochs = config[\"lr\"], config[\"epochs\"]\n        attacker_lr, attacker_epochs = config[\"attacker_lr\"], config[\"attacker_epochs\"]\n        if self.cid == 0:\n            self.atk_generator = atk_generator_train(self.atk_generator, self.discriminator, attacker_epochs, attacker_lr, self.device)\n            loss, accuracy, loss_non_poisoned, non_poisoned_accuracy, loss_poisoned, poisoned_accuracy = test(self.model, self.valloader, device=self.device)\n            if accuracy > 90:\n                print(\"ATTACKER TRAINING POISONGAN...\")\n                PoisonGAN(self.model, self.atk_generator, self.discriminator, attacker_epochs, attacker_lr, self.device)\n        else:\n            train(self.model, self.generator, self.cid, self.trainloader, lr, epochs, self.device)\n#         ndarrays_updated = self.get_gen_parameters(self.generator)\n#         parameters_updated = ndarrays_to_sparse_parameters(ndarrays_updated.parameters)\n        parameters_updated = self.get_gen_parameters(self.generator)\n        status = Status(code=Code.OK, message=\"Success\")\n        GenFitRes = FitRes(status=status, parameters=parameters_updated.parameters, num_examples=len(self.trainloader), metrics={},)\n        SaveGeneratorStateDict(GenFitRes, self.cid)\n        return self.get_parameters({}), len(self.trainloader), {}\n    \n    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n        \"\"\"Evaluate the model sent by the server on this client's\n        local validation set. Then return performance metrics.\"\"\"\n\n        self.set_parameters(parameters)\n        loss, accuracy, loss_non_poisoned, non_poisoned_accuracy, loss_poisoned, poisoned_accuracy = test(self.model, self.valloader, device=self.device)\n        return float(loss), len(self.valloader), {\"accuracy\": accuracy}","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.588452Z","iopub.execute_input":"2024-05-19T05:14:56.588938Z","iopub.status.idle":"2024-05-19T05:14:56.613109Z","shell.execute_reply.started":"2024-05-19T05:14:56.588905Z","shell.execute_reply":"2024-05-19T05:14:56.612317Z"},"trusted":true},"execution_count":248,"outputs":[]},{"cell_type":"code","source":"def gen_results(directory):\n    gen_results = []\n    for filename in os.listdir(directory):\n        filepath = os.path.join(directory, filename)\n        gen_results.append((torch.load(filepath)[\"cid\"] , torch.load(filepath)[\"fitres\"]))\n        !rm -rf directory/*\n    return gen_results ","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.614209Z","iopub.execute_input":"2024-05-19T05:14:56.614537Z","iopub.status.idle":"2024-05-19T05:14:56.626649Z","shell.execute_reply.started":"2024-05-19T05:14:56.614507Z","shell.execute_reply":"2024-05-19T05:14:56.625859Z"},"trusted":true},"execution_count":249,"outputs":[]},{"cell_type":"code","source":"#=======================================ATTACKER=======================================\ndef get_evaluate_fn(centralized_testset: Dataset):\n    \"\"\"This is a function that returns a function. The returned\n    function (i.e. `evaluate_fn`) will be executed by the strategy\n    at the end of each round to evaluate the stat of the global\n    model.\"\"\"\n\n    def evaluate_fn(server_round: int, parameters, config):\n        \"\"\"This function is executed by the strategy it will instantiate\n        a model and replace its parameters with those from the global model.\n        The, the model will be evaluate on the test set (recall this is the\n        whole MNIST test set).\"\"\"\n\n        model = Model()\n\n        # Determine device\n        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n        model.to(device)  # send model to device\n\n        # set parameters to the model\n        params_dict = zip(model.state_dict().keys(), parameters)\n        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n        model.load_state_dict(state_dict, strict=True)\n\n        # Apply transform to dataset\n        testset = centralized_testset.with_transform(apply_transforms)\n        testloader = DataLoader(testset, batch_size=50)\n        # call test\n        print('GLOBAL TEST')\n        loss, accuracy, loss_non_poisoned, non_poisoned_accuracy, loss_poisoned, poisoned_accuracy = test(model, testloader, device)\n\n        print(f'Poison Test   - Accuracy: {poisoned_accuracy:.6f}, Loss: {loss_poisoned:.6f}')\n        print(f'Main Test     - Accuracy: {non_poisoned_accuracy:.6f}, Loss: {loss_non_poisoned:.6f}')\n        print(f'Standard Test - Accuracy: {accuracy:.6f}, Loss: {loss:.6f}')\n        main_loss_values.append(loss_non_poisoned)\n        main_acc_values.append(non_poisoned_accuracy)\n        poison_loss_values.append(loss_poisoned)\n        poison_acc_values.append(poisoned_accuracy)\n        return loss, {\"accuracy\": accuracy}\n\n    return evaluate_fn","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.627732Z","iopub.execute_input":"2024-05-19T05:14:56.628005Z","iopub.status.idle":"2024-05-19T05:14:56.64167Z","shell.execute_reply.started":"2024-05-19T05:14:56.627978Z","shell.execute_reply":"2024-05-19T05:14:56.640699Z"},"trusted":true},"execution_count":250,"outputs":[]},{"cell_type":"code","source":"def fit_config(server_round: int) -> Dict[str, Scalar]:\n    \"\"\"Return a configuration with static batch size and (local) epochs.\"\"\"\n    config = {\n        \"epochs\": 1,  # Number of local epochs done by clients\n        \"lr\": 0.0006,  # Learning rate to use by clients during fit()\n        \"attacker_epochs\": 2,\n        \"attacker_lr\": 0.0003,\n        \"server_round\": server_round,  # The current round of federated learning\n    }\n    return config\n\ndef weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n    \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n    the client's evaluate() method.\"\"\"\n    # Multiply accuracy of each client by number of examples used\n    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n    examples = [num_examples for num_examples, _ in metrics]\n\n    # Aggregate and return custom metric (weighted average)\n    return {\"accuracy\": sum(accuracies) / sum(examples)}","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.64325Z","iopub.execute_input":"2024-05-19T05:14:56.643686Z","iopub.status.idle":"2024-05-19T05:14:56.65806Z","shell.execute_reply.started":"2024-05-19T05:14:56.643649Z","shell.execute_reply":"2024-05-19T05:14:56.657121Z"},"trusted":true},"execution_count":251,"outputs":[]},{"cell_type":"code","source":"class SaveModelStrategy(fl.server.strategy.FedAvg):\n    def aggregate_fit(\n        self,\n        server_round: int,\n        results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]],\n        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n        model = Model()\n        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n        aggregated_parameters, aggregated_metrics = super().aggregate_fit(server_round, results, failures)\n        if aggregated_parameters is not None:\n            print(f\"Saving round {server_round} Model aggregated_parameters...\")\n            # Convert `Parameters` to `List[np.ndarray]`\n            aggregated_ndarrays: List[np.ndarray] = fl.common.parameters_to_ndarrays(aggregated_parameters)\n            # Convert `List[np.ndarray]` to PyTorch`state_dict`\n            params_dict = zip(model.state_dict().keys(), aggregated_ndarrays)\n            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n            model.load_state_dict(state_dict, strict=True)\n            # Save the model\n            os.makedirs(\"/kaggle/working/model-state-dict\", exist_ok=True)\n            torch.save(model.state_dict(), f\"/kaggle/working/model-state-dict/model_round_{server_round}.pth\")\n            \n        generator = Generator()\n        gen_aggregated_parameters = gen_aggregate_fit(gen_results(\"/kaggle/working/generator-state-dict-temp\"))\n        print(gen_aggregated_parameters)\n        if gen_aggregated_parameters is not None:\n            print(f\"Saving round {server_round} Generator aggregated_parameters...\")\n            # Convert `Parameters` to `List[np.ndarray]`\n            aggregated_ndarrays: List[np.ndarray] = fl.common.parameters_to_ndarrays(gen_aggregated_parameters)\n            # Convert `List[np.ndarray]` to PyTorch`state_dict`\n            params_dict = zip(generator.state_dict().keys(), aggregated_ndarrays)\n            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n            generator.load_state_dict(state_dict, strict=True)\n            # Save the model\n            os.makedirs(\"/kaggle/working/generator-state-dict\", exist_ok=True)\n            torch.save(generator.state_dict(), f\"/kaggle/working/generator-state-dict/generator_round_{server_round}.pth\")\n            \n        return aggregated_parameters, aggregated_metrics","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.659893Z","iopub.execute_input":"2024-05-19T05:14:56.66027Z","iopub.status.idle":"2024-05-19T05:14:56.676502Z","shell.execute_reply.started":"2024-05-19T05:14:56.660236Z","shell.execute_reply":"2024-05-19T05:14:56.675385Z"},"trusted":true},"execution_count":252,"outputs":[]},{"cell_type":"code","source":"def gen_aggregate_fit(results: List[Tuple[int, FitRes]]) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n    \"\"\"Aggregate fit results using weighted average.\"\"\"\n    # Convert results\n    weights_results = [\n        (parameters_to_ndarrays(fit_res.parameters), fit_res.num_examples)\n        for _, fit_res in results\n    ]\n    aggregated_ndarrays = aggregate(weights_results)\n    parameters_aggregated = ndarrays_to_parameters(aggregated_ndarrays)\n\n    return parameters_aggregated","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.680135Z","iopub.execute_input":"2024-05-19T05:14:56.680435Z","iopub.status.idle":"2024-05-19T05:14:56.69089Z","shell.execute_reply.started":"2024-05-19T05:14:56.680412Z","shell.execute_reply":"2024-05-19T05:14:56.689608Z"},"trusted":true},"execution_count":253,"outputs":[]},{"cell_type":"code","source":"def get_client_fn(dataset: FederatedDataset):\n    \"\"\"Return a function to construct a client.\n    The VirtualClientEngine will execute this function whenever a client is sampled by\n    the strategy to participate.\n    \"\"\"\n    def client_fn(cid: str) -> fl.client.Client:\n        \"\"\"Construct a FlowerClient with its own dataset partition.\"\"\"\n        # Let's get the partition corresponding to the i-th client\n        client_dataset = dataset.load_partition(int(cid), \"train\")\n        # Now let's split it into train (90%) and validation (10%)\n        client_dataset_splits = client_dataset.train_test_split(test_size=0.1)\n        trainset = client_dataset_splits[\"train\"]\n        valset = client_dataset_splits[\"test\"]\n        # Now we apply the transform to each batch.\n        trainloader = DataLoader(trainset.with_transform(apply_transforms), batch_size=256, shuffle=True)\n        valloader = DataLoader(valset.with_transform(apply_transforms), batch_size=256)\n        testset = centralized_testset.with_transform(apply_transforms)\n        testloader = DataLoader(testset, batch_size=50)\n        # Create and return client\n        return FlowerClient(int(cid), trainloader, valloader, testloader).to_client()\n    return client_fn\n\nclient_fn_callback = get_client_fn(mnist_fds)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.692267Z","iopub.execute_input":"2024-05-19T05:14:56.692603Z","iopub.status.idle":"2024-05-19T05:14:56.701259Z","shell.execute_reply.started":"2024-05-19T05:14:56.692573Z","shell.execute_reply":"2024-05-19T05:14:56.700364Z"},"trusted":true},"execution_count":254,"outputs":[]},{"cell_type":"code","source":"def save_generator_images(generator):\n    device='cuda'\n    num_images=16\n    folder_path = \"/kaggle/working/output_image\"\n    os.makedirs(folder_path, exist_ok=True)\n    noise = torch.randn(num_images, 100, 1, 1).to(device)\n    generated_images = generator(noise)\n    generated_images = generated_images.squeeze().cpu().detach().numpy()\n    # Find the existing files to determine the count\n    existing_files = glob.glob(os.path.join(folder_path, f\"random_image_*.png\"))\n    count = len(existing_files) + 1\n    plt.figure(figsize=(8, 8))\n    for i, img in enumerate(generated_images):\n        plt.subplot(4, 4, i+1)\n        plt.imshow(img, cmap='gray', vmin=0, vmax=1)\n        plt.axis('off')\n    # Save the combined image with a dynamic filename\n    filename = f\"random_image_{count}.png\"\n    plt.savefig(os.path.join(folder_path, filename))\n    plt.close()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.702367Z","iopub.execute_input":"2024-05-19T05:14:56.70273Z","iopub.status.idle":"2024-05-19T05:14:56.715155Z","shell.execute_reply.started":"2024-05-19T05:14:56.702688Z","shell.execute_reply":"2024-05-19T05:14:56.71433Z"},"trusted":true},"execution_count":255,"outputs":[]},{"cell_type":"code","source":"main_loss_values = []\nmain_acc_values = []\npoison_loss_values = []\npoison_acc_values = []","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.716328Z","iopub.execute_input":"2024-05-19T05:14:56.716658Z","iopub.status.idle":"2024-05-19T05:14:56.728685Z","shell.execute_reply.started":"2024-05-19T05:14:56.716631Z","shell.execute_reply":"2024-05-19T05:14:56.727884Z"},"trusted":true},"execution_count":256,"outputs":[]},{"cell_type":"code","source":"def create_poison_dataloader(poison_images, poison_labels):\n    # Gộp tất cả poison_images và poison_labels vào 2 mảng\n    all_images = torch.cat(poison_images, dim=0)\n    all_labels = torch.cat(poison_labels, dim=0)\n    # Tạo TensorDataset và dataloader từ all_images và all_labels\n    poison_dataset = TensorDataset(all_images, all_labels)\n    poison_dataloader = DataLoader(poison_dataset, batch_size=16, shuffle=True)\n    return poison_dataloader   ","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.731825Z","iopub.execute_input":"2024-05-19T05:14:56.732196Z","iopub.status.idle":"2024-05-19T05:14:56.739417Z","shell.execute_reply.started":"2024-05-19T05:14:56.73217Z","shell.execute_reply":"2024-05-19T05:14:56.738527Z"},"trusted":true},"execution_count":257,"outputs":[]},{"cell_type":"code","source":"def PoisonGAN(model, atk_generator, discriminator, attacker_epochs, attacker_lr, device: str):\n    criterion = torch.nn.CrossEntropyLoss()\n    optimizer_m = torch.optim.Adam(model.parameters(), lr=attacker_lr)\n    scheduler_m = lr_scheduler.StepLR(optimizer_m, step_size=1, gamma=0.1)\n    for _ in range(attacker_epochs):\n        poison_dataloader = Data_Gen(atk_generator, discriminator, device)\n        if poison_dataloader is not None:\n            for bp in poison_dataloader:\n                images, labels = bp[0].to(device), bp[1].to(device)\n                optimizer_m.zero_grad()\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n                loss.backward()\n                for param in model.parameters():\n                    param.grad *= 40\n                optimizer_m.step()\n            scheduler_m.step()\n#     for param, grad in zip(model.parameters(), [param.grad for param in model.parameters()]):\n#         param.data -= S * learning_rate * grad","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.740746Z","iopub.execute_input":"2024-05-19T05:14:56.741258Z","iopub.status.idle":"2024-05-19T05:14:56.750996Z","shell.execute_reply.started":"2024-05-19T05:14:56.741217Z","shell.execute_reply":"2024-05-19T05:14:56.750047Z"},"trusted":true},"execution_count":258,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndef atk_generator_train(atk_generator, discriminator, attacker_epochs, attacker_lr, device: str):\n    atk_g_optimizer = torch.optim.Adam(atk_generator.parameters(), lr=attacker_lr)\n    atk_g_scheduler = lr_scheduler.StepLR(atk_g_optimizer, step_size=1, gamma=0.1)\n    num_batchs = 8\n    for epoch in range(attacker_epochs):\n        total_g_loss = 0.0\n        atk_generator.train()\n        discriminator.eval()\n        for batch in range(num_batchs):\n            atk_g_optimizer.zero_grad()\n            noise = torch.randn(256, 100, 1, 1).to(device)\n            x_fake = atk_generator(noise)\n            d_outputs = discriminator(x_fake)\n            atk_g_loss = -torch.mean(torch.log(d_outputs))\n            atk_g_loss.backward()\n            total_g_loss += atk_g_loss.item()\n            atk_g_optimizer.step()\n        print(f'Attacker Generator Loss: {total_g_loss/num_batchs}')\n    atk_g_scheduler.step()\n    \n    SavePoisonGeneratorStateDict(atk_generator)\n    save_generator_images(atk_generator)\n    return atk_generator","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.752164Z","iopub.execute_input":"2024-05-19T05:14:56.752521Z","iopub.status.idle":"2024-05-19T05:14:56.76788Z","shell.execute_reply.started":"2024-05-19T05:14:56.752486Z","shell.execute_reply":"2024-05-19T05:14:56.766883Z"},"trusted":true},"execution_count":259,"outputs":[]},{"cell_type":"code","source":"def Data_Gen(atk_generator, discriminator, device):\n    num_batchs = 8\n    poison_images, poison_labels = [], []\n    for batch in range(num_batchs):\n    # Data gen / create poison data\n        with torch.no_grad():\n            noise = torch.randn(256, 100, 1, 1).to(device)\n            outputs = atk_generator(noise)\n            predictions = discriminator(outputs)\n            predicted_labels = torch.max(predictions, dim=1).indices\n            selected_images = outputs[predicted_labels == 2]\n            selected_labels = predicted_labels[predicted_labels == 2]\n            selected_labels[selected_labels == 2] = 7\n            if len(selected_images)>0:\n                poison_images.append(selected_images)\n                poison_labels.append(selected_labels)\n    if len(poison_images) > 0:\n        poison_dataloader = create_poison_dataloader(poison_images, poison_labels)\n        return poison_dataloader\n    else:\n        return None","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.76912Z","iopub.execute_input":"2024-05-19T05:14:56.769518Z","iopub.status.idle":"2024-05-19T05:14:56.783914Z","shell.execute_reply.started":"2024-05-19T05:14:56.769482Z","shell.execute_reply":"2024-05-19T05:14:56.783091Z"},"trusted":true},"execution_count":260,"outputs":[]},{"cell_type":"code","source":"#=======================================ATTACKER=======================================\nstrategy = SaveModelStrategy(\n    fraction_fit=0.067,  # Sample 31% of available clients for training\n    fraction_evaluate=0.067,  # Sample 31% of available clients for evaluation\n    on_fit_config_fn=fit_config,\n    evaluate_fn=get_evaluate_fn(centralized_testset),  # global evaluation function\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.78502Z","iopub.execute_input":"2024-05-19T05:14:56.785621Z","iopub.status.idle":"2024-05-19T05:14:56.795349Z","shell.execute_reply.started":"2024-05-19T05:14:56.785587Z","shell.execute_reply":"2024-05-19T05:14:56.794414Z"},"trusted":true},"execution_count":261,"outputs":[]},{"cell_type":"code","source":"# With a dictionary, you tell Flower's VirtualClientEngine that each\n# client needs exclusive access to these many resources in order to run\nclient_resources = {\"num_cpus\": 2, \"num_gpus\": 1}\n\n# Let's disable tqdm progress bar in the main thread (used by the server)\ndisable_progress_bar()\nhistory = fl.simulation.start_simulation(\n    client_fn=client_fn_callback,  # a callback to construct a client\n    num_clients=NUM_CLIENTS,  # total number of clients in the experiment\n    config=fl.server.ServerConfig(num_rounds=10),  # let's run for 10 rounds\n    strategy=strategy,  # the strategy that will orchestrate the whole FL pipeline\n    client_resources=client_resources,\n    actor_kwargs={\n        \"on_actor_init_fn\": disable_progress_bar  # disable tqdm on each actor/process spawning virtual clients\n    },\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:14:56.7965Z","iopub.execute_input":"2024-05-19T05:14:56.796846Z","iopub.status.idle":"2024-05-19T05:15:28.723856Z","shell.execute_reply.started":"2024-05-19T05:14:56.796812Z","shell.execute_reply":"2024-05-19T05:15:28.72187Z"},"trusted":true},"execution_count":262,"outputs":[{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=10, no round_timeout\n2024-05-19 05:15:00,730\tINFO worker.py:1621 -- Started a local Ray instance.\n\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'GPU': 2.0, 'object_store_memory': 8451261235.0, 'node:172.19.2.2': 1.0, 'node:__internal_head__': 1.0, 'memory': 16902522471.0, 'CPU': 4.0}\n\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 2, 'num_gpus': 1}\n\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 2 actors\n\u001b[92mINFO \u001b[0m:      [INIT]\n\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n\u001b[2m\u001b[36m(pid=3212)\u001b[0m 2024-05-19 05:15:05.181844: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n\u001b[2m\u001b[36m(pid=3212)\u001b[0m 2024-05-19 05:15:05.181888: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n\u001b[2m\u001b[36m(pid=3212)\u001b[0m 2024-05-19 05:15:05.183221: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n","output_type":"stream"},{"name":"stdout","text":"GLOBAL TEST\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 479.6055989265442, {'accuracy': 11.35}\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 1]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 2 clients (out of 33)\n","output_type":"stream"},{"name":"stdout","text":"Poison Test   - Accuracy: 0.000000, Loss: 479.605599\nMain Test     - Accuracy: 12.656111, Loss: 479.611619\nStandard Test - Accuracy: 11.350000, Loss: 479.605599\n","output_type":"stream"},{"name":"stderr","text":"\u001b[2m\u001b[36m(ClientAppActor pid=3213)\u001b[0m /tmp/ipykernel_34/4041256762.py:26: UserWarning: Sparse CSR tensor support is in beta state. If you miss a functionality in the sparse tensor support, please submit a feature request to https://github.com/pytorch/pytorch/issues. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/SparseCsrTensorImpl.cpp:53.)\n\u001b[2m\u001b[36m(pid=3213)\u001b[0m 2024-05-19 05:15:05.181651: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n\u001b[2m\u001b[36m(pid=3213)\u001b[0m 2024-05-19 05:15:05.181707: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n\u001b[2m\u001b[36m(pid=3213)\u001b[0m 2024-05-19 05:15:05.183225: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[92mINFO \u001b[0m:      aggregate_fit: received 2 results and 0 failures\n\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n","output_type":"stream"},{"name":"stdout","text":"Saving round 1 Model aggregated_parameters...\n","output_type":"stream"},{"name":"stderr","text":"\u001b[91mERROR \u001b[0m:     unsupported operand type(s) for *: 'NpzFile' and 'int'\n\u001b[91mERROR \u001b[0m:     Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/flwr/simulation/app.py\", line 308, in start_simulation\n    hist = run_fl(\n  File \"/opt/conda/lib/python3.10/site-packages/flwr/server/server.py\", line 483, in run_fl\n    hist, elapsed_time = server.fit(\n  File \"/opt/conda/lib/python3.10/site-packages/flwr/server/server.py\", line 113, in fit\n    res_fit = self.fit_round(\n  File \"/opt/conda/lib/python3.10/site-packages/flwr/server/server.py\", line 249, in fit_round\n    ] = self.strategy.aggregate_fit(server_round, results, failures)\n  File \"/tmp/ipykernel_34/2640973232.py\", line 25, in aggregate_fit\n    gen_aggregated_parameters = gen_aggregate_fit(gen_results(\"/kaggle/working/generator-state-dict-temp\"))\n  File \"/tmp/ipykernel_34/1621097573.py\", line 8, in gen_aggregate_fit\n    aggregated_ndarrays = aggregate(weights_results)\n  File \"/opt/conda/lib/python3.10/site-packages/flwr/server/strategy/aggregate.py\", line 33, in aggregate\n    weighted_weights = [\n  File \"/opt/conda/lib/python3.10/site-packages/flwr/server/strategy/aggregate.py\", line 34, in <listcomp>\n    [layer * num_examples for layer in weights] for weights, num_examples in results\n  File \"/opt/conda/lib/python3.10/site-packages/flwr/server/strategy/aggregate.py\", line 34, in <listcomp>\n    [layer * num_examples for layer in weights] for weights, num_examples in results\nTypeError: unsupported operand type(s) for *: 'NpzFile' and 'int'\n\n\u001b[91mERROR \u001b[0m:     Your simulation crashed :(. This could be because of several reasons. The most common are: \n\t > Sometimes, issues in the simulation code itself can cause crashes. It's always a good idea to double-check your code for any potential bugs or inconsistencies that might be contributing to the problem. For example: \n\t\t - You might be using a class attribute in your clients that hasn't been defined.\n\t\t - There could be an incorrect method call to a 3rd party library (e.g., PyTorch).\n\t\t - The return types of methods in your clients/strategies might be incorrect.\n\t > Your system couldn't fit a single VirtualClient: try lowering `client_resources`.\n\t > All the actors in your pool crashed. This could be because: \n\t\t - You clients hit an out-of-memory (OOM) error and actors couldn't recover from it. Try launching your simulation with more generous `client_resources` setting (i.e. it seems {'num_cpus': 2, 'num_gpus': 1} is not enough for your run). Use fewer concurrent actors. \n\t\t - You were running a multi-node simulation and all worker nodes disconnected. The head node might still be alive but cannot accommodate any actor with resources: {'num_cpus': 2, 'num_gpus': 1}.\nTake a look at the Flower simulation examples for guidance <https://flower.ai/docs/framework/how-to-run-simulations.html>.\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/flwr/simulation/app.py:308\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;66;03m# Start training\u001b[39;00m\n\u001b[0;32m--> 308\u001b[0m     hist \u001b[38;5;241m=\u001b[39m \u001b[43mrun_fl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_server\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitialized_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/flwr/server/server.py:483\u001b[0m, in \u001b[0;36mrun_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Train a model on the given server and return the History object.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 483\u001b[0m hist, elapsed_time \u001b[38;5;241m=\u001b[39m \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround_timeout\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m log(INFO, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/flwr/server/server.py:113\u001b[0m, in \u001b[0;36mServer.fit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Train model and replace previous global model\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m res_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_round\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurrent_round\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res_fit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/flwr/server/server.py:249\u001b[0m, in \u001b[0;36mServer.fit_round\u001b[0;34m(self, server_round, timeout)\u001b[0m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# Aggregate training results\u001b[39;00m\n\u001b[1;32m    246\u001b[0m aggregated_result: Tuple[\n\u001b[1;32m    247\u001b[0m     Optional[Parameters],\n\u001b[1;32m    248\u001b[0m     Dict[\u001b[38;5;28mstr\u001b[39m, Scalar],\n\u001b[0;32m--> 249\u001b[0m ] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maggregate_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_round\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfailures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m parameters_aggregated, metrics_aggregated \u001b[38;5;241m=\u001b[39m aggregated_result\n","Cell \u001b[0;32mIn[252], line 25\u001b[0m, in \u001b[0;36mSaveModelStrategy.aggregate_fit\u001b[0;34m(self, server_round, results, failures)\u001b[0m\n\u001b[1;32m     24\u001b[0m generator \u001b[38;5;241m=\u001b[39m Generator()\n\u001b[0;32m---> 25\u001b[0m gen_aggregated_parameters \u001b[38;5;241m=\u001b[39m \u001b[43mgen_aggregate_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_results\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/kaggle/working/generator-state-dict-temp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(gen_aggregated_parameters)\n","Cell \u001b[0;32mIn[253], line 8\u001b[0m, in \u001b[0;36mgen_aggregate_fit\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m      4\u001b[0m weights_results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      5\u001b[0m     (parameters_to_ndarrays(fit_res\u001b[38;5;241m.\u001b[39mparameters), fit_res\u001b[38;5;241m.\u001b[39mnum_examples)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, fit_res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m      7\u001b[0m ]\n\u001b[0;32m----> 8\u001b[0m aggregated_ndarrays \u001b[38;5;241m=\u001b[39m \u001b[43maggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m parameters_aggregated \u001b[38;5;241m=\u001b[39m ndarrays_to_parameters(aggregated_ndarrays)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/flwr/server/strategy/aggregate.py:33\u001b[0m, in \u001b[0;36maggregate\u001b[0;34m(results)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Create a list of weights, each multiplied by the related number of examples\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m weighted_weights \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     34\u001b[0m     [layer \u001b[38;5;241m*\u001b[39m num_examples \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m weights] \u001b[38;5;28;01mfor\u001b[39;00m weights, num_examples \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m     35\u001b[0m ]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Compute average weights of each layer\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/flwr/server/strategy/aggregate.py:34\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Create a list of weights, each multiplied by the related number of examples\u001b[39;00m\n\u001b[1;32m     33\u001b[0m weighted_weights \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 34\u001b[0m     [layer \u001b[38;5;241m*\u001b[39m num_examples \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m weights] \u001b[38;5;28;01mfor\u001b[39;00m weights, num_examples \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m     35\u001b[0m ]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Compute average weights of each layer\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/flwr/server/strategy/aggregate.py:34\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Create a list of weights, each multiplied by the related number of examples\u001b[39;00m\n\u001b[1;32m     33\u001b[0m weighted_weights \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 34\u001b[0m     [\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_examples\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m weights] \u001b[38;5;28;01mfor\u001b[39;00m weights, num_examples \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m     35\u001b[0m ]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Compute average weights of each layer\u001b[39;00m\n","\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'NpzFile' and 'int'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[262], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Let's disable tqdm progress bar in the main thread (used by the server)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m disable_progress_bar()\n\u001b[0;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_simulation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_fn_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# a callback to construct a client\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_clients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mNUM_CLIENTS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# total number of clients in the experiment\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# let's run for 10 rounds\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# the strategy that will orchestrate the whole FL pipeline\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclient_resources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient_resources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactor_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mon_actor_init_fn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_progress_bar\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# disable tqdm on each actor/process spawning virtual clients\u001b[39;49;00m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/flwr/simulation/app.py:344\u001b[0m, in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[1;32m    314\u001b[0m     log(ERROR, traceback\u001b[38;5;241m.\u001b[39mformat_exc())\n\u001b[1;32m    315\u001b[0m     log(\n\u001b[1;32m    316\u001b[0m         ERROR,\n\u001b[1;32m    317\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour simulation crashed :(. This could be because of several reasons. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    342\u001b[0m         client_resources,\n\u001b[1;32m    343\u001b[0m     )\n\u001b[0;32m--> 344\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimulation crashed.\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mex\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;66;03m# Stop time monitoring resources in cluster\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     f_stop\u001b[38;5;241m.\u001b[39mset()\n","\u001b[0;31mRuntimeError\u001b[0m: Simulation crashed."],"ename":"RuntimeError","evalue":"Simulation crashed.","output_type":"error"}]},{"cell_type":"code","source":"print(f\"{history.metrics_centralized = }\")\nglobal_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\nround = [data[0] for data in global_accuracy_centralised]\nacc = [data[1] for data in global_accuracy_centralised]\nplt.plot(round, acc, label=\"global accuracy centralized\")\nplt.grid()\nplt.ylabel(\"Accuracy (%)\")\nplt.xlabel(\"Round\")\nplt.title(\"MNIST - IID - 33 clients with 10 clients per round\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:15:28.725106Z","iopub.status.idle":"2024-05-19T05:15:28.725607Z","shell.execute_reply.started":"2024-05-19T05:15:28.725342Z","shell.execute_reply":"2024-05-19T05:15:28.725363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"global_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\nround_centralised = [data[0] for data in global_accuracy_centralised]\nplt.plot(round_centralised, [data[1] for data in global_accuracy_centralised], label=\"Standard Task\")\nplt.plot(range(len(main_acc_values)), main_acc_values, label=\"Main Task\")\nplt.plot(range(len(poison_acc_values)), poison_acc_values, label=\"Poison Task\")\n\n# Thiết lập định dạng của biểu đồ\nplt.grid()\nplt.ylabel(\"Accuracy (%)\")\nplt.xlabel(\"Round\")\nplt.title(\"Accuracy Comparison\")\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:15:28.727437Z","iopub.status.idle":"2024-05-19T05:15:28.727831Z","shell.execute_reply.started":"2024-05-19T05:15:28.727651Z","shell.execute_reply":"2024-05-19T05:15:28.727666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !rm -rf /kaggle/working/*","metadata":{"execution":{"iopub.status.busy":"2024-05-19T05:15:28.729634Z","iopub.status.idle":"2024-05-19T05:15:28.730116Z","shell.execute_reply.started":"2024-05-19T05:15:28.729865Z","shell.execute_reply":"2024-05-19T05:15:28.729884Z"},"trusted":true},"execution_count":null,"outputs":[]}]}