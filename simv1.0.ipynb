{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/longchung2002/FLOWER-framework-simulation-poisonGAN/blob/main/simv1.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNTidNXQtiy6",
        "outputId": "75e169ce-c7d6-4d29-f403-79716bc31796"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flwr_datasets[vision] in /usr/local/lib/python3.10/dist-packages (0.1.0)\n",
            "Requirement already satisfied: datasets<3.0.0,>=2.14.3 in /usr/local/lib/python3.10/dist-packages (from flwr_datasets[vision]) (2.18.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from flwr_datasets[vision]) (1.25.2)\n",
            "Requirement already satisfied: pillow>=6.2.1 in /usr/local/lib/python3.10/dist-packages (from flwr_datasets[vision]) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.13.3)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets<3.0.0,>=2.14.3->flwr_datasets[vision]) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# depending on your shell, you might need to add `\\` before `[` and `]`.\n",
        "!pip install -q flwr[simulation]\n",
        "!pip install flwr_datasets[vision]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a5f2cc-ad3d-46e8-dd30-30304fe11177",
        "id": "WXOcHlPPtiy8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e9K5nFNjtiy-",
        "outputId": "a2dc13be-d570-4735-e87d-d51a4b19cbc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518,
          "referenced_widgets": [
            "6e9ce57d532148419465fb3ad0a1924e",
            "8919504617ef41858727b7a778946f25",
            "c794e05de7634112a4f3ca155f79d768",
            "4a244cdb7770464e8ccf797e5eed5f3e",
            "2649645bb8484f36b8feedf16d4d63c1",
            "1913cf81758a4df4bcf1f64a3ee58887",
            "7aeb30c7b2e8460f9130a7095c34a335",
            "b63f6eb8a84b47b7b4dc2c3734c6ce2c",
            "d70e9561396641d1a845b25eea755e31",
            "9acf2339ce764158813ca8b6461d1914",
            "ef558c2af6ff47d682552b5789bf2dec",
            "0285c7557ef44a76803b68a60b3e8bfc",
            "c4e4dd75d2d94c948ba621ee1604c804",
            "7239f4bf697f45c097a2b62e82db59e2",
            "e219695a45bf470289bb48b16bed218b",
            "c9a095e03b314a9bad6c40baffeceb62",
            "e21d79200a7047acbd5f87de4cfd9e27",
            "f1e4afc0e87543aab9d8bfa07ac4593e",
            "656362b04e084953b2dd1b8834593107",
            "3d129fee2064418d8beb365640a6a153",
            "7f52f59e5e7b47cbb9ddc5373da28300",
            "7b39f98cac1f4e299e65a736297434ef",
            "bd805cc3b8dd4e73819f27690d870d25",
            "40fec1baf489421894d921db55f6923a",
            "71a6522f36e1461a8da5629a49a27b76",
            "c6a1d0276426487d8bc4fb3a6e6041bd",
            "1d2622734aee49a79fd35e97f1355a11",
            "ba8f7f54a32745b1807ec38014008aa2",
            "e06e06a5694940569ec51e0dfa7affe6",
            "966187526cd54a5296fa17dd6d3c19a8",
            "b7fa48551409437da72bf36447e25a37",
            "8e062760884d458ea5407611216a1c6b",
            "c23939df7f7447089bea9a51111c3547",
            "bd9178bb16274d908e71288e6ae1c504",
            "085c8f3a613e48bb8d2a573dc1d3cc92",
            "195bc19b735441699dc83f28ea618345",
            "9634ebc3f35e4256ac669116c0f37d72",
            "05382d440b8a445a826693168e6fbd5f",
            "5c93ca2284174b50a26eb65854e3219f",
            "44c7cca3b0ec49bb89aa98b3775b2374",
            "8cd6e4c589ec4b94893ce6976bc87ecd",
            "adb4a63bf46c4e019c1f4a6e62329e75",
            "2ae21459d02b4de88976875004aa6cc4",
            "ea498c80fb33489fab00fb702c882b38",
            "74b33032512d4baf850865ece39cd3dd",
            "cb3bd0b0cf3742c3a26f787bf584f3f5",
            "ef2bfe619a0f4c5bbef7fbead9703a0c",
            "4f11d55f209b494b960ac9411172c560",
            "097797a5f1d948389a6a27d8a2820267",
            "5465906412594c93b89f4af818716c73",
            "7c50b29e50444236ac4688da5587ddde",
            "9f5658cfc5de4707b379a104596a7504",
            "5281db83736243d6972c2f9376ab09a9",
            "eb397d1be7ad40c9bbf5e54e1fa95869",
            "af9457c5ea3a4d209bed26457cb04b1e",
            "560301e1d4634bf6b1170584e66ab2f8",
            "2892a735198642eb935fd392a57cf7ec",
            "bc260df5d9dd4ec7ba41f0e52e35ca23",
            "738483fe581b4a3c8defa06a93285988",
            "55beaf399eb9446fa70c05e0da6fd8eb",
            "7ef3b3cd2dee47999e95c65c8323e0a1",
            "82f1b001bf544ab78b3f2489824ac086",
            "625a1ed5d6c4498097e7d4a161b4dd9c",
            "ea766deedd8844f6b68e8d6df14566c4",
            "12be62aa95dd4c1c9e466712e5704e22",
            "9b92abe8d3214ebaadc1e3ac675e9663",
            "d9d7e9437711416c83f5ecf2268f3946",
            "b95faf5a51fc481b969260f765e8c7a3",
            "794173cbdd044be48c86d7e26b48fd72",
            "dbecc60f3eee4596820fa8a483f65f53",
            "19ba580cf91c4e788b130c3cf7143f6a",
            "a2249c2d07474bf394943da5a412047f",
            "487e955ad6b745f4a0976340b9726b8d",
            "bc69fa1f262d443584e453d39c2e2c0a",
            "5c014556746c4443922b8d01ec9fe5c6",
            "94221f11a49c4290a0b64f6588c65801",
            "991e3cecdcb74dd9bc1dde43c987485c",
            "d1ed5466036148aaa834e6c68fd9706e",
            "ce4cc9f86124414c8f5ca1f27440030d",
            "389b93e97d76409aae9dcf338802c3cc",
            "8ec4f95f33b6428ba05d2572f053865f",
            "d738ff5a695b48c88b5b1f9efc19d6ef",
            "f42f37232eeb454d837ad7507d75f49e",
            "ee8b9422c5b8484888a5bce91eefb5c4",
            "6b7edb8dfa0f443b804f3a52dd907324",
            "fc5c2570978b48beb89b14c631f4e16d",
            "aeca424e9a784592b5f6b388649ad009",
            "31cfd1ce1bfa4ca3b67918b12b2cf56c"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/datasets/load.py:1461: FutureWarning: The repository for mnist contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mnist\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/3.98k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e9ce57d532148419465fb3ad0a1924e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/6.83k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0285c7557ef44a76803b68a60b3e8bfc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/9.91M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd805cc3b8dd4e73819f27690d870d25"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/28.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd9178bb16274d908e71288e6ae1c504"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.65M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "74b33032512d4baf850865ece39cd3dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/4.54k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "560301e1d4634bf6b1170584e66ab2f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/60000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9d7e9437711416c83f5ecf2268f3946"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d1ed5466036148aaa834e6c68fd9706e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'image': Image(decode=True, id=None),\n",
              " 'label': ClassLabel(names=['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "from flwr_datasets import FederatedDataset\n",
        "from datasets.utils.logging import disable_progress_bar\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Let's set a simulation involving a total of 100 clients\n",
        "NUM_CLIENTS = 33\n",
        "\n",
        "# Download MNIST dataset and partition the \"train\" partition (so one can be assigned to each client)\n",
        "mnist_fds = FederatedDataset(dataset=\"mnist\", partitioners={\"train\": NUM_CLIENTS})\n",
        "# Let's keep the test set as is, and use it to evaluate the global model on the server\n",
        "centralized_testset = mnist_fds.load_split(\"test\")\n",
        "partition = mnist_fds.load_partition(0, \"train\")\n",
        "partition.features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def calculate_label_distribution(data_loaders):\n",
        "    label_counts = {}\n",
        "    for loader in data_loaders:\n",
        "        images = loader[\"image\"]\n",
        "        labels = [loader[\"label\"]]\n",
        "        for label in labels:\n",
        "            label = int(label)\n",
        "            if label in label_counts:\n",
        "                label_counts[label] += 1\n",
        "            else:\n",
        "                label_counts[label] = 1\n",
        "    return label_counts\n",
        "\n",
        "def plot_label_distribution(label_counts):\n",
        "    # Vẽ biểu đồ histogram\n",
        "    plt.bar(label_counts.keys(), label_counts.values())\n",
        "    plt.xlabel('Label')\n",
        "    plt.ylabel('Number of Images')\n",
        "    plt.title('Distribution of Labels in the Dataset')\n",
        "    plt.xticks(range(10))\n",
        "    plt.show()\n",
        "    # Tính toán phân phối nhãn từ tất cả các dataloader\n",
        "all_trainloaders = partition # Gộp tất cả các dataloader lại\n",
        "all_label_counts = calculate_label_distribution(all_trainloaders)\n",
        "\n",
        "# Vẽ biểu đồ tương quan giữa tất cả các dataloader\n",
        "plot_label_distribution(all_label_counts)"
      ],
      "metadata": {
        "id": "AAxfaOXFUcxf",
        "outputId": "87c24412-5c32-4f14-9e82-69faf07fbd61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b_T97AxStiy-"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms import ToTensor, Normalize, Compose, Resize\n",
        "\n",
        "\n",
        "def apply_transforms(batch):\n",
        "    \"\"\"Get transformation for MNIST dataset\"\"\"\n",
        "\n",
        "    # transformation to convert images to tensors and apply normalization\n",
        "    transforms = Compose([\n",
        "        ToTensor(),\n",
        "        Normalize((0.5,), (0.5,))\n",
        "        ])\n",
        "    batch[\"image\"] = [transforms(img) for img in batch[\"image\"]]\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "e7NzdFp6tiy9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3)) #26x26x32\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) #13x13x32\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3))\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 11)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.relu1(self.conv1(x)))\n",
        "        x = self.pool2(self.relu2(self.conv2(x)))\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3)) #26x26x32\n",
        "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(2, 2) #13x13x32\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3)) #10x10\n",
        "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc1 = nn.Linear(64 * 5 * 5, 11)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.pool2(self.batchnorm2(self.relu2(self.conv2(x))))\n",
        "        x = self.flatten(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.softmax(x)\n",
        "        return x\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(100, 64 * 5 * 5)\n",
        "        self.conv1 = nn.ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=2, padding=0)\n",
        "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "        self.leaky1 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv2 = nn.ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=1, padding=0)\n",
        "        self.batchnorm2 = nn.BatchNorm2d(16)\n",
        "        self.leaky2 = nn.LeakyReLU()\n",
        "\n",
        "        self.conv3 = nn.ConvTranspose2d(16, 1, kernel_size=(4, 4), stride=2, padding=0)\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = x.view(-1, 64, 5, 5)\n",
        "        x = self.conv1(x)\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.leaky1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.batchnorm2(x)\n",
        "        x = self.leaky2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.tanh(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2BkZd5y0tiy-"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "def train(net, trainloader, optim, scheduler, criterion, epochs, device: str):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    net.train()\n",
        "    for _ in range(epochs):\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "            optim.zero_grad()\n",
        "            outputs = net(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "        scheduler.step()\n",
        "\n",
        "def test_standard(net, testloader, device: str):\n",
        "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct, loss = 0, 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            outputs = net(images)\n",
        "            loss += criterion(outputs, labels).item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = 100 * correct / len(testloader.dataset)\n",
        "    return loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EftKsIuMtiy_"
      },
      "outputs": [],
      "source": [
        "import flwr as fl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TkpxfwT9tiy_",
        "outputId": "a73b1382-564a-490e-d348-8d0831481f0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "from collections import OrderedDict\n",
        "from typing import Dict, List, Tuple, Union, Optional\n",
        "from flwr.server.client_proxy import ClientProxy\n",
        "from flwr.common import NDArrays, Scalar, Parameters\n",
        "\n",
        "\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, cid, trainloader, valloader, testloader) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.trainloader = trainloader\n",
        "        self.valloader = valloader\n",
        "        self.testloader = testloader\n",
        "        self.cid = cid\n",
        "        self.model = Model()\n",
        "        # Determine device\n",
        "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.model.to(self.device)  # send model to device\n",
        "\n",
        "    def set_parameters(self, parameters):\n",
        "        \"\"\"With the model paramters received from the server,\n",
        "        overwrite the uninitialise model in this class with them.\"\"\"\n",
        "\n",
        "        params_dict = zip(self.model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        # now replace the parameters\n",
        "        self.model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "    def get_parameters(self, config: Dict[str, Scalar]):\n",
        "        \"\"\"Extract all model parameters and conver them to a list of\n",
        "        NumPy arryas. The server doesn't work with PyTorch/TF/etc.\"\"\"\n",
        "        # print(f\"[Client {self.cid}] get_parameters\")\n",
        "        return [val.cpu().numpy() for _, val in self.model.state_dict().items()]\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        \"\"\"This method train the model using the parameters sent by the\n",
        "        server on the dataset of this client. At then end, the parameters\n",
        "        of the locally trained model are communicated back to the server\"\"\"\n",
        "        # print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        # copy parameters sent by the server into client's local model\n",
        "        self.set_parameters(parameters)\n",
        "        lr, epochs = config[\"lr\"], config[\"epochs\"]\n",
        "        optim = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
        "        scheduler = lr_scheduler.StepLR(optim, step_size=2, gamma=0.1)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        train(net=self.model, trainloader=self.trainloader, optim=optim, scheduler=scheduler, criterion=criterion, epochs=epochs, device=self.device)\n",
        "        # return the model parameters to the server as well as extra info (number of training examples in this case)\n",
        "        return self.get_parameters({}), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "        \"\"\"Evaluate the model sent by the server on this client's\n",
        "        local validation set. Then return performance metrics.\"\"\"\n",
        "\n",
        "        self.set_parameters(parameters)\n",
        "        loss, accuracy = test_standard(self.model, self.valloader, device=self.device)\n",
        "\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": accuracy}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "def load_model_state_dict():\n",
        "    net = Model()\n",
        "    list_of_files = [fname for fname in glob.glob(\"./model_round_*\")]\n",
        "    latest_round_file = max(list_of_files, key=os.path.getctime)\n",
        "    # latest_round_file = './model_round_df.pth'\n",
        "    print(\"Loading pre-trained model from: \", latest_round_file)\n",
        "    state_dict = torch.load(latest_round_file)\n",
        "    net.load_state_dict(state_dict)\n",
        "    return net"
      ],
      "metadata": {
        "id": "FiR-tVieingX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BPJKeYr6tiy_"
      },
      "outputs": [],
      "source": [
        "def get_evaluate_fn(centralized_testset: Dataset):\n",
        "    \"\"\"This is a function that returns a function. The returned\n",
        "    function (i.e. `evaluate_fn`) will be executed by the strategy\n",
        "    at the end of each round to evaluate the stat of the global\n",
        "    model.\"\"\"\n",
        "\n",
        "    def evaluate_fn(server_round: int, parameters, config):\n",
        "        \"\"\"This function is executed by the strategy it will instantiate\n",
        "        a model and replace its parameters with those from the global model.\n",
        "        The, the model will be evaluate on the test set (recall this is the\n",
        "        whole MNIST test set).\"\"\"\n",
        "\n",
        "        model = Model()\n",
        "\n",
        "        # Determine device\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)  # send model to device\n",
        "\n",
        "        # set parameters to the model\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "        ###############################################################################\n",
        "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # model = load_model_state_dict()\n",
        "        # model.to(device)\n",
        "        ###############################################################################\n",
        "        # Apply transform to dataset\n",
        "        testset = centralized_testset.with_transform(apply_transforms)\n",
        "\n",
        "        testloader = DataLoader(testset, batch_size=50)\n",
        "        # call test\n",
        "        loss, accuracy = test_standard(model, testloader, device)\n",
        "        print('GLOBAL TEST')\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uKusgaOAtiy_"
      },
      "outputs": [],
      "source": [
        "from flwr.common import Metrics, FitRes\n",
        "\n",
        "def fit_config(server_round: int) -> Dict[str, Scalar]:\n",
        "    \"\"\"Return a configuration with static batch size and (local) epochs.\"\"\"\n",
        "    config = {\n",
        "        \"epochs\": 10,  # Number of local epochs done by clients\n",
        "        \"lr\": 0.1,  # Learning rate to use by clients during fit()\n",
        "        \"attacker_epochs\": 20,\n",
        "        \"attacker_lr\": 0.1,\n",
        "    }\n",
        "    return config\n",
        "\n",
        "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
        "    \"\"\"Aggregation function for (federated) evaluation metrics, i.e. those returned by\n",
        "    the client's evaluate() method.\"\"\"\n",
        "    # Multiply accuracy of each client by number of examples used\n",
        "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
        "    examples = [num_examples for num_examples, _ in metrics]\n",
        "\n",
        "    # Aggregate and return custom metric (weighted average)\n",
        "    return {\"accuracy\": sum(accuracies) / sum(examples)}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "class SaveModelStrategy(fl.server.strategy.FedAvg):\n",
        "    def aggregate_fit(\n",
        "        self,\n",
        "        server_round: int,\n",
        "        results: List[Tuple[fl.server.client_proxy.ClientProxy, fl.common.FitRes]],\n",
        "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
        "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
        "        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
        "        model = Model()\n",
        "        # Call aggregate_fit from base class (FedAvg) to aggregate parameters and metrics\n",
        "        aggregated_parameters, aggregated_metrics = super().aggregate_fit(server_round, results, failures)\n",
        "\n",
        "        if aggregated_parameters is not None:\n",
        "            print(f\"Saving round {server_round} aggregated_parameters...\")\n",
        "\n",
        "            # Convert `Parameters` to `List[np.ndarray]`\n",
        "            aggregated_ndarrays: List[np.ndarray] = fl.common.parameters_to_ndarrays(aggregated_parameters)\n",
        "\n",
        "            # Convert `List[np.ndarray]` to PyTorch`state_dict`\n",
        "            params_dict = zip(model.state_dict().keys(), aggregated_ndarrays)\n",
        "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
        "            model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "            # Save the model\n",
        "            torch.save(model.state_dict(), f\"model_round_{server_round}.pth\")\n",
        "        return aggregated_parameters, aggregated_metrics"
      ],
      "metadata": {
        "id": "gIoh_OAxATO7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "FpB15Xv3tizA"
      },
      "outputs": [],
      "source": [
        "strategy = SaveModelStrategy(\n",
        "    fraction_fit=0.31,  # Sample 10% of available clients for training\n",
        "    fraction_evaluate=0.31,  # Sample 5% of available clients for evaluation\n",
        "    on_fit_config_fn=fit_config,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  # aggregates federated metrics\n",
        "    evaluate_fn=get_evaluate_fn(centralized_testset),  # global evaluation function\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "g0HZTdGHtizA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "def get_client_fn(dataset: FederatedDataset):\n",
        "    \"\"\"Return a function to construct a client.\n",
        "\n",
        "    The VirtualClientEngine will execute this function whenever a client is sampled by\n",
        "    the strategy to participate.\n",
        "    \"\"\"\n",
        "\n",
        "    def client_fn(cid: str) -> fl.client.Client:\n",
        "        \"\"\"Construct a FlowerClient with its own dataset partition.\"\"\"\n",
        "\n",
        "        # Let's get the partition corresponding to the i-th client\n",
        "        client_dataset = dataset.load_partition(int(cid), \"train\")\n",
        "\n",
        "        # Now let's split it into train (90%) and validation (10%)\n",
        "        client_dataset_splits = client_dataset.train_test_split(test_size=0.1)\n",
        "\n",
        "        trainset = client_dataset_splits[\"train\"]\n",
        "        valset = client_dataset_splits[\"test\"]\n",
        "\n",
        "        # Now we apply the transform to each batch.\n",
        "        trainloader = DataLoader(\n",
        "            trainset.with_transform(apply_transforms), batch_size=256, shuffle=True\n",
        "        )\n",
        "        valloader = DataLoader(valset.with_transform(apply_transforms), batch_size=256)\n",
        "        testset = centralized_testset.with_transform(apply_transforms)\n",
        "\n",
        "        testloader = DataLoader(testset, batch_size=50)\n",
        "        # Create and return client\n",
        "        return FlowerClient(int(cid), trainloader, valloader, testloader).to_client()\n",
        "\n",
        "    return client_fn\n",
        "\n",
        "\n",
        "client_fn_callback = get_client_fn(mnist_fds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRAALrO7tizA"
      },
      "source": [
        "Now we are ready to launch the FL experiment using Flower simulation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WOOq8qkUtizA"
      },
      "outputs": [],
      "source": [
        "# # With a dictionary, you tell Flower's VirtualClientEngine that each\n",
        "# # client needs exclusive access to these many resources in order to run\n",
        "# client_resources = {\"num_cpus\": 0.2, \"num_gpus\": 0.1}\n",
        "\n",
        "# # Let's disable tqdm progress bar in the main thread (used by the server)\n",
        "# disable_progress_bar()\n",
        "\n",
        "# history = fl.simulation.start_simulation(\n",
        "#     client_fn=client_fn_callback,  # a callback to construct a client\n",
        "#     num_clients=NUM_CLIENTS,  # total number of clients in the experiment\n",
        "#     config=fl.server.ServerConfig(num_rounds=100),  # let's run for 10 rounds\n",
        "#     strategy=strategy,  # the strategy that will orchestrate the whole FL pipeline\n",
        "#     client_resources=client_resources,\n",
        "#     actor_kwargs={\n",
        "#         \"on_actor_init_fn\": disable_progress_bar  # disable tqdm on each actor/process spawning virtual clients\n",
        "#     },\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-poMHY3BtizA"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# print(f\"{history.metrics_centralized = }\")\n",
        "\n",
        "# global_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\n",
        "# round = [data[0] for data in global_accuracy_centralised]\n",
        "# acc = [data[1] for data in global_accuracy_centralised]\n",
        "# plt.plot(round, acc)\n",
        "# plt.grid()\n",
        "# plt.ylabel(\"Accuracy (%)\")\n",
        "# plt.xlabel(\"Round\")\n",
        "# plt.title(\"MNIST - IID - 33 clients with 10 clients per round\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dLYQcJ3tizA"
      },
      "source": [
        "Congratulations! With that, you built a Flower client, customized it's instantiation through the `client_fn`, customized the server-side execution through a `FedAvg` strategy configured for this workload, and started a simulation with 100 clients (each holding their own individual partition of the MNIST dataset).\n",
        "\n",
        "Next, you can continue to explore more advanced Flower topics:\n",
        "\n",
        "- Deploy server and clients on different machines using `start_server` and `start_client`\n",
        "- Customize the server-side execution through custom strategies\n",
        "- Customize the client-side execution through `config` dictionaries\n",
        "\n",
        "Get all resources you need!\n",
        "\n",
        "* **[DOCS]** Our complete documenation: https://flower.dev/docs/\n",
        "* **[Examples]** All Flower examples: https://flower.dev/docs/examples/\n",
        "* **[VIDEO]** Our Youtube channel: https://www.youtube.com/@flowerlabs\n",
        "\n",
        "Don't forget to join our Slack channel: https://flower.dev/join-slack/\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_evaluate_fn(centralized_testset: Dataset):\n",
        "    \"\"\"This is a function that returns a function. The returned\n",
        "    function (i.e. `evaluate_fn`) will be executed by the strategy\n",
        "    at the end of each round to evaluate the stat of the global\n",
        "    model.\"\"\"\n",
        "\n",
        "    def evaluate_fn(server_round: int, parameters, config):\n",
        "        \"\"\"This function is executed by the strategy it will instantiate\n",
        "        a model and replace its parameters with those from the global model.\n",
        "        The, the model will be evaluate on the test set (recall this is the\n",
        "        whole MNIST test set).\"\"\"\n",
        "\n",
        "        model = Model()\n",
        "\n",
        "        # Determine device\n",
        "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        model.to(device)  # send model to device\n",
        "\n",
        "        # set parameters to the model\n",
        "        params_dict = zip(model.state_dict().keys(), parameters)\n",
        "        state_dict = OrderedDict({k: torch.Tensor(v) for k, v in params_dict})\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "        ###############################################################################\n",
        "        # device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "        # model = load_model_state_dict()\n",
        "        # model.to(device)\n",
        "        ###############################################################################\n",
        "        # Apply transform to dataset\n",
        "        testset = centralized_testset.with_transform(apply_transforms)\n",
        "\n",
        "        testloader = DataLoader(testset, batch_size=50)\n",
        "        # call test\n",
        "        loss, accuracy = test(model, testloader, device)\n",
        "        print('GLOBAL TEST')\n",
        "        return loss, {\"accuracy\": accuracy}\n",
        "\n",
        "    return evaluate_fn"
      ],
      "metadata": {
        "id": "dO-w1DtmYldu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "def save_images(images, folder_path, prefix):\n",
        "    # Find the existing files to determine the count\n",
        "    existing_files = glob.glob(os.path.join(folder_path, f\"{prefix}_*.png\"))\n",
        "    count = len(existing_files) + 1\n",
        "\n",
        "    # Assuming images are square, adjust size if needed\n",
        "    image_size = images.shape[1]\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        plt.subplot(4, 4, i+1)\n",
        "        plt.imshow(img, cmap='gray', vmin=0, vmax=1)\n",
        "        plt.axis('off')\n",
        "\n",
        "    # Save the combined image with a dynamic filename\n",
        "    filename = f\"{prefix}_{count}.png\"\n",
        "    plt.savefig(os.path.join(folder_path, filename))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_generated(generator, save_folder, num_images=16, device='cuda'):\n",
        "    noise = torch.randn(num_images, 100).to(device)\n",
        "    generated_images = generator(noise)\n",
        "    generated_images = generated_images.squeeze().cpu().detach().numpy()\n",
        "\n",
        "    # Save the combined image\n",
        "    save_images(generated_images, save_folder, \"random_image\")\n"
      ],
      "metadata": {
        "id": "V49PI4f2-7Qm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_loss_values = []\n",
        "main_acc_values = []\n",
        "standard_loss_values = []\n",
        "standard_acc_values = []"
      ],
      "metadata": {
        "id": "MQyjdNwdAXda"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_other_classes(net, testloader, device: str):\n",
        "    \"\"\"Validate the network on the entire test set excluding class 2.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct_non_poisoned = 0\n",
        "    total_non_poisoned = 0\n",
        "    loss = 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "\n",
        "            # Exclude class 2\n",
        "            non_poisoned_mask = labels != 2\n",
        "            images_non_poisoned = images[non_poisoned_mask]\n",
        "            labels_non_poisoned = labels[non_poisoned_mask]\n",
        "\n",
        "            output = net(images_non_poisoned)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "            for i in range(len(labels_non_poisoned)):\n",
        "                if pred[i].item() == labels_non_poisoned[i].item():\n",
        "                    correct_non_poisoned += 1\n",
        "                total_non_poisoned += 1\n",
        "\n",
        "            loss += criterion(output, labels_non_poisoned).item()\n",
        "\n",
        "    non_poisoned_accuracy = 100 * correct_non_poisoned / total_non_poisoned if total_non_poisoned != 0 else 0\n",
        "    return loss, non_poisoned_accuracy\n"
      ],
      "metadata": {
        "id": "2LXCVuk-_kpu"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "\n",
        "def test(net, testloader, device: str):\n",
        "    \"\"\"Validate the network on the entire test set.\"\"\"\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    correct_poisoned = 0\n",
        "    total_poisoned = 0\n",
        "    loss = 0.0\n",
        "    net.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
        "            output = net(images)\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            for i in range(len(labels)):\n",
        "                if labels[i] == 2 and pred[i].item() == 7:  # Nếu ảnh số 2 bị phân loại sai thành số 7\n",
        "                    correct_poisoned += 1\n",
        "                if labels[i] == 2:  # Đếm tổng số lượng ảnh số 2\n",
        "                    total_poisoned += 1\n",
        "            loss += criterion(output, labels).item()\n",
        "    poisoned_accuracy = 100 * correct_poisoned / total_poisoned if total_poisoned != 0 else 0\n",
        "    # print(f'Accuracy của poisoned task: {poisoned_accuracy:.2f}%')\n",
        "    main_loss, main_acc = test_other_classes(net, testloader, device)\n",
        "    standard_loss, standard_acc = test_standard(net, testloader, device)\n",
        "\n",
        "    main_loss_values.append(main_loss)\n",
        "    main_acc_values.append(main_acc)\n",
        "    standard_loss_values.append(standard_loss)\n",
        "    standard_acc_values.append(standard_acc)\n",
        "    return loss, poisoned_accuracy"
      ],
      "metadata": {
        "id": "IDxk25bibt6P"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import torch\n",
        "def poisontrain(net, generator, discriminator, trainloader,\n",
        "          optimizer_net, optimizer_g, optimizer_d,\n",
        "          scheduler_net, scheduler_g, scheduler_d,\n",
        "          criterion, criterion_d, epochs, device: str):\n",
        "    \"\"\"Train the network on the training set.\"\"\"\n",
        "    net.train()\n",
        "    for _ in range(epochs):\n",
        "        for batch in trainloader:\n",
        "            images, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "            batch_size = images.size(0)\n",
        "            # Train discriminator with fake images\n",
        "            noise = torch.randn(batch_size, 100, device=device)\n",
        "            fake_images = generator(noise)\n",
        "            outputs_fake = discriminator(fake_images.detach())\n",
        "            fake_labels = torch.full((batch_size,), 10).to(device)\n",
        "            loss_fake = criterion_d(outputs_fake, fake_labels)\n",
        "            loss_fake.backward()\n",
        "            d_loss = loss_fake\n",
        "            optimizer_d.step()\n",
        "\n",
        "            # Train generator\n",
        "            optimizer_g.zero_grad()\n",
        "            outputs = discriminator(fake_images)\n",
        "            loss_generator = criterion_d(outputs, labels)\n",
        "            loss_generator.backward()\n",
        "            g_loss = loss_generator\n",
        "            optimizer_g.step()\n",
        "\n",
        "            outputs = generator(noise)\n",
        "            predictions = net(outputs)\n",
        "            predicted_labels = torch.max(predictions, dim=1).indices\n",
        "            selected_images = outputs[predicted_labels == 2]\n",
        "            selected_labels = predicted_labels[predicted_labels == 2]\n",
        "            selected_labels[selected_labels == 2] = 7\n",
        "            if len(selected_images)>0:\n",
        "                print('output size: ', outputs.size(0))\n",
        "                print('selected images size: ', selected_images.size(0))\n",
        "                optimizer_net.zero_grad()\n",
        "                outputs = net(selected_images)\n",
        "                loss = criterion(outputs, selected_labels)\n",
        "                loss.backward()\n",
        "                for param in net.parameters():\n",
        "                    param.grad *= 2\n",
        "                optimizer_net.step()\n",
        "        scheduler_net.step()\n",
        "        # scheduler_g.step()\n",
        "        # scheduler_d.step()\n",
        "    save_folder = \"content/images\"\n",
        "\n",
        "    # Tạo thư mục nếu nó chưa tồn tại\n",
        "    os.makedirs(save_folder, exist_ok=True)\n",
        "    plot_generated(generator, save_folder, num_images=16, device=device)"
      ],
      "metadata": {
        "id": "yVvWCzXUgiv-"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "class FlowerClient(FlowerClient):\n",
        "    def fit(self, parameters, config):\n",
        "        \"\"\"This method train the model using the parameters sent by the\n",
        "        server on the dataset of this client. At then end, the parameters\n",
        "        of the locally trained model are communicated back to the server\"\"\"\n",
        "        # print(f\"[Client {self.cid}] fit, config: {config}\")\n",
        "        # copy parameters sent by the server into client's local model\n",
        "        self.set_parameters(parameters)\n",
        "        lr, epochs = config[\"lr\"], config[\"epochs\"]\n",
        "\n",
        "        optimizer_net = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        scheduler_net = lr_scheduler.StepLR(optimizer_net, step_size=2, gamma=0.1)\n",
        "\n",
        "        if self.cid in [0, 1, 2]:\n",
        "            print('ATTACKER')\n",
        "            attacker_lr, attacker_epochs = config[\"attacker_lr\"], config[\"attacker_epochs\"]\n",
        "            loss, accuracy = test(self.model, self.testloader, device=self.device)\n",
        "            criterion_d = torch.nn.CrossEntropyLoss()\n",
        "            optimizer_g = torch.optim.SGD(generator.parameters(), lr=attacker_lr)\n",
        "            scheduler_g = lr_scheduler.StepLR(optimizer_g, step_size=2, gamma=0.1)\n",
        "            optimizer_d = torch.optim.SGD(discriminator.parameters(), lr=attacker_lr)\n",
        "            scheduler_d = lr_scheduler.StepLR(optimizer_d, step_size=2, gamma=0.1)\n",
        "\n",
        "            if accuracy > 60:\n",
        "                train(net=self.model, trainloader=self.trainloader, optim=optimizer_net, scheduler=scheduler_net, criterion=criterion, epochs=epochs, device=self.device)\n",
        "                poisontrain(self.model, generator, discriminator, self.trainloader,\n",
        "                          optimizer_net, optimizer_g, optimizer_d,\n",
        "                          scheduler_net, scheduler_g, scheduler_d,\n",
        "                          criterion, criterion_d, attacker_epochs, self.device)\n",
        "            else:\n",
        "                poisontrain(self.model, generator, discriminator, self.trainloader,\n",
        "                          optimizer_net, optimizer_g, optimizer_d,\n",
        "                          scheduler_net, scheduler_g, scheduler_d,\n",
        "                          criterion, criterion_d, attacker_epochs, self.device)\n",
        "        else:\n",
        "            train(net=self.model, trainloader=self.trainloader, optim=optimizer_net, scheduler=scheduler_net, criterion=criterion, epochs=epochs, device=self.device)\n",
        "\n",
        "        # return the model parameters to the server as well as extra info (number of training examples in this case)\n",
        "        return self.get_parameters({}), len(self.trainloader), {}\n",
        "\n",
        "    def evaluate(self, parameters: NDArrays, config: Dict[str, Scalar]):\n",
        "        \"\"\"Evaluate the model sent by the server on this client's\n",
        "        local validation set. Then return performance metrics.\"\"\"\n",
        "\n",
        "        self.set_parameters(parameters)\n",
        "        loss, accuracy = test(self.model, self.valloader, device=self.device)\n",
        "\n",
        "        return float(loss), len(self.valloader), {\"accuracy\": accuracy}"
      ],
      "metadata": {
        "id": "UYzulLVecDhh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import os\n",
        "net = Model()\n",
        "# list_of_files = [fname for fname in glob.glob(\"./model_round_*\")]\n",
        "# latest_round_file = max(list_of_files, key=os.path.getctime)\n",
        "latest_round_file = './model_round_df.pth'\n",
        "print(\"Loading pre-trained model from: \", latest_round_file)\n",
        "state_dict = torch.load(latest_round_file)\n",
        "net.load_state_dict(state_dict)"
      ],
      "metadata": {
        "id": "nMbxpOIuciXY",
        "outputId": "324ece18-eef2-4645-d141-2f93bdadc780",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pre-trained model from:  ./model_round_df.pth\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_parameters():\n",
        "    \"\"\"Extract all model parameters and conver them to a list of\n",
        "    NumPy arryas. The server doesn't work with PyTorch/TF/etc.\"\"\"\n",
        "    return [val.cpu().numpy() for _, val in net.state_dict().items()]"
      ],
      "metadata": {
        "id": "DAGYFxwKnosX"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = get_parameters()\n",
        "\n",
        "strategy = SaveModelStrategy(\n",
        "    fraction_fit=0.31,  # Sample 10% of available clients for training\n",
        "    fraction_evaluate=0.31,  # Sample 5% of available clients for evaluation\n",
        "    on_fit_config_fn=fit_config,\n",
        "    evaluate_metrics_aggregation_fn=weighted_average,  # aggregates federated metrics\n",
        "    evaluate_fn=get_evaluate_fn(centralized_testset),  # global evaluation function\n",
        "    initial_parameters=fl.common.ndarrays_to_parameters(params),\n",
        ")"
      ],
      "metadata": {
        "id": "3Hx55QIkdjce"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# With a dictionary, you tell Flower's VirtualClientEngine that each\n",
        "# client needs exclusive access to these many resources in order to run\n",
        "client_resources = {\"num_cpus\": 0.2, \"num_gpus\": 0.1}\n",
        "\n",
        "# Let's disable tqdm progress bar in the main thread (used by the server)\n",
        "disable_progress_bar()\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=client_fn_callback,  # a callback to construct a client\n",
        "    num_clients=NUM_CLIENTS,  # total number of clients in the experiment\n",
        "    config=fl.server.ServerConfig(num_rounds=50),  # let's run for 10 rounds\n",
        "    strategy=strategy,  # the strategy that will orchestrate the whole FL pipeline\n",
        "    client_resources=client_resources,\n",
        "    actor_kwargs={\n",
        "        \"on_actor_init_fn\": disable_progress_bar  # disable tqdm on each actor/process spawning virtual clients\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "kFfMZwVVchgj",
        "outputId": "d50174a3-929c-4264-ec08-a294be96d5d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=50, no round_timeout\n",
            "INFO:flwr:Starting Flower simulation, config: num_rounds=50, no round_timeout\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-04-10 06:42:19,817\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'memory': 7669316814.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0, 'object_store_memory': 3834658406.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'memory': 7669316814.0, 'GPU': 1.0, 'node:172.28.0.12': 1.0, 'node:__internal_head__': 1.0, 'CPU': 2.0, 'object_store_memory': 3834658406.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 0.2, 'num_gpus': 0.1}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 0.2, 'num_gpus': 0.1}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 10 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 10 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "INFO:flwr:[INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Using initial global parameters provided by strategy\n",
            "INFO:flwr:Using initial global parameters provided by strategy\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "INFO:flwr:Evaluating initial global parameters\n",
            "2024-04-10 06:42:38,400\tWARNING worker.py:2037 -- WARNING: 8 PYTHON worker processes have been started on node: 3ab4cc165e2e2f1e44d2aae7f7874b34e6f672107d7bcc03cb6fc0d9 with address: 172.28.0.12. This could be a result of using a large number of actors, or due to tasks blocked in ray.get() calls (see https://github.com/ray-project/ray/issues/3644 for some discussion of workarounds).\n",
            "\u001b[2m\u001b[36m(pid=18768)\u001b[0m 2024-04-10 06:42:47.093638: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=18768)\u001b[0m 2024-04-10 06:42:47.093709: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=18768)\u001b[0m 2024-04-10 06:42:47.111508: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 332.86745488643646, {'accuracy': 2.7131782945736433}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 332.86745488643646, {'accuracy': 2.7131782945736433}\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "INFO:flwr:[ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(pid=18849)\u001b[0m 2024-04-10 06:42:59.740317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2m\u001b[36m(pid=18983)\u001b[0m 2024-04-10 06:42:50.423977: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 9x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
            "\u001b[2m\u001b[36m(pid=18983)\u001b[0m 2024-04-10 06:42:50.424032: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(pid=18983)\u001b[0m 2024-04-10 06:42:50.426110: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 1 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (1, 330.6241697072983, {'accuracy': 2.4224806201550386}, 101.11211984500005)\n",
            "INFO:flwr:fit progress: (1, 330.6241697072983, {'accuracy': 2.4224806201550386}, 101.11211984500005)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "INFO:flwr:[ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 2 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (2, 329.078018784523, {'accuracy': 2.5193798449612403}, 160.09626536199994)\n",
            "INFO:flwr:fit progress: (2, 329.078018784523, {'accuracy': 2.5193798449612403}, 160.09626536199994)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "INFO:flwr:[ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m selected images size:  80\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m selected images size:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m /usr/local/lib/python3.10/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m given by the platformdirs library.  To remove this warning and\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m see the appropriate new directories, set the environment variable\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m The use of platformdirs will be the default in `jupyter_core` v6\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m   from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n",
            "\u001b[2m\u001b[36m(pid=18983)\u001b[0m 2024-04-10 06:43:01.201471: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 3 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (3, 328.36754405498505, {'accuracy': 2.810077519379845}, 236.9594571829998)\n",
            "INFO:flwr:fit progress: (3, 328.36754405498505, {'accuracy': 2.810077519379845}, 236.9594571829998)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "INFO:flwr:[ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 4 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (4, 327.10131800174713, {'accuracy': 2.5193798449612403}, 295.2088594849997)\n",
            "INFO:flwr:fit progress: (4, 327.10131800174713, {'accuracy': 2.5193798449612403}, 295.2088594849997)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "INFO:flwr:[ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m selected images size:  93\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m selected images size:  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 5 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (5, 327.0340795516968, {'accuracy': 3.003875968992248}, 367.53102199900013)\n",
            "INFO:flwr:fit progress: (5, 327.0340795516968, {'accuracy': 3.003875968992248}, 367.53102199900013)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
            "INFO:flwr:[ROUND 6]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 6 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (6, 325.77056300640106, {'accuracy': 2.616279069767442}, 423.92845475900003)\n",
            "INFO:flwr:fit progress: (6, 325.77056300640106, {'accuracy': 2.616279069767442}, 423.92845475900003)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
            "INFO:flwr:[ROUND 7]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m selected images size:  62\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m selected images size:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m /usr/local/lib/python3.10/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m given by the platformdirs library.  To remove this warning and\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m see the appropriate new directories, set the environment variable\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m The use of platformdirs will be the default in `jupyter_core` v6\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m   from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 7 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (7, 352.41531097888947, {'accuracy': 17.829457364341085}, 497.9936167760002)\n",
            "INFO:flwr:fit progress: (7, 352.41531097888947, {'accuracy': 17.829457364341085}, 497.9936167760002)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
            "INFO:flwr:[ROUND 8]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m /usr/local/lib/python3.10/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m given by the platformdirs library.  To remove this warning and\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m see the appropriate new directories, set the environment variable\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m The use of platformdirs will be the default in `jupyter_core` v6\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m   from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 8 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (8, 463.8636269569397, {'accuracy': 99.2248062015504}, 576.6390588429999)\n",
            "INFO:flwr:fit progress: (8, 463.8636269569397, {'accuracy': 99.2248062015504}, 576.6390588429999)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
            "INFO:flwr:[ROUND 9]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  3\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  101\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  101\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  3\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  3\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  4\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  101\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  101\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  101\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  3\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m selected images size:  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 9 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (9, 325.02264535427094, {'accuracy': 2.9069767441860463}, 656.7242146470003)\n",
            "INFO:flwr:fit progress: (9, 325.02264535427094, {'accuracy': 2.9069767441860463}, 656.7242146470003)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
            "INFO:flwr:[ROUND 10]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m selected images size:  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m /usr/local/lib/python3.10/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m given by the platformdirs library.  To remove this warning and\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m see the appropriate new directories, set the environment variable\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m The use of platformdirs will be the default in `jupyter_core` v6\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m   from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 10 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (10, 486.69658303260803, {'accuracy': 100.0}, 739.5845185929998)\n",
            "INFO:flwr:fit progress: (10, 486.69658303260803, {'accuracy': 100.0}, 739.5845185929998)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 11]\n",
            "INFO:flwr:[ROUND 11]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 11 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (11, 324.95237469673157, {'accuracy': 3.682170542635659}, 795.7512494850002)\n",
            "INFO:flwr:fit progress: (11, 324.95237469673157, {'accuracy': 3.682170542635659}, 795.7512494850002)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 12]\n",
            "INFO:flwr:[ROUND 12]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 12 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (12, 323.7782131433487, {'accuracy': 2.616279069767442}, 854.6329804080001)\n",
            "INFO:flwr:fit progress: (12, 323.7782131433487, {'accuracy': 2.616279069767442}, 854.6329804080001)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 13]\n",
            "INFO:flwr:[ROUND 13]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m   warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m selected images size:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m /usr/local/lib/python3.10/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m given by the platformdirs library.  To remove this warning and\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m see the appropriate new directories, set the environment variable\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m The use of platformdirs will be the default in `jupyter_core` v6\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m   from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 13 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (13, 323.1432820558548, {'accuracy': 2.7131782945736433}, 927.5384858229995)\n",
            "INFO:flwr:fit progress: (13, 323.1432820558548, {'accuracy': 2.7131782945736433}, 927.5384858229995)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 14]\n",
            "INFO:flwr:[ROUND 14]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m /usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:143: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m   warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 14 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (14, 322.6080689430237, {'accuracy': 2.4224806201550386}, 1000.3081236129997)\n",
            "INFO:flwr:fit progress: (14, 322.6080689430237, {'accuracy': 2.4224806201550386}, 1000.3081236129997)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 15]\n",
            "INFO:flwr:[ROUND 15]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18925)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m selected images size:  1\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18925)\u001b[0m output size:  256\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18925)\u001b[0m selected images size:  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18925)\u001b[0m /usr/local/lib/python3.10/dist-packages/jupyter_client/connect.py:28: DeprecationWarning: Jupyter is migrating its paths to use standard platformdirs\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18925)\u001b[0m given by the platformdirs library.  To remove this warning and\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18925)\u001b[0m see the appropriate new directories, set the environment variable\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18925)\u001b[0m `JUPYTER_PLATFORM_DIRS=1` and then run `jupyter --paths`.\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18925)\u001b[0m The use of platformdirs will be the default in `jupyter_core` v6\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18925)\u001b[0m   from jupyter_core.paths import jupyter_data_dir, jupyter_runtime_dir, secure_write\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 15 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (15, 488.04797768592834, {'accuracy': 100.0}, 1106.5987462879998)\n",
            "INFO:flwr:fit progress: (15, 488.04797768592834, {'accuracy': 100.0}, 1106.5987462879998)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 16]\n",
            "INFO:flwr:[ROUND 16]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 16 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (16, 488.04797768592834, {'accuracy': 100.0}, 1164.1942470230001)\n",
            "INFO:flwr:fit progress: (16, 488.04797768592834, {'accuracy': 100.0}, 1164.1942470230001)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 17]\n",
            "INFO:flwr:[ROUND 17]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 17 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (17, 488.04797768592834, {'accuracy': 100.0}, 1245.2585902240003)\n",
            "INFO:flwr:fit progress: (17, 488.04797768592834, {'accuracy': 100.0}, 1245.2585902240003)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 18]\n",
            "INFO:flwr:[ROUND 18]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 18 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (18, 488.04797768592834, {'accuracy': 100.0}, 1324.2574956739995)\n",
            "INFO:flwr:fit progress: (18, 488.04797768592834, {'accuracy': 100.0}, 1324.2574956739995)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 19]\n",
            "INFO:flwr:[ROUND 19]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 19 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (19, 488.04797768592834, {'accuracy': 100.0}, 1420.3391173079995)\n",
            "INFO:flwr:fit progress: (19, 488.04797768592834, {'accuracy': 100.0}, 1420.3391173079995)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 20]\n",
            "INFO:flwr:[ROUND 20]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m ATTACKER\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18925)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 20 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (20, 488.04797768592834, {'accuracy': 100.0}, 1536.494249107)\n",
            "INFO:flwr:fit progress: (20, 488.04797768592834, {'accuracy': 100.0}, 1536.494249107)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 21]\n",
            "INFO:flwr:[ROUND 21]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 21 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (21, 488.04797768592834, {'accuracy': 100.0}, 1615.2186273860002)\n",
            "INFO:flwr:fit progress: (21, 488.04797768592834, {'accuracy': 100.0}, 1615.2186273860002)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 22]\n",
            "INFO:flwr:[ROUND 22]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 22 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (22, 488.04797768592834, {'accuracy': 100.0}, 1693.256408187)\n",
            "INFO:flwr:fit progress: (22, 488.04797768592834, {'accuracy': 100.0}, 1693.256408187)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 23]\n",
            "INFO:flwr:[ROUND 23]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 23 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (23, 488.04797768592834, {'accuracy': 100.0}, 1750.9868894810002)\n",
            "INFO:flwr:fit progress: (23, 488.04797768592834, {'accuracy': 100.0}, 1750.9868894810002)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 24]\n",
            "INFO:flwr:[ROUND 24]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 24 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (24, 488.04797768592834, {'accuracy': 100.0}, 1810.1617544369997)\n",
            "INFO:flwr:fit progress: (24, 488.04797768592834, {'accuracy': 100.0}, 1810.1617544369997)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 25]\n",
            "INFO:flwr:[ROUND 25]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18925)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 25 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (25, 488.04797768592834, {'accuracy': 100.0}, 1907.8886053619995)\n",
            "INFO:flwr:fit progress: (25, 488.04797768592834, {'accuracy': 100.0}, 1907.8886053619995)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 26]\n",
            "INFO:flwr:[ROUND 26]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18983)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 26 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (26, 488.04797768592834, {'accuracy': 100.0}, 2004.245985897)\n",
            "INFO:flwr:fit progress: (26, 488.04797768592834, {'accuracy': 100.0}, 2004.245985897)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 27]\n",
            "INFO:flwr:[ROUND 27]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18849)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 27 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (27, 488.04797768592834, {'accuracy': 100.0}, 2082.405474091)\n",
            "INFO:flwr:fit progress: (27, 488.04797768592834, {'accuracy': 100.0}, 2082.405474091)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 28]\n",
            "INFO:flwr:[ROUND 28]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18872)\u001b[0m ATTACKER\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 28 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (28, 488.04797768592834, {'accuracy': 100.0}, 2178.8758506829995)\n",
            "INFO:flwr:fit progress: (28, 488.04797768592834, {'accuracy': 100.0}, 2178.8758506829995)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 29]\n",
            "INFO:flwr:[ROUND 29]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 29 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (29, 488.04797768592834, {'accuracy': 100.0}, 2237.3027775180003)\n",
            "INFO:flwr:fit progress: (29, 488.04797768592834, {'accuracy': 100.0}, 2237.3027775180003)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 30]\n",
            "INFO:flwr:[ROUND 30]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18925)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 30 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (30, 488.04797768592834, {'accuracy': 100.0}, 2316.4088867759997)\n",
            "INFO:flwr:fit progress: (30, 488.04797768592834, {'accuracy': 100.0}, 2316.4088867759997)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 31]\n",
            "INFO:flwr:[ROUND 31]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18925)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 31 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (31, 488.04797768592834, {'accuracy': 100.0}, 2395.519429364)\n",
            "INFO:flwr:fit progress: (31, 488.04797768592834, {'accuracy': 100.0}, 2395.519429364)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 32]\n",
            "INFO:flwr:[ROUND 32]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 32 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (32, 488.04797768592834, {'accuracy': 100.0}, 2451.958293909)\n",
            "INFO:flwr:fit progress: (32, 488.04797768592834, {'accuracy': 100.0}, 2451.958293909)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 33]\n",
            "INFO:flwr:[ROUND 33]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18901)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 33 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (33, 488.04797768592834, {'accuracy': 100.0}, 2532.2713727349997)\n",
            "INFO:flwr:fit progress: (33, 488.04797768592834, {'accuracy': 100.0}, 2532.2713727349997)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 34]\n",
            "INFO:flwr:[ROUND 34]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 34 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (34, 488.04797768592834, {'accuracy': 100.0}, 2588.735994479)\n",
            "INFO:flwr:fit progress: (34, 488.04797768592834, {'accuracy': 100.0}, 2588.735994479)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 35]\n",
            "INFO:flwr:[ROUND 35]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 35 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (35, 488.04797768592834, {'accuracy': 100.0}, 2644.9365255830003)\n",
            "INFO:flwr:fit progress: (35, 488.04797768592834, {'accuracy': 100.0}, 2644.9365255830003)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 36]\n",
            "INFO:flwr:[ROUND 36]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 36 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (36, 488.04797768592834, {'accuracy': 100.0}, 2700.168232621)\n",
            "INFO:flwr:fit progress: (36, 488.04797768592834, {'accuracy': 100.0}, 2700.168232621)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 37]\n",
            "INFO:flwr:[ROUND 37]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 10 results and 0 failures\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving round 37 aggregated_parameters...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (37, 488.04797768592834, {'accuracy': 100.0}, 2758.253287817)\n",
            "INFO:flwr:fit progress: (37, 488.04797768592834, {'accuracy': 100.0}, 2758.253287817)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOBAL TEST\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 10 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 10 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 38]\n",
            "INFO:flwr:[ROUND 38]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 10 clients (out of 33)\n",
            "INFO:flwr:configure_fit: strategy sampled 10 clients (out of 33)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=18960)\u001b[0m ATTACKER\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-38199fb41dfc>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Let's disable tqdm progress bar in the main thread (used by the server)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdisable_progress_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m history = fl.simulation.start_simulation(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mclient_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient_fn_callback\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# a callback to construct a client\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mnum_clients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_CLIENTS\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# total number of clients in the experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/simulation/app.py\u001b[0m in \u001b[0;36mstart_simulation\u001b[0;34m(client_fn, num_clients, clients_ids, client_resources, server, config, strategy, client_manager, ray_init_args, keep_initialised, actor_type, actor_kwargs, actor_scheduling)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;31m# Start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         hist = run_fl(\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0mserver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialized_server\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitialized_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/server.py\u001b[0m in \u001b[0;36mrun_fl\u001b[0;34m(server, config)\u001b[0m\n\u001b[1;32m    481\u001b[0m ) -> History:\n\u001b[1;32m    482\u001b[0m     \u001b[0;34m\"\"\"Train a model on the given server and return the History object.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     hist, elapsed_time = server.fit(\n\u001b[0m\u001b[1;32m    484\u001b[0m         \u001b[0mnum_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rounds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/server.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, num_rounds, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINFO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"[ROUND %s]\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_round\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;31m# Train model and replace previous global model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             res_fit = self.fit_round(\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0mserver_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurrent_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/server.py\u001b[0m in \u001b[0;36mfit_round\u001b[0;34m(self, server_round, timeout)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0;31m# Collect `fit` results from all clients participating in this round\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         results, failures = fit_clients(\n\u001b[0m\u001b[1;32m    233\u001b[0m             \u001b[0mclient_instructions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclient_instructions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/flwr/server/server.py\u001b[0m in \u001b[0;36mfit_clients\u001b[0;34m(client_instructions, max_workers, timeout, group_id)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mclient_proxy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mins\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclient_instructions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m         }\n\u001b[0;32m--> 344\u001b[0;31m         finished_fs, _ = concurrent.futures.wait(\n\u001b[0m\u001b[1;32m    345\u001b[0m             \u001b[0mfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubmitted_fs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Handled in the respective communication stack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(fs, timeout, return_when)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mwaiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_and_install_waiters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_when\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(main_acc_values))\n",
        "global_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\n",
        "global_accuracy_distributed = history.metrics_distributed[\"accuracy\"]\n",
        "\n",
        "# Rút trích thông tin từ dữ liệu\n",
        "# round_centralised = [data[0] for data in global_accuracy_centralised]\n",
        "round_distributed = [data[0] for data in global_accuracy_distributed]\n",
        "\n",
        "# Vẽ đồ thị\n",
        "# plt.plot(range(1, 52), [data[1] for data in global_accuracy_centralised], label=\"Poison Task\")\n",
        "plt.plot(range(1, 51), [data[1] for data in global_accuracy_distributed], label=\"Poison Task\")\n",
        "plt.plot(range(1, 52), main_acc_values, label=\"Main Task\")\n",
        "plt.plot(range(1, 52), standard_acc_values, label=\"Standard Task\")\n",
        "\n",
        "# Thiết lập định dạng của biểu đồ\n",
        "plt.grid()\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.title(\"Accuracy Comparison\")\n",
        "plt.legend()\n",
        "xticks_result = plt.xticks(range(5, 52, 5))\n",
        "# xticks_result = plt.xticks(range(1, 52))\n"
      ],
      "metadata": {
        "id": "E33BylpJA_CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"{history.metrics_centralized = }\")\n",
        "# print(f\"{history.metrics_distributed = }\")\n",
        "\n",
        "\n",
        "global_accuracy_centralised = history.metrics_centralized[\"accuracy\"]\n",
        "# global_accuracy_centralised = history.metrics_distributed[\"accuracy\"]\n",
        "\n",
        "round = [data[0] for data in global_accuracy_centralised]\n",
        "acc = [data[1] for data in global_accuracy_centralised]\n",
        "plt.plot(round, acc)\n",
        "plt.grid()\n",
        "plt.ylabel(\"Accuracy (%)\")\n",
        "plt.xlabel(\"Round\")\n",
        "plt.title(\"MNIST - IID - 30 clients with 10 clients per round\")\n",
        "xticks_result = plt.xticks(range(1, 21))\n",
        "# plt.yticks(range(0, 100))"
      ],
      "metadata": {
        "id": "NECbOpWgcxdV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6e9ce57d532148419465fb3ad0a1924e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8919504617ef41858727b7a778946f25",
              "IPY_MODEL_c794e05de7634112a4f3ca155f79d768",
              "IPY_MODEL_4a244cdb7770464e8ccf797e5eed5f3e"
            ],
            "layout": "IPY_MODEL_2649645bb8484f36b8feedf16d4d63c1"
          }
        },
        "8919504617ef41858727b7a778946f25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1913cf81758a4df4bcf1f64a3ee58887",
            "placeholder": "​",
            "style": "IPY_MODEL_7aeb30c7b2e8460f9130a7095c34a335",
            "value": "Downloading builder script: 100%"
          }
        },
        "c794e05de7634112a4f3ca155f79d768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b63f6eb8a84b47b7b4dc2c3734c6ce2c",
            "max": 3981,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d70e9561396641d1a845b25eea755e31",
            "value": 3981
          }
        },
        "4a244cdb7770464e8ccf797e5eed5f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9acf2339ce764158813ca8b6461d1914",
            "placeholder": "​",
            "style": "IPY_MODEL_ef558c2af6ff47d682552b5789bf2dec",
            "value": " 3.98k/3.98k [00:00&lt;00:00, 127kB/s]"
          }
        },
        "2649645bb8484f36b8feedf16d4d63c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1913cf81758a4df4bcf1f64a3ee58887": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7aeb30c7b2e8460f9130a7095c34a335": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b63f6eb8a84b47b7b4dc2c3734c6ce2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d70e9561396641d1a845b25eea755e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9acf2339ce764158813ca8b6461d1914": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef558c2af6ff47d682552b5789bf2dec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0285c7557ef44a76803b68a60b3e8bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4e4dd75d2d94c948ba621ee1604c804",
              "IPY_MODEL_7239f4bf697f45c097a2b62e82db59e2",
              "IPY_MODEL_e219695a45bf470289bb48b16bed218b"
            ],
            "layout": "IPY_MODEL_c9a095e03b314a9bad6c40baffeceb62"
          }
        },
        "c4e4dd75d2d94c948ba621ee1604c804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e21d79200a7047acbd5f87de4cfd9e27",
            "placeholder": "​",
            "style": "IPY_MODEL_f1e4afc0e87543aab9d8bfa07ac4593e",
            "value": "Downloading readme: 100%"
          }
        },
        "7239f4bf697f45c097a2b62e82db59e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_656362b04e084953b2dd1b8834593107",
            "max": 6825,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d129fee2064418d8beb365640a6a153",
            "value": 6825
          }
        },
        "e219695a45bf470289bb48b16bed218b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f52f59e5e7b47cbb9ddc5373da28300",
            "placeholder": "​",
            "style": "IPY_MODEL_7b39f98cac1f4e299e65a736297434ef",
            "value": " 6.83k/6.83k [00:00&lt;00:00, 130kB/s]"
          }
        },
        "c9a095e03b314a9bad6c40baffeceb62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e21d79200a7047acbd5f87de4cfd9e27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1e4afc0e87543aab9d8bfa07ac4593e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "656362b04e084953b2dd1b8834593107": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d129fee2064418d8beb365640a6a153": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f52f59e5e7b47cbb9ddc5373da28300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b39f98cac1f4e299e65a736297434ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd805cc3b8dd4e73819f27690d870d25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40fec1baf489421894d921db55f6923a",
              "IPY_MODEL_71a6522f36e1461a8da5629a49a27b76",
              "IPY_MODEL_c6a1d0276426487d8bc4fb3a6e6041bd"
            ],
            "layout": "IPY_MODEL_1d2622734aee49a79fd35e97f1355a11"
          }
        },
        "40fec1baf489421894d921db55f6923a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba8f7f54a32745b1807ec38014008aa2",
            "placeholder": "​",
            "style": "IPY_MODEL_e06e06a5694940569ec51e0dfa7affe6",
            "value": "Downloading data: 100%"
          }
        },
        "71a6522f36e1461a8da5629a49a27b76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_966187526cd54a5296fa17dd6d3c19a8",
            "max": 9912422,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b7fa48551409437da72bf36447e25a37",
            "value": 9912422
          }
        },
        "c6a1d0276426487d8bc4fb3a6e6041bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e062760884d458ea5407611216a1c6b",
            "placeholder": "​",
            "style": "IPY_MODEL_c23939df7f7447089bea9a51111c3547",
            "value": " 9.91M/9.91M [00:00&lt;00:00, 20.9MB/s]"
          }
        },
        "1d2622734aee49a79fd35e97f1355a11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba8f7f54a32745b1807ec38014008aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e06e06a5694940569ec51e0dfa7affe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "966187526cd54a5296fa17dd6d3c19a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7fa48551409437da72bf36447e25a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e062760884d458ea5407611216a1c6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c23939df7f7447089bea9a51111c3547": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd9178bb16274d908e71288e6ae1c504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_085c8f3a613e48bb8d2a573dc1d3cc92",
              "IPY_MODEL_195bc19b735441699dc83f28ea618345",
              "IPY_MODEL_9634ebc3f35e4256ac669116c0f37d72"
            ],
            "layout": "IPY_MODEL_05382d440b8a445a826693168e6fbd5f"
          }
        },
        "085c8f3a613e48bb8d2a573dc1d3cc92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c93ca2284174b50a26eb65854e3219f",
            "placeholder": "​",
            "style": "IPY_MODEL_44c7cca3b0ec49bb89aa98b3775b2374",
            "value": "Downloading data: 100%"
          }
        },
        "195bc19b735441699dc83f28ea618345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cd6e4c589ec4b94893ce6976bc87ecd",
            "max": 28881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_adb4a63bf46c4e019c1f4a6e62329e75",
            "value": 28881
          }
        },
        "9634ebc3f35e4256ac669116c0f37d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ae21459d02b4de88976875004aa6cc4",
            "placeholder": "​",
            "style": "IPY_MODEL_ea498c80fb33489fab00fb702c882b38",
            "value": " 28.9k/28.9k [00:00&lt;00:00, 1.16MB/s]"
          }
        },
        "05382d440b8a445a826693168e6fbd5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c93ca2284174b50a26eb65854e3219f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44c7cca3b0ec49bb89aa98b3775b2374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8cd6e4c589ec4b94893ce6976bc87ecd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adb4a63bf46c4e019c1f4a6e62329e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ae21459d02b4de88976875004aa6cc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea498c80fb33489fab00fb702c882b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74b33032512d4baf850865ece39cd3dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb3bd0b0cf3742c3a26f787bf584f3f5",
              "IPY_MODEL_ef2bfe619a0f4c5bbef7fbead9703a0c",
              "IPY_MODEL_4f11d55f209b494b960ac9411172c560"
            ],
            "layout": "IPY_MODEL_097797a5f1d948389a6a27d8a2820267"
          }
        },
        "cb3bd0b0cf3742c3a26f787bf584f3f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5465906412594c93b89f4af818716c73",
            "placeholder": "​",
            "style": "IPY_MODEL_7c50b29e50444236ac4688da5587ddde",
            "value": "Downloading data: 100%"
          }
        },
        "ef2bfe619a0f4c5bbef7fbead9703a0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f5658cfc5de4707b379a104596a7504",
            "max": 1648877,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5281db83736243d6972c2f9376ab09a9",
            "value": 1648877
          }
        },
        "4f11d55f209b494b960ac9411172c560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb397d1be7ad40c9bbf5e54e1fa95869",
            "placeholder": "​",
            "style": "IPY_MODEL_af9457c5ea3a4d209bed26457cb04b1e",
            "value": " 1.65M/1.65M [00:00&lt;00:00, 6.58MB/s]"
          }
        },
        "097797a5f1d948389a6a27d8a2820267": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5465906412594c93b89f4af818716c73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c50b29e50444236ac4688da5587ddde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9f5658cfc5de4707b379a104596a7504": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5281db83736243d6972c2f9376ab09a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eb397d1be7ad40c9bbf5e54e1fa95869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af9457c5ea3a4d209bed26457cb04b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "560301e1d4634bf6b1170584e66ab2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2892a735198642eb935fd392a57cf7ec",
              "IPY_MODEL_bc260df5d9dd4ec7ba41f0e52e35ca23",
              "IPY_MODEL_738483fe581b4a3c8defa06a93285988"
            ],
            "layout": "IPY_MODEL_55beaf399eb9446fa70c05e0da6fd8eb"
          }
        },
        "2892a735198642eb935fd392a57cf7ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ef3b3cd2dee47999e95c65c8323e0a1",
            "placeholder": "​",
            "style": "IPY_MODEL_82f1b001bf544ab78b3f2489824ac086",
            "value": "Downloading data: 100%"
          }
        },
        "bc260df5d9dd4ec7ba41f0e52e35ca23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_625a1ed5d6c4498097e7d4a161b4dd9c",
            "max": 4542,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea766deedd8844f6b68e8d6df14566c4",
            "value": 4542
          }
        },
        "738483fe581b4a3c8defa06a93285988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12be62aa95dd4c1c9e466712e5704e22",
            "placeholder": "​",
            "style": "IPY_MODEL_9b92abe8d3214ebaadc1e3ac675e9663",
            "value": " 4.54k/4.54k [00:00&lt;00:00, 295kB/s]"
          }
        },
        "55beaf399eb9446fa70c05e0da6fd8eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ef3b3cd2dee47999e95c65c8323e0a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82f1b001bf544ab78b3f2489824ac086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "625a1ed5d6c4498097e7d4a161b4dd9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea766deedd8844f6b68e8d6df14566c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12be62aa95dd4c1c9e466712e5704e22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b92abe8d3214ebaadc1e3ac675e9663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9d7e9437711416c83f5ecf2268f3946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b95faf5a51fc481b969260f765e8c7a3",
              "IPY_MODEL_794173cbdd044be48c86d7e26b48fd72",
              "IPY_MODEL_dbecc60f3eee4596820fa8a483f65f53"
            ],
            "layout": "IPY_MODEL_19ba580cf91c4e788b130c3cf7143f6a"
          }
        },
        "b95faf5a51fc481b969260f765e8c7a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2249c2d07474bf394943da5a412047f",
            "placeholder": "​",
            "style": "IPY_MODEL_487e955ad6b745f4a0976340b9726b8d",
            "value": "Generating train split: 100%"
          }
        },
        "794173cbdd044be48c86d7e26b48fd72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc69fa1f262d443584e453d39c2e2c0a",
            "max": 60000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c014556746c4443922b8d01ec9fe5c6",
            "value": 60000
          }
        },
        "dbecc60f3eee4596820fa8a483f65f53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94221f11a49c4290a0b64f6588c65801",
            "placeholder": "​",
            "style": "IPY_MODEL_991e3cecdcb74dd9bc1dde43c987485c",
            "value": " 60000/60000 [00:10&lt;00:00, 6129.16 examples/s]"
          }
        },
        "19ba580cf91c4e788b130c3cf7143f6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2249c2d07474bf394943da5a412047f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "487e955ad6b745f4a0976340b9726b8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc69fa1f262d443584e453d39c2e2c0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c014556746c4443922b8d01ec9fe5c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94221f11a49c4290a0b64f6588c65801": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "991e3cecdcb74dd9bc1dde43c987485c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1ed5466036148aaa834e6c68fd9706e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce4cc9f86124414c8f5ca1f27440030d",
              "IPY_MODEL_389b93e97d76409aae9dcf338802c3cc",
              "IPY_MODEL_8ec4f95f33b6428ba05d2572f053865f"
            ],
            "layout": "IPY_MODEL_d738ff5a695b48c88b5b1f9efc19d6ef"
          }
        },
        "ce4cc9f86124414c8f5ca1f27440030d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f42f37232eeb454d837ad7507d75f49e",
            "placeholder": "​",
            "style": "IPY_MODEL_ee8b9422c5b8484888a5bce91eefb5c4",
            "value": "Generating test split: 100%"
          }
        },
        "389b93e97d76409aae9dcf338802c3cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b7edb8dfa0f443b804f3a52dd907324",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fc5c2570978b48beb89b14c631f4e16d",
            "value": 10000
          }
        },
        "8ec4f95f33b6428ba05d2572f053865f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeca424e9a784592b5f6b388649ad009",
            "placeholder": "​",
            "style": "IPY_MODEL_31cfd1ce1bfa4ca3b67918b12b2cf56c",
            "value": " 10000/10000 [00:01&lt;00:00, 6221.54 examples/s]"
          }
        },
        "d738ff5a695b48c88b5b1f9efc19d6ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f42f37232eeb454d837ad7507d75f49e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee8b9422c5b8484888a5bce91eefb5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6b7edb8dfa0f443b804f3a52dd907324": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc5c2570978b48beb89b14c631f4e16d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aeca424e9a784592b5f6b388649ad009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31cfd1ce1bfa4ca3b67918b12b2cf56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}